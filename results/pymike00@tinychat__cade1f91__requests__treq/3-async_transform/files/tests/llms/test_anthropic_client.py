import json
import unittest
from unittest.mock import AsyncMock, MagicMock, Mock, patch

from tinychat.llms.anthropic import AnthropicAIClient
import pytest


class TestAnthropicAIClientStreaming(unittest.IsolatedAsyncioTestCase):
    @pytest.mark.asyncio
    @patch("tinychat.llms.anthropic.treq.post")
    @patch("tinychat.llms.base.BaseLLMClient.api_key", new_callable=MagicMock)
    async def test_perform_stream_request_success(self, mock_api_key, mock_post):
        # Setting a dummy value for mock_api_key is not strictly needed here

        # Mocking the response
        mock_response = AsyncMock()
        mock_response.code = 200
        mock_post.return_value = mock_response

        # Creating mock events
        mock_event1 = MagicMock()
        mock_event1.data = json.dumps(
            {"type": "content_block_delta", "delta": {"text": "part1"}}
        )
        mock_event2 = MagicMock()
        mock_event2.data = json.dumps(
            {"type": "content_block_delta", "delta": {"text": "part2"}}
        )
        mock_event_done = MagicMock()
        mock_event_done.data = json.dumps({"type": "done"})

        # Mocking SSEClient to return test events
        with patch("tinychat.llms.anthropic.SSEClient") as mock_sse_client:
            test_stream = iter([mock_event1, mock_event2, mock_event_done])
            mock_sse_client.return_value.events = MagicMock(return_value=test_stream)

            client = AnthropicAIClient(model_name="test_model", temperature=0.0)
            messages = [{"role": "user", "content": "hello"}]
            stream = await client.perform_stream_request(messages)

            # Extracting and verifying the stream response
            responses = []
            async for event in stream.events():
                event_data = json.loads(event.data)
                if event_data.get("type") == "content_block_delta":
                    responses.append(event_data["delta"]["text"])

            self.assertEqual(responses, ["part1", "part2"])

    @pytest.mark.asyncio
    @patch("tinychat.llms.anthropic.treq.post")
    @patch("tinychat.llms.base.BaseLLMClient.api_key", new_callable=MagicMock)
    async def test_perform_stream_request_failure(self, mock_api_key, mock_post):
        # Setting a dummy value for mock_api_key is not strictly needed here

        # Mocking the response with an error status code
        mock_response = AsyncMock()
        mock_response.code = 400
        mock_post.return_value = mock_response

        client = AnthropicAIClient(model_name="test_model", temperature=0.0)
        messages = [{"role": "user", "content": "hello"}]

        with self.assertRaises(ValueError) as context:
            async for _ in await client.perform_stream_request(messages):
                pass
        self.assertIn(
            "Server responded with an error. Status Code: 400", str(context.exception)
        )
