{
  "exitcode": 1,
  "summary": {
    "failed": 6,
    "passed": 15,
    "total": 21,
    "collected": 21
  },
  "collectors": [
    {
      "nodeid": "",
      "outcome": "passed",
      "result": [
        {
          "nodeid": ".",
          "type": "Dir"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 52
        },
        {
          "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 11
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming::test_stream_response_success",
          "type": "TestCaseFunction",
          "lineno": 10
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 30
        },
        {
          "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 10
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming::test_stream_response_success",
          "type": "TestCaseFunction",
          "lineno": 8
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 55
        },
        {
          "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 11
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 9
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_invalid_key",
          "type": "TestCaseFunction",
          "lineno": 15
        },
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_valid_key",
          "type": "TestCaseFunction",
          "lineno": 9
        },
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_default_headers",
          "type": "TestCaseFunction",
          "lineno": 23
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_llms_base.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 52
        },
        {
          "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 12
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 9
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 55
        },
        {
          "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 12
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 9
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 55
        },
        {
          "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 12
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 9
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_anthropic_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_cohere_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_cohere_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_google_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_google_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_llms_base.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_mistral_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_mistral_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_openai_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_openai_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_together_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_together_handler.py",
          "type": "Module"
        }
      ]
    },
    {
      "nodeid": "tests",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": "tinychat/backend",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat/llms",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat/ui",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat/utils",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tinychat/backend",
          "type": "Package"
        },
        {
          "nodeid": "tinychat/llms",
          "type": "Package"
        },
        {
          "nodeid": "tinychat/ui",
          "type": "Package"
        },
        {
          "nodeid": "tinychat/utils",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": ".",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests",
          "type": "Package"
        },
        {
          "nodeid": "tinychat",
          "type": "Package"
        }
      ]
    }
  ],
  "tests": [
    {
      "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_failure",
      "lineno": 52,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_failure",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestAnthropicAIClientStreaming",
        "test_anthropic_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\pymike00@tinychat__cade1f91__requests__aiohttp\\tests\\llms\\test_anthropic_client.py",
          "lineno": 68,
          "message": "TypeError: object async_generator can't be used in 'await' expression"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_anthropic_client.py",
            "lineno": 68,
            "message": "TypeError"
          }
        ],
        "longrepr": "self = <tests.llms.test_anthropic_client.TestAnthropicAIClientStreaming testMethod=test_perform_stream_request_failure>\nmock_api_key = <MagicMock name='api_key' id='1616374622608'>\nmock_post = <MagicMock name='post' id='1616383677344'>\n\n    @pytest.mark.asyncio\n    @patch(\"tinychat.llms.anthropic.aiohttp.ClientSession.post\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    async def test_perform_stream_request_failure(self, mock_api_key, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Mocking the response with an error status code\n        mock_response = AsyncMock(spec=ClientResponse)\n        mock_response.status = 400\n        mock_post.return_value.__aenter__.return_value = mock_response\n    \n        client = AnthropicAIClient(model_name=\"test_model\", temperature=0.0)\n        messages = [{\"role\": \"user\", \"content\": \"hello\"}]\n    \n        with self.assertRaises(ValueError) as context:\n>           async for _ in await client.perform_stream_request(messages):\nE           TypeError: object async_generator can't be used in 'await' expression\n\ntests\\llms\\test_anthropic_client.py:68: TypeError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_success",
      "lineno": 11,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestAnthropicAIClientStreaming",
        "test_anthropic_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py",
          "lineno": 1431,
          "message": "AttributeError: <module 'tinychat.llms.anthropic' from 'D:\\\\repos\\\\pymike00@tinychat__cade1f91__requests__aiohttp\\\\tinychat\\\\llms\\\\anthropic.py'> does not have the attribute 'SSEClient'"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_anthropic_client.py",
            "lineno": 36,
            "message": ""
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py",
            "lineno": 1458,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py",
            "lineno": 1431,
            "message": "AttributeError"
          }
        ],
        "longrepr": "self = <tests.llms.test_anthropic_client.TestAnthropicAIClientStreaming testMethod=test_perform_stream_request_success>\nmock_api_key = <MagicMock name='api_key' id='1616384527632'>\nmock_post = <MagicMock name='post' id='1616384531808'>\n\n    @pytest.mark.asyncio\n    @patch(\"tinychat.llms.anthropic.aiohttp.ClientSession.post\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    async def test_perform_stream_request_success(self, mock_api_key, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Mocking the response\n        mock_response = AsyncMock(spec=ClientResponse)\n        mock_response.status = 200\n        mock_post.return_value.__aenter__.return_value = mock_response\n    \n        # Creating mock events\n        mock_event1 = MagicMock()\n        mock_event1.data = json.dumps(\n            {\"type\": \"content_block_delta\", \"delta\": {\"text\": \"part1\"}}\n        )\n        mock_event2 = MagicMock()\n        mock_event2.data = json.dumps(\n            {\"type\": \"content_block_delta\", \"delta\": {\"text\": \"part2\"}}\n        )\n        mock_event_done = MagicMock()\n        mock_event_done.data = json.dumps({\"type\": \"done\"})\n    \n        # Mocking SSEClient to return test events\n>       with patch(\"tinychat.llms.anthropic.SSEClient\") as mock_sse_client:\n\ntests\\llms\\test_anthropic_client.py:36: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py:1458: in __enter__\n    original, local = self.get_original()\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <unittest.mock._patch object at 0x00000178580B7C50>\n\n    def get_original(self):\n        target = self.getter()\n        name = self.attribute\n    \n        original = DEFAULT\n        local = False\n    \n        try:\n            original = target.__dict__[name]\n        except (AttributeError, KeyError):\n            original = getattr(target, name, DEFAULT)\n        else:\n            local = True\n    \n        if name in _builtins and isinstance(target, ModuleType):\n            self.create = True\n    \n        if not self.create and original is DEFAULT:\n>           raise AttributeError(\n                \"%s does not have the attribute %r\" % (target, name)\n            )\nE           AttributeError: <module 'tinychat.llms.anthropic' from 'D:\\\\repos\\\\pymike00@tinychat__cade1f91__requests__aiohttp\\\\tinychat\\\\llms\\\\anthropic.py'> does not have the attribute 'SSEClient'\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\mock.py:1431: AttributeError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming::test_stream_response_success",
      "lineno": 10,
      "outcome": "passed",
      "keywords": [
        "test_stream_response_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestAnthropicAIHandlerStreaming",
        "test_anthropic_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_failure",
      "lineno": 30,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_failure",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestCohereClientStreaming",
        "test_cohere_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\pymike00@tinychat__cade1f91__requests__aiohttp\\tests\\llms\\test_cohere_client.py",
          "lineno": 48,
          "message": "TypeError: object async_generator can't be used in 'await' expression"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_cohere_client.py",
            "lineno": 48,
            "message": "TypeError"
          }
        ],
        "longrepr": "self = <tests.llms.test_cohere_client.TestCohereClientStreaming testMethod=test_perform_stream_request_failure>\nmock_api_key = <MagicMock name='api_key' id='1616384813360'>\nmock_post = <MagicMock name='post' id='1616384817296'>\n\n    @pytest.mark.asyncio\n    @patch(\"tinychat.llms.cohere.aiohttp.ClientSession.post\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    async def test_perform_stream_request_failure(self, mock_api_key, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Mocking aiohttp response\n        mock_response = AsyncMock()\n        mock_response.status = 400\n        mock_post.return_value = mock_response\n    \n        client = CohereClient(temperature=0.0)\n        chat_history = [\n            {\"role\": \"User\", \"message\": \"hello\"},\n            {\"role\": \"Chatbot\", \"message\": \"hello!\"},\n        ]\n        with self.assertRaises(ValueError) as context:\n>           await client.perform_stream_request(\"how are you?\", chat_history)\nE           TypeError: object async_generator can't be used in 'await' expression\n\ntests\\llms\\test_cohere_client.py:48: TypeError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_success",
      "lineno": 10,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestCohereClientStreaming",
        "test_cohere_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\pymike00@tinychat__cade1f91__requests__aiohttp\\tests\\llms\\test_cohere_client.py",
          "lineno": 27,
          "message": "TypeError: object async_generator can't be used in 'await' expression"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_cohere_client.py",
            "lineno": 27,
            "message": "TypeError"
          }
        ],
        "longrepr": "self = <tests.llms.test_cohere_client.TestCohereClientStreaming testMethod=test_perform_stream_request_success>\nmock_api_key = <MagicMock name='api_key' id='1616385973072'>\nmock_post = <MagicMock name='post' id='1616377294256'>\n\n    @pytest.mark.asyncio\n    @patch(\"tinychat.llms.cohere.aiohttp.ClientSession.post\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    async def test_perform_stream_request_success(self, mock_api_key, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Mocking aiohttp response\n        mock_response = AsyncMock()\n        mock_response.status = 200\n        mock_post.return_value = mock_response\n    \n        client = CohereClient(temperature=0.0)\n        chat_history = [\n            {\"role\": \"User\", \"message\": \"hello\"},\n            {\"role\": \"Chatbot\", \"message\": \"hello!\"},\n        ]\n>       response = await client.perform_stream_request(\"how are you?\", chat_history)\nE       TypeError: object async_generator can't be used in 'await' expression\n\ntests\\llms\\test_cohere_client.py:27: TypeError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming::test_stream_response_success",
      "lineno": 8,
      "outcome": "passed",
      "keywords": [
        "test_stream_response_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestCohereHandlerStreaming",
        "test_cohere_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_failure",
      "lineno": 55,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestGoogleAIClientStreaming",
        "test_google_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_success",
      "lineno": 11,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestGoogleAIClientStreaming",
        "test_google_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming::test_stream_response",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestGoogleGeminiHandlerStreaming",
        "test_google_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_invalid_key",
      "lineno": 15,
      "outcome": "passed",
      "keywords": [
        "test_api_key_setter_invalid_key",
        "__wrapped__",
        "patchings",
        "TestBaseLLMClient",
        "test_llms_base.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_valid_key",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_api_key_setter_valid_key",
        "__wrapped__",
        "patchings",
        "TestBaseLLMClient",
        "test_llms_base.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_default_headers",
      "lineno": 23,
      "outcome": "passed",
      "keywords": [
        "test_default_headers",
        "__wrapped__",
        "patchings",
        "TestBaseLLMClient",
        "test_llms_base.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_failure",
      "lineno": 52,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_failure",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestMistralClientStreaming",
        "test_mistral_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\pymike00@tinychat__cade1f91__requests__aiohttp\\tests\\llms\\test_mistral_client.py",
          "lineno": 70,
          "message": "TypeError: object async_generator can't be used in 'await' expression"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_mistral_client.py",
            "lineno": 70,
            "message": "TypeError"
          }
        ],
        "longrepr": "self = <tests.llms.test_mistral_client.TestMistralClientStreaming testMethod=test_perform_stream_request_failure>\nmock_api_key = <MagicMock name='api_key' id='1616385963792'>\nmock_post = <MagicMock name='post' id='1616385959184'>\n\n    @pytest.mark.asyncio\n    @patch(\"tinychat.llms.mistral.aiohttp.ClientSession.post\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    async def test_perform_stream_request_failure(self, mock_api_key, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Setup: Mocking the response with an error status code\n        mock_response = AsyncMock(spec=ClientResponse)\n        mock_response.status = 400\n        mock_post.return_value.__aenter__.return_value = mock_response\n    \n        # Execution\n        client = MistralClient(model_name=\"test_model\", temperature=0.0)\n        messages = [{\"role\": \"user\", \"content\": \"hello\"}]\n    \n        # Verification: Expecting a ValueError on error response\n        with self.assertRaises(ValueError) as context:\n>           async for _ in await client.perform_stream_request(messages):  # type: ignore\nE           TypeError: object async_generator can't be used in 'await' expression\n\ntests\\llms\\test_mistral_client.py:70: TypeError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_success",
      "lineno": 12,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestMistralClientStreaming",
        "test_mistral_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\pymike00@tinychat__cade1f91__requests__aiohttp\\tests\\llms\\test_mistral_client.py",
          "lineno": 40,
          "message": "TypeError: object async_generator can't be used in 'await' expression"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_mistral_client.py",
            "lineno": 40,
            "message": "TypeError"
          }
        ],
        "longrepr": "self = <tests.llms.test_mistral_client.TestMistralClientStreaming testMethod=test_perform_stream_request_success>\nmock_api_key = <MagicMock name='api_key' id='1616385441184'>\nmock_sse_client = <MagicMock name='SSEClient' id='1616385379360'>\nmock_post = <MagicMock name='post' id='1616385383152'>\n\n    @pytest.mark.asyncio\n    @patch(\"tinychat.llms.mistral.aiohttp.ClientSession.post\")\n    @patch(\"tinychat.llms.mistral.SSEClient\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    async def test_perform_stream_request_success(self, mock_api_key, mock_sse_client, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Setup: Mocking SSEClient and the response\n        mock_response = AsyncMock(spec=ClientResponse)\n        mock_response.status = 200\n        mock_post.return_value.__aenter__.return_value = mock_response\n    \n        # Creating mock events\n        mock_event1 = MagicMock()\n        mock_event1.data = json.dumps({\"choices\": [{\"delta\": {\"content\": \"part1\"}}]})\n        mock_event2 = MagicMock()\n        mock_event2.data = json.dumps({\"choices\": [{\"delta\": {\"content\": \"part2\"}}]})\n        mock_event_done = MagicMock()\n        mock_event_done.data = \"[DONE]\"\n    \n        # Setting up a test stream\n        test_stream = [mock_event1, mock_event2, mock_event_done]\n        mock_sse_client.return_value.events = MagicMock(return_value=iter(test_stream))\n    \n        # Execution\n        client = MistralClient(model_name=\"test_model\", temperature=0.0)\n        messages = [{\"role\": \"user\", \"content\": \"hello\"}]\n>       stream = await client.perform_stream_request(messages)\nE       TypeError: object async_generator can't be used in 'await' expression\n\ntests\\llms\\test_mistral_client.py:40: TypeError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming::test_stream_response",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestMistralHandlerStreaming",
        "test_mistral_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_failure",
      "lineno": 55,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestOpenAIClientStreaming",
        "test_openai_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_success",
      "lineno": 12,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestOpenAIClientStreaming",
        "test_openai_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming::test_stream_response",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestOpenAIHandlerStreaming",
        "test_openai_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_failure",
      "lineno": 55,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestTogetherClientStreaming",
        "test_together_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_success",
      "lineno": 12,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestTogetherClientStreaming",
        "test_together_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming::test_stream_response",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "asyncio",
        "__wrapped__",
        "patchings",
        "pytestmark",
        "TestTogetherHandlerStreaming",
        "test_together_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__aiohttp",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    }
  ],
  "warnings": [
    {
      "message": "coroutine 'TestAnthropicAIHandlerStreaming.test_stream_response_success' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestAnthropicAIHandlerStreaming.test_stream_response_success of <tests.llms.test_anthropic_handler.TestAnthropicAIHandlerStreaming testMethod=test_stream_response_success>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestCohereHandlerStreaming.test_stream_response_success' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestCohereHandlerStreaming.test_stream_response_success of <tests.llms.test_cohere_handler.TestCohereHandlerStreaming testMethod=test_stream_response_success>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestGoogleAIClientStreaming.test_perform_stream_request_failure' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestGoogleAIClientStreaming.test_perform_stream_request_failure of <tests.llms.test_google_client.TestGoogleAIClientStreaming testMethod=test_perform_stream_request_failure>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestGoogleAIClientStreaming.test_perform_stream_request_success' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestGoogleAIClientStreaming.test_perform_stream_request_success of <tests.llms.test_google_client.TestGoogleAIClientStreaming testMethod=test_perform_stream_request_success>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestGoogleGeminiHandlerStreaming.test_stream_response' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestGoogleGeminiHandlerStreaming.test_stream_response of <tests.llms.test_google_handler.TestGoogleGeminiHandlerStreaming testMethod=test_stream_response>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestMistralHandlerStreaming.test_stream_response' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestMistralHandlerStreaming.test_stream_response of <tests.llms.test_mistral_handler.TestMistralHandlerStreaming testMethod=test_stream_response>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestOpenAIClientStreaming.test_perform_stream_request_failure' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestOpenAIClientStreaming.test_perform_stream_request_failure of <tests.llms.test_openai_client.TestOpenAIClientStreaming testMethod=test_perform_stream_request_failure>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestOpenAIClientStreaming.test_perform_stream_request_success' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestOpenAIClientStreaming.test_perform_stream_request_success of <tests.llms.test_openai_client.TestOpenAIClientStreaming testMethod=test_perform_stream_request_success>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestOpenAIHandlerStreaming.test_stream_response' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestOpenAIHandlerStreaming.test_stream_response of <tests.llms.test_openai_handler.TestOpenAIHandlerStreaming testMethod=test_stream_response>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestTogetherClientStreaming.test_perform_stream_request_failure' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestTogetherClientStreaming.test_perform_stream_request_failure of <tests.llms.test_together_client.TestTogetherClientStreaming testMethod=test_perform_stream_request_failure>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestTogetherClientStreaming.test_perform_stream_request_success' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestTogetherClientStreaming.test_perform_stream_request_success of <tests.llms.test_together_client.TestTogetherClientStreaming testMethod=test_perform_stream_request_success>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    },
    {
      "message": "coroutine 'TestTogetherHandlerStreaming.test_stream_response' was never awaited",
      "category": "RuntimeWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 589
    },
    {
      "message": "It is deprecated to return a value that is not None from a test case (<bound method TestTogetherHandlerStreaming.test_stream_response of <tests.llms.test_together_handler.TestTogetherHandlerStreaming testMethod=test_stream_response>>)",
      "category": "DeprecationWarning",
      "when": "runtest",
      "filename": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
      "lineno": 690
    }
  ]
}