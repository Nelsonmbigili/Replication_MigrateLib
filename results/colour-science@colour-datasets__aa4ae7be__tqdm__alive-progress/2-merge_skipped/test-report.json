{
  "exitcode": 1,
  "summary": {
    "passed": 68,
    "failed": 39,
    "total": 107,
    "collected": 107
  },
  "collectors": [
    {
      "nodeid": "",
      "outcome": "passed",
      "result": [
        {
          "nodeid": ".",
          "type": "Dir"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/examples",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "colour_datasets/loaders/tests/resources",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_abstract.py::TestAbstractDatasetLoader",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_abstract.py::TestAbstractDatasetLoader::test_required_attributes",
          "type": "Function",
          "lineno": 22
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_abstract.py::TestAbstractDatasetLoader::test_required_methods",
          "type": "Function",
          "lineno": 30
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_abstract.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_abstract.py::TestAbstractDatasetLoader",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015::test_required_attributes",
          "type": "Function",
          "lineno": 27
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015::test_required_methods",
          "type": "Function",
          "lineno": 35
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015::test_load",
          "type": "Function",
          "lineno": 43
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestBuildAsano2015",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestBuildAsano2015::test_build_Asano2015",
          "type": "Function",
          "lineno": 135
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_asano2015.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestBuildAsano2015",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020::test_required_attributes",
          "type": "Function",
          "lineno": 31
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020::test_required_methods",
          "type": "Function",
          "lineno": 39
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020::test_load",
          "type": "Function",
          "lineno": 47
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestBuildBrendel2020",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestBuildBrendel2020::test_build_Brendel2020",
          "type": "Function",
          "lineno": 68
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestBuildBrendel2020",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017::test_required_attributes",
          "type": "Function",
          "lineno": 26
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017::test_required_methods",
          "type": "Function",
          "lineno": 34
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017::test_load",
          "type": "Function",
          "lineno": 42
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestBuildDyer2017",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestBuildDyer2017::test_build_Dyer2017",
          "type": "Function",
          "lineno": 289
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestBuildDyer2017",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998::test_required_attributes",
          "type": "Function",
          "lineno": 26
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998::test_required_methods",
          "type": "Function",
          "lineno": 34
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998::test_load",
          "type": "Function",
          "lineno": 42
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestBuildEbner1998",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestBuildEbner1998::test_build_Ebner1998",
          "type": "Function",
          "lineno": 127
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestBuildEbner1998",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995::test_required_attributes",
          "type": "Function",
          "lineno": 26
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995::test_required_methods",
          "type": "Function",
          "lineno": 34
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995::test_load",
          "type": "Function",
          "lineno": 42
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestBuildHung1995",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestBuildHung1995::test_build_Hung1995",
          "type": "Function",
          "lineno": 114
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_hung1995.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestBuildHung1995",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019::test_required_attributes",
          "type": "Function",
          "lineno": 23
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019::test_required_methods",
          "type": "Function",
          "lineno": 31
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019::test_load",
          "type": "Function",
          "lineno": 39
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestBuildJakob2019",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestBuildJakob2019::test_build_Jakob2019",
          "type": "Function",
          "lineno": 60
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestBuildJakob2019",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013::test_required_attributes",
          "type": "Function",
          "lineno": 25
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013::test_required_methods",
          "type": "Function",
          "lineno": 33
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013::test_load",
          "type": "Function",
          "lineno": 41
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestBuildJiang2013",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestBuildJiang2013::test_build_Jiang2013",
          "type": "Function",
          "lineno": 87
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestBuildJiang2013",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015::test_required_attributes",
          "type": "Function",
          "lineno": 25
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015::test_required_methods",
          "type": "Function",
          "lineno": 33
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015::test_load",
          "type": "Function",
          "lineno": 41
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestBuildKarge2015",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestBuildKarge2015::test_build_Karge2015",
          "type": "Function",
          "lineno": 68
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_karge2015.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestBuildKarge2015",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestReadSdsFromMatFileKuopioUniversity",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestReadSdsFromMatFileKuopioUniversity::test_read_sds_from_mat_file_KuopioUniversity",
          "type": "Function",
          "lineno": 44
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity::test_required_attributes",
          "type": "Function",
          "lineno": 107
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity::test_required_methods",
          "type": "Function",
          "lineno": 125
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity::test_load",
          "type": "Function",
          "lineno": 143
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_kuopio.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestReadSdsFromMatFileKuopioUniversity",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019::test_required_attributes",
          "type": "Function",
          "lineno": 31
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019::test_required_methods",
          "type": "Function",
          "lineno": 39
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019::test_load",
          "type": "Function",
          "lineno": 47
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestBuildLabsphere2019",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestBuildLabsphere2019::test_build_Labsphere2019",
          "type": "Function",
          "lineno": 66
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestBuildLabsphere2019",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997::test_required_attributes",
          "type": "Function",
          "lineno": 26
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997::test_required_methods",
          "type": "Function",
          "lineno": 34
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997::test_load",
          "type": "Function",
          "lineno": 42
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestBuildLuo1997",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestBuildLuo1997::test_build_Luo1997",
          "type": "Function",
          "lineno": 177
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1997.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestBuildLuo1997",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999::test_required_attributes",
          "type": "Function",
          "lineno": 26
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999::test_required_methods",
          "type": "Function",
          "lineno": 34
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999::test_load",
          "type": "Function",
          "lineno": 42
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestBuildLuo1999",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestBuildLuo1999::test_build_Luo1999",
          "type": "Function",
          "lineno": 160
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1999.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestBuildLuo1999",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023::test_required_attributes",
          "type": "Function",
          "lineno": 28
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023::test_required_methods",
          "type": "Function",
          "lineno": 36
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023::test_load",
          "type": "Function",
          "lineno": 44
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestBuildSolomotav2023",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestBuildSolomotav2023::test_build_Solomotav2023",
          "type": "Function",
          "lineno": 64
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestBuildSolomotav2023",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022::test_required_attributes",
          "type": "Function",
          "lineno": 33
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022::test_required_methods",
          "type": "Function",
          "lineno": 41
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022::test_load",
          "type": "Function",
          "lineno": 49
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestBuildWinquist2022",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestBuildWinquist2022::test_build_Winquist2022",
          "type": "Function",
          "lineno": 72
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestBuildWinquist2022",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016::test_required_attributes",
          "type": "Function",
          "lineno": 25
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016::test_required_methods",
          "type": "Function",
          "lineno": 33
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016::test_load",
          "type": "Function",
          "lineno": 41
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestBuildXRite2016",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestBuildXRite2016::test_build_XRite2016",
          "type": "Function",
          "lineno": 68
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestBuildXRite2016",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009::test_required_attributes",
          "type": "Function",
          "lineno": 25
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009::test_required_methods",
          "type": "Function",
          "lineno": 33
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009::test_load",
          "type": "Function",
          "lineno": 41
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestBuildZhao2009",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestBuildZhao2009::test_build_Zhao2009",
          "type": "Function",
          "lineno": 73
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestBuildZhao2009",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders/tests",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests/resources",
          "type": "Dir"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_abstract.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_asano2015.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_hung1995.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_karge2015.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_kuopio.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1997.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_luo1999.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py",
          "type": "Module"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/loaders",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/loaders/tests",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records/tests/test_configuration.py::TestUseSandbox",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests/test_configuration.py::TestUseSandbox::test_use_sandbox",
          "type": "Function",
          "lineno": 31
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records/tests/test_configuration.py::TestSandbox",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests/test_configuration.py::TestSandbox::test_sandbox",
          "type": "Function",
          "lineno": 49
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records/tests/test_configuration.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests/test_configuration.py::TestUseSandbox",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/records/tests/test_configuration.py::TestSandbox",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test__init__",
          "type": "TestCaseFunction",
          "lineno": 109
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test__repr__",
          "type": "TestCaseFunction",
          "lineno": 168
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test__str__",
          "type": "TestCaseFunction",
          "lineno": 121
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_configuration",
          "type": "TestCaseFunction",
          "lineno": 69
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_data",
          "type": "TestCaseFunction",
          "lineno": 77
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_from_id",
          "type": "TestCaseFunction",
          "lineno": 182
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_id",
          "type": "TestCaseFunction",
          "lineno": 93
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_pull",
          "type": "TestCaseFunction",
          "lineno": 201
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_remove",
          "type": "TestCaseFunction",
          "lineno": 208
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_repository",
          "type": "TestCaseFunction",
          "lineno": 82
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_required_attributes",
          "type": "TestCaseFunction",
          "lineno": 39
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_required_methods",
          "type": "TestCaseFunction",
          "lineno": 53
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_synced",
          "type": "TestCaseFunction",
          "lineno": 193
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_title",
          "type": "TestCaseFunction",
          "lineno": 98
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__getitem__",
          "type": "TestCaseFunction",
          "lineno": 355
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__init__",
          "type": "TestCaseFunction",
          "lineno": 300
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__iter__",
          "type": "TestCaseFunction",
          "lineno": 363
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__len__",
          "type": "TestCaseFunction",
          "lineno": 371
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__repr__",
          "type": "TestCaseFunction",
          "lineno": 341
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__str__",
          "type": "TestCaseFunction",
          "lineno": 312
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_configuration",
          "type": "TestCaseFunction",
          "lineno": 270
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_data",
          "type": "TestCaseFunction",
          "lineno": 278
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_from_id",
          "type": "TestCaseFunction",
          "lineno": 379
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_pull",
          "type": "TestCaseFunction",
          "lineno": 402
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_records",
          "type": "TestCaseFunction",
          "lineno": 293
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_remove",
          "type": "TestCaseFunction",
          "lineno": 411
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_repository",
          "type": "TestCaseFunction",
          "lineno": 285
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_required_attributes",
          "type": "TestCaseFunction",
          "lineno": 238
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_required_methods",
          "type": "TestCaseFunction",
          "lineno": 251
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_synced",
          "type": "TestCaseFunction",
          "lineno": 392
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord",
          "type": "UnitTestCase"
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records/tests",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests/test_configuration.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/records/tests/test_zenodo.py",
          "type": "Module"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/records",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/records/tests",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/resources",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestHashMd5",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestHashMd5::test_hash_md5",
          "type": "Function",
          "lineno": 37
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUrlDownload",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUrlDownload::test_url_download",
          "type": "Function",
          "lineno": 75
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestJsonOpen",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestJsonOpen::test_json_open",
          "type": "Function",
          "lineno": 120
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUnpackGzipfile",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUnpackGzipfile::test_unpack_gzipfile",
          "type": "Function",
          "lineno": 146
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestHashMd5",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUrlDownload",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestJsonOpen",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUnpackGzipfile",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestRowToIndex",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestRowToIndex::test_row_to_index",
          "type": "Function",
          "lineno": 40
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToRow",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToRow::test_index_to_row",
          "type": "Function",
          "lineno": 61
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestColumnToIndex",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestColumnToIndex::test_column_to_index",
          "type": "Function",
          "lineno": 80
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToColumn",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToColumn::test_index_to_column",
          "type": "Function",
          "lineno": 101
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestCellRangeValues",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestCellRangeValues::test_cell_range_values",
          "type": "Function",
          "lineno": 120
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestRowToIndex",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToRow",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestColumnToIndex",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToColumn",
          "type": "Class"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestCellRangeValues",
          "type": "Class"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities/tests",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests/resources",
          "type": "Dir"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_common.py",
          "type": "Module"
        },
        {
          "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py",
          "type": "Module"
        }
      ]
    },
    {
      "nodeid": "colour_datasets/utilities",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/utilities/tests",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": "colour_datasets",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets/examples",
          "type": "Dir"
        },
        {
          "nodeid": "colour_datasets/loaders",
          "type": "Package"
        },
        {
          "nodeid": "colour_datasets/records",
          "type": "Package"
        },
        {
          "nodeid": "colour_datasets/utilities",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": "docs/_static",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "docs/_templates",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "docs",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "docs/_static",
          "type": "Dir"
        },
        {
          "nodeid": "docs/_templates",
          "type": "Dir"
        }
      ]
    },
    {
      "nodeid": "utilities",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": ".",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "colour_datasets",
          "type": "Package"
        },
        {
          "nodeid": "docs",
          "type": "Dir"
        },
        {
          "nodeid": "utilities",
          "type": "Dir"
        }
      ]
    }
  ],
  "tests": [
    {
      "nodeid": "colour_datasets/loaders/tests/test_abstract.py::TestAbstractDatasetLoader::test_required_attributes",
      "lineno": 22,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestAbstractDatasetLoader",
        "test_abstract.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_abstract.py::TestAbstractDatasetLoader::test_required_methods",
      "lineno": 30,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestAbstractDatasetLoader",
        "test_abstract.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015::test_required_attributes",
      "lineno": 27,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Asano2015",
        "test_asano2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015::test_required_methods",
      "lineno": 35,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Asano2015",
        "test_asano2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestDatasetLoader_Asano2015::test_load",
      "lineno": 43,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Asano2015",
        "test_asano2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_asano2015.py",
            "lineno": 51,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\asano2015.py",
            "lineno": 133,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Observer Function Database - Asano (2015)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/3 [0%] in 0.2s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_asano2015.TestDatasetLoader_Asano2015 object at 0x000001AD84B656A0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.asano2015.\\\n    DatasetLoader_Asano2015.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Asano2015()\n>           assert sorted(dataset.load().keys()) == [\n                \"Categorical Observers\",\n                \"Colour Normal Observers\",\n            ]\n\ncolour_datasets\\loaders\\tests\\test_asano2015.py:51: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\asano2015.py:133: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86257560>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86244140>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86254...ocals>.inner at 0x000001AD86254EA0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86255440>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_asano2015.py::TestBuildAsano2015::test_build_Asano2015",
      "lineno": 135,
      "outcome": "failed",
      "keywords": [
        "test_build_Asano2015",
        "TestBuildAsano2015",
        "test_asano2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_asano2015.py",
            "lineno": 142,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\asano2015.py",
            "lineno": 317,
            "message": "in build_Asano2015"
          },
          {
            "path": "colour_datasets\\loaders\\asano2015.py",
            "lineno": 133,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Observer Function Database - Asano (2015)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/3 [0%] in 0.2s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_asano2015.TestBuildAsano2015 object at 0x000001AD84B65370>\n\n    def test_build_Asano2015(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.asano2015.build_Asano2015`\n        definition.\n        \"\"\"\n    \n>       assert build_Asano2015() is build_Asano2015()\n\ncolour_datasets\\loaders\\tests\\test_asano2015.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\asano2015.py:317: in build_Asano2015\n    _DATASET_LOADER_ASANO2015.load()\ncolour_datasets\\loaders\\asano2015.py:133: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD862C9DA0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD865CAA40>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86339...ocals>.inner at 0x000001AD86339A80>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86339760>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020::test_required_attributes",
      "lineno": 31,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Brendel2020",
        "test_brendel2020.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020::test_required_methods",
      "lineno": 39,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Brendel2020",
        "test_brendel2020.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestDatasetLoader_Brendel2020::test_load",
      "lineno": 47,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Brendel2020",
        "test_brendel2020.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py",
          "lineno": 262,
          "message": "FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets\\\\4051012\\\\downloads\\\\urls.txt'"
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_brendel2020.py",
            "lineno": 56,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\brendel2020.py",
            "lineno": 91,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 412,
            "message": "in pull"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py",
            "lineno": 262,
            "message": "FileNotFoundError"
          }
        ],
        "stdout": "Pulling \"Measured Commercial LED Spectra - Brendel (2020)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_brendel2020.TestDatasetLoader_Brendel2020 object at 0x000001AD84B647D0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.brendel2020.\\\n    DatasetLoader_Brendel2020.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Brendel2020()\n    \n>           assert len(dataset.load()) == 29\n\ncolour_datasets\\loaders\\tests\\test_brendel2020.py:56: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\brendel2020.py:91: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:412: in pull\n    shutil.copyfile(\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nsrc = 'C:\\\\Users\\\\Mohay\\\\AppData\\\\Local\\\\Temp\\\\tmpy_bdxvwn'\ndst = 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets\\\\4051012\\\\downloads\\\\urls.txt'\n\n    def copyfile(src, dst, *, follow_symlinks=True):\n        \"\"\"Copy data from src to dst in the most efficient way possible.\n    \n        If follow_symlinks is not set and src is a symbolic link, a new\n        symlink will be created instead of copying the file it points to.\n    \n        \"\"\"\n        sys.audit(\"shutil.copyfile\", src, dst)\n    \n        if _samefile(src, dst):\n            raise SameFileError(\"{!r} and {!r} are the same file\".format(src, dst))\n    \n        file_size = 0\n        for i, fn in enumerate([src, dst]):\n            try:\n                st = _stat(fn)\n            except OSError:\n                # File most likely does not exist\n                pass\n            else:\n                # XXX What about other special files? (sockets, devices...)\n                if stat.S_ISFIFO(st.st_mode):\n                    fn = fn.path if isinstance(fn, os.DirEntry) else fn\n                    raise SpecialFileError(\"`%s` is a named pipe\" % fn)\n                if _WINDOWS and i == 0:\n                    file_size = st.st_size\n    \n        if not follow_symlinks and _islink(src):\n            os.symlink(os.readlink(src), dst)\n        else:\n            with open(src, 'rb') as fsrc:\n                try:\n>                   with open(dst, 'wb') as fdst:\nE                   FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets\\\\4051012\\\\downloads\\\\urls.txt'\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\shutil.py:262: FileNotFoundError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_brendel2020.py::TestBuildBrendel2020::test_build_Brendel2020",
      "lineno": 68,
      "outcome": "failed",
      "keywords": [
        "test_build_Brendel2020",
        "TestBuildBrendel2020",
        "test_brendel2020.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_brendel2020.py",
            "lineno": 75,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\brendel2020.py",
            "lineno": 145,
            "message": "in build_Brendel2020"
          },
          {
            "path": "colour_datasets\\loaders\\brendel2020.py",
            "lineno": 91,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Measured Commercial LED Spectra - Brendel (2020)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4051012/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.6s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_brendel2020.TestBuildBrendel2020 object at 0x000001AD84B64470>\n\n    def test_build_Brendel2020(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.brendel2020.build_Brendel2020`\n        definition.\n        \"\"\"\n    \n>       assert build_Brendel2020() is build_Brendel2020()\n\ncolour_datasets\\loaders\\tests\\test_brendel2020.py:75: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\brendel2020.py:145: in build_Brendel2020\n    _DATASET_LOADER_BRENDEL2020.load()\ncolour_datasets\\loaders\\brendel2020.py:91: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD8633AA20>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD865DB440>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86398...ocals>.inner at 0x000001AD86398180>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD8633BE20>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017::test_required_attributes",
      "lineno": 26,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Dyer2017",
        "test_dyer2017.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017::test_required_methods",
      "lineno": 34,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Dyer2017",
        "test_dyer2017.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestDatasetLoader_Dyer2017::test_load",
      "lineno": 42,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Dyer2017",
        "test_dyer2017.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_dyer2017.py",
            "lineno": 50,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\dyer2017.py",
            "lineno": 1513,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"RAW to ACES Utility Data - Dyer et al. (2017)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3372170',\n     'conceptrecid': '3372170',\n     'created': '2019-08-20T08:38...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_dyer2017.TestDatasetLoader_Dyer2017 object at 0x000001AD84B660F0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.dyer2017.DatasetLoader_Dyer2017.\\\n    load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Dyer2017()\n>           assert sorted(dataset.load().keys()) == [\n                \"camera\",\n                \"cmf\",\n                \"illuminant\",\n                \"training\",\n            ]\n\ncolour_datasets\\loaders\\tests\\test_dyer2017.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\dyer2017.py:1513: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD8633B560>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD865328C0>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86399...ocals>.inner at 0x000001AD86399440>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86399120>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_dyer2017.py::TestBuildDyer2017::test_build_Dyer2017",
      "lineno": 289,
      "outcome": "failed",
      "keywords": [
        "test_build_Dyer2017",
        "TestBuildDyer2017",
        "test_dyer2017.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_dyer2017.py",
            "lineno": 296,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\dyer2017.py",
            "lineno": 1567,
            "message": "in build_Dyer2017"
          },
          {
            "path": "colour_datasets\\loaders\\dyer2017.py",
            "lineno": 1513,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"RAW to ACES Utility Data - Dyer et al. (2017)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3372170',\n     'conceptrecid': '3372170',\n     'created': '2019-08-20T08:38...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_dyer2017.TestBuildDyer2017 object at 0x000001AD84B65EE0>\n\n    def test_build_Dyer2017(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.dyer2017.build_Dyer2017`\n        definition.\n        \"\"\"\n    \n>       assert build_Dyer2017() is build_Dyer2017()\n\ncolour_datasets\\loaders\\tests\\test_dyer2017.py:296: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\dyer2017.py:1567: in build_Dyer2017\n    _DATASET_LOADER_DYER2017.load()\ncolour_datasets\\loaders\\dyer2017.py:1513: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD863747C0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86675E00>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86375...ocals>.inner at 0x000001AD863754E0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD863751C0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998::test_required_attributes",
      "lineno": 26,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Ebner1998",
        "test_ebner1998.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998::test_required_methods",
      "lineno": 34,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Ebner1998",
        "test_ebner1998.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestDatasetLoader_Ebner1998::test_load",
      "lineno": 42,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Ebner1998",
        "test_ebner1998.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_ebner1998.py",
            "lineno": 50,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\ebner1998.py",
            "lineno": 135,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Constant Perceived-Hue Data - Ebner and Fairchild (1998)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3362536\\downloads\\Ebner_Constant_Hue_Data.txt\" file during attempt 1, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3362536\\downloads\\Ebner_Constant_Hue_Data.txt\" file during attempt 2, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3362536\\downloads\\Ebner_Constant_Hue_Data.txt\" file during attempt 3, retrying...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3362535',\n     'conceptrecid': '3362535',\n     'created': '2019-08-07T19:28...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n>               urls_download(urls)\n\ncolour_datasets\\records\\zenodo.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:182: in url_download\n    with urllib.request.urlopen(url) as response:  # noqa: S310\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215: in urlopen\n    return opener.open(url, data, timeout)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521: in open\n    response = meth(req, response)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630: in http_response\n    response = self.parent.error(\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559: in error\n    return self._call_chain(*args)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x000001AD84CB4BC0>\nreq = <urllib.request.Request object at 0x000001AD8632E210>\nfp = <http.client.HTTPResponse object at 0x000001AD8632DA50>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x000001AD8632D910>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_ebner1998.TestDatasetLoader_Ebner1998 object at 0x000001AD84B66CF0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.ebner1998.\\\n    DatasetLoader_Ebner1998.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Ebner1998()\n>           assert sorted(dataset.load().keys()) == [\"Constant Perceived-Hue Data\"]\n\ncolour_datasets\\loaders\\tests\\test_ebner1998.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\ebner1998.py:135: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86374FE0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD867189C0>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD8639A...ocals>.inner at 0x000001AD8639B4C0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD8639BA60>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_ebner1998.py::TestBuildEbner1998::test_build_Ebner1998",
      "lineno": 127,
      "outcome": "failed",
      "keywords": [
        "test_build_Ebner1998",
        "TestBuildEbner1998",
        "test_ebner1998.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_ebner1998.py",
            "lineno": 134,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\ebner1998.py",
            "lineno": 210,
            "message": "in build_Ebner1998"
          },
          {
            "path": "colour_datasets\\loaders\\ebner1998.py",
            "lineno": 135,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Constant Perceived-Hue Data - Ebner and Fairchild (1998)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3362536/files/urls.txt/content\" url \non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3362536\\downloads\\Ebner_Constant_Hue_Data.txt\" file during attempt 1, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3362536\\downloads\\Ebner_Constant_Hue_Data.txt\" file during attempt 2, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3362536\\downloads\\Ebner_Constant_Hue_Data.txt\" file during attempt 3, retrying...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3362535',\n     'conceptrecid': '3362535',\n     'created': '2019-08-07T19:28...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n>               urls_download(urls)\n\ncolour_datasets\\records\\zenodo.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:182: in url_download\n    with urllib.request.urlopen(url) as response:  # noqa: S310\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215: in urlopen\n    return opener.open(url, data, timeout)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521: in open\n    response = meth(req, response)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630: in http_response\n    response = self.parent.error(\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559: in error\n    return self._call_chain(*args)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x000001AD84CB4BC0>\nreq = <urllib.request.Request object at 0x000001AD86319280>\nfp = <http.client.HTTPResponse object at 0x000001AD8631A7A0>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x000001AD86318B00>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_ebner1998.TestBuildEbner1998 object at 0x000001AD84B67080>\n\n    def test_build_Ebner1998(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.ebner1998.build_Ebner1998`\n        definition.\n        \"\"\"\n    \n>       assert build_Ebner1998() is build_Ebner1998()\n\ncolour_datasets\\loaders\\tests\\test_ebner1998.py:134: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\ebner1998.py:210: in build_Ebner1998\n    _DATASET_LOADER_EBNER1998.load()\ncolour_datasets\\loaders\\ebner1998.py:135: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD863A2DE0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8672EB00>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD8639B...ocals>.inner at 0x000001AD8639BE20>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD8639B560>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995::test_required_attributes",
      "lineno": 26,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Hung1995",
        "test_hung1995.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995::test_required_methods",
      "lineno": 34,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Hung1995",
        "test_hung1995.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestDatasetLoader_Hung1995::test_load",
      "lineno": 42,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Hung1995",
        "test_hung1995.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_hung1995.py",
            "lineno": 50,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\hung1995.py",
            "lineno": 134,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Constant Hue Loci Data - Hung and Berns (1995)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/4 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3367462',\n     'conceptrecid': '3367462',\n     'created': '2019-08-13T18:32...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_hung1995.TestDatasetLoader_Hung1995 object at 0x000001AD84B67CE0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.hung1995.DatasetLoader_Hung1995.\\\n    load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Hung1995()\n>           assert list(dataset.load().keys()) == [\n                \"Table I\",\n                \"Table II\",\n                \"Table III\",\n                \"Table IV\",\n                \"Constant Hue Loci Data - CL\",\n                \"Constant Hue Loci Data - VL\",\n            ]\n\ncolour_datasets\\loaders\\tests\\test_hung1995.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\hung1995.py:134: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD862DD580>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86546280>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD862DE...ocals>.inner at 0x000001AD862DE840>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD862DE520>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_hung1995.py::TestBuildHung1995::test_build_Hung1995",
      "lineno": 114,
      "outcome": "failed",
      "keywords": [
        "test_build_Hung1995",
        "TestBuildHung1995",
        "test_hung1995.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_hung1995.py",
            "lineno": 121,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\hung1995.py",
            "lineno": 241,
            "message": "in build_Hung1995"
          },
          {
            "path": "colour_datasets\\loaders\\hung1995.py",
            "lineno": 134,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Constant Hue Loci Data - Hung and Berns (1995)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/4 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3367462',\n     'conceptrecid': '3367462',\n     'created': '2019-08-13T18:32...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_hung1995.TestBuildHung1995 object at 0x000001AD84BD00B0>\n\n    def test_build_Hung1995(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.hung1995.build_Hung1995`\n        definition.\n        \"\"\"\n    \n>       assert build_Hung1995() is build_Hung1995()\n\ncolour_datasets\\loaders\\tests\\test_hung1995.py:121: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\hung1995.py:241: in build_Hung1995\n    _DATASET_LOADER_HUNG1995.load()\ncolour_datasets\\loaders\\hung1995.py:134: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86651C60>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8678AE40>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86652...ocals>.inner at 0x000001AD86652980>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86652660>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019::test_required_attributes",
      "lineno": 23,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Jakob2019",
        "test_jakob2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019::test_required_methods",
      "lineno": 31,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Jakob2019",
        "test_jakob2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestDatasetLoader_Jakob2019::test_load",
      "lineno": 39,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Jakob2019",
        "test_jakob2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_jakob2019.py",
            "lineno": 47,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\jakob2019.py",
            "lineno": 91,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Spectral Upsampling Coefficient Tables - Jakob and Hanika. (2019)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.6s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_jakob2019.TestDatasetLoader_Jakob2019 object at 0x000001AD84BD0800>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.jakob2019.\\\n    DatasetLoader_Jakob2019.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Jakob2019()\n>           assert sorted(dataset.load().keys()) == [\n                \"ACES2065-1\",\n                \"ITU-R BT.2020\",\n                \"ProPhoto RGB\",\n                \"sRGB\",\n            ]\n\ncolour_datasets\\loaders\\tests\\test_jakob2019.py:47: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\jakob2019.py:91: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD8663CCC0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86585F80>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD8663F...ocals>.inner at 0x000001AD8663F1A0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD8663EE80>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jakob2019.py::TestBuildJakob2019::test_build_Jakob2019",
      "lineno": 60,
      "outcome": "failed",
      "keywords": [
        "test_build_Jakob2019",
        "TestBuildJakob2019",
        "test_jakob2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_jakob2019.py",
            "lineno": 67,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\jakob2019.py",
            "lineno": 155,
            "message": "in build_Jakob2019"
          },
          {
            "path": "colour_datasets\\loaders\\jakob2019.py",
            "lineno": 91,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Spectral Upsampling Coefficient Tables - Jakob and Hanika. (2019)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4050598/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.4s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_jakob2019.TestBuildJakob2019 object at 0x000001AD84BD0B90>\n\n    def test_build_Jakob2019(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.jakob2019.build_Jakob2019`\n        definition.\n        \"\"\"\n    \n>       assert build_Jakob2019() is build_Jakob2019()\n\ncolour_datasets\\loaders\\tests\\test_jakob2019.py:67: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\jakob2019.py:155: in build_Jakob2019\n    _DATASET_LOADER_JAKOB2019.load()\ncolour_datasets\\loaders\\jakob2019.py:91: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD866BCD60>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD865AC680>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD866BF...ocals>.inner at 0x000001AD866BEFC0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD866BECA0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013::test_required_attributes",
      "lineno": 25,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Jiang2013",
        "test_jiang2013.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013::test_required_methods",
      "lineno": 33,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Jiang2013",
        "test_jiang2013.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestDatasetLoader_Jiang2013::test_load",
      "lineno": 41,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Jiang2013",
        "test_jiang2013.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_jiang2013.py",
            "lineno": 49,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\jiang2013.py",
            "lineno": 97,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Camera Spectral Sensitivity Database - Jiang et al. (2013)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.0s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_jiang2013.TestDatasetLoader_Jiang2013 object at 0x000001AD84BD1760>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.jiang2013.\\\n    DatasetLoader_Jiang2013.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Jiang2013()\n>           assert sorted(dataset.load().keys()) == [\n                \"Canon 1DMarkIII\",\n                \"Canon 20D\",\n                \"Canon 300D\",\n                \"Canon 40D\",\n                \"Canon 500D\",\n                \"Canon 50D\",\n                \"Canon 5DMarkII\",\n                \"Canon 600D\",\n                \"Canon 60D\",\n                \"Hasselblad H2\",\n                \"Nikon D200\",\n                \"Nikon D3\",\n                \"Nikon D300s\",\n                \"Nikon D3X\",\n                \"Nikon D40\",\n                \"Nikon D50\",\n                \"Nikon D5100\",\n                \"Nikon D700\",\n                \"Nikon D80\",\n                \"Nikon D90\",\n                \"Nokia N900\",\n                \"Olympus E-PL2\",\n                \"Pentax K-5\",\n                \"Pentax Q\",\n                \"Phase One\",\n                \"Point Grey Grasshopper 50S5C\",\n                \"Point Grey Grasshopper2 14S5C\",\n                \"SONY NEX-5N\",\n            ]\n\ncolour_datasets\\loaders\\tests\\test_jiang2013.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\jiang2013.py:97: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD864A09A0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD866EE500>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD864A1...ocals>.inner at 0x000001AD864A16C0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD864A1300>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_jiang2013.py::TestBuildJiang2013::test_build_Jiang2013",
      "lineno": 87,
      "outcome": "failed",
      "keywords": [
        "test_build_Jiang2013",
        "TestBuildJiang2013",
        "test_jiang2013.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_jiang2013.py",
            "lineno": 94,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\jiang2013.py",
            "lineno": 161,
            "message": "in build_Jiang2013"
          },
          {
            "path": "colour_datasets\\loaders\\jiang2013.py",
            "lineno": 97,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Camera Spectral Sensitivity Database - Jiang et al. (2013)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.0s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_jiang2013.TestBuildJiang2013 object at 0x000001AD84BD1AF0>\n\n    def test_build_Jiang2013(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.jiang2013.build_Jiang2013`\n        definition.\n        \"\"\"\n    \n>       assert build_Jiang2013() is build_Jiang2013()\n\ncolour_datasets\\loaders\\tests\\test_jiang2013.py:94: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\jiang2013.py:161: in build_Jiang2013\n    _DATASET_LOADER_JIANG2013.load()\ncolour_datasets\\loaders\\jiang2013.py:97: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD866BCCC0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86403340>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD866BD...ocals>.inner at 0x000001AD866BC540>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD866BE980>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015::test_required_attributes",
      "lineno": 25,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Karge2015",
        "test_karge2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015::test_required_methods",
      "lineno": 33,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Karge2015",
        "test_karge2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestDatasetLoader_Karge2015::test_load",
      "lineno": 41,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Karge2015",
        "test_karge2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_karge2015.py",
            "lineno": 49,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\karge2015.py",
            "lineno": 95,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Spectral Database of Commonly Used Cine Lighting - Karge et al. (2015)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\4642271\\downloads\\OFTP_full-sample-package_v2.zip\" file during attempt 1, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\4642271\\downloads\\OFTP_full-sample-package_v2.zip\" file during attempt 2, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\4642271\\downloads\\OFTP_full-sample-package_v2.zip\" file during attempt 3, retrying...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 1.5s (0.00/s) \nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.4642270',\n     'conceptrecid': '4642270',\n     'created': '2021-03-28T07:26...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n>               urls_download(urls)\n\ncolour_datasets\\records\\zenodo.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:182: in url_download\n    with urllib.request.urlopen(url) as response:  # noqa: S310\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215: in urlopen\n    return opener.open(url, data, timeout)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521: in open\n    response = meth(req, response)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630: in http_response\n    response = self.parent.error(\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559: in error\n    return self._call_chain(*args)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x000001AD84CB4BC0>\nreq = <urllib.request.Request object at 0x000001AD86411040>\nfp = <http.client.HTTPResponse object at 0x000001AD86411A20>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x000001AD864136B0>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_karge2015.TestDatasetLoader_Karge2015 object at 0x000001AD84BD2750>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.karge2015.\\\n    DatasetLoader_Karge2015.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Karge2015()\n>           assert sorted(dataset.load().keys()) == [\n                \"Arri HMI\",\n                \"Arri LED\",\n                \"Arri TU\",\n                \"Bron Kobold FL\",\n                \"Bron Kobold HMI\",\n                \"CMT Kinoflo FL\",\n                \"Dedolight TU\",\n            ]\n\ncolour_datasets\\loaders\\tests\\test_karge2015.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\karge2015.py:95: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD866BCF40>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8652FAC0>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD863F5...ocals>.inner at 0x000001AD863F5260>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD863F4F40>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_karge2015.py::TestBuildKarge2015::test_build_Karge2015",
      "lineno": 68,
      "outcome": "failed",
      "keywords": [
        "test_build_Karge2015",
        "TestBuildKarge2015",
        "test_karge2015.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_karge2015.py",
            "lineno": 75,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\karge2015.py",
            "lineno": 163,
            "message": "in build_Karge2015"
          },
          {
            "path": "colour_datasets\\loaders\\karge2015.py",
            "lineno": 95,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Spectral Database of Commonly Used Cine Lighting - Karge et al. (2015)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4642271/files/urls.txt/content\" url \non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\4642271\\downloads\\OFTP_full-sample-package_v2.zip\" file during attempt 1, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\4642271\\downloads\\OFTP_full-sample-package_v2.zip\" file during attempt 2, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\4642271\\downloads\\OFTP_full-sample-package_v2.zip\" file during attempt 3, retrying...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 1.4s (0.00/s) \nDownloading files |\u26a0\ufe0e                                       | (!) 0/1 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.4642270',\n     'conceptrecid': '4642270',\n     'created': '2021-03-28T07:26...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n>               urls_download(urls)\n\ncolour_datasets\\records\\zenodo.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:182: in url_download\n    with urllib.request.urlopen(url) as response:  # noqa: S310\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215: in urlopen\n    return opener.open(url, data, timeout)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521: in open\n    response = meth(req, response)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630: in http_response\n    response = self.parent.error(\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559: in error\n    return self._call_chain(*args)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x000001AD84CB4BC0>\nreq = <urllib.request.Request object at 0x000001AD863C4DA0>\nfp = <http.client.HTTPResponse object at 0x000001AD863C4550>, code = 404\nmsg = 'Not Found', hdrs = <http.client.HTTPMessage object at 0x000001AD863C4500>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 404: Not Found\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_karge2015.TestBuildKarge2015 object at 0x000001AD84BD16A0>\n\n    def test_build_Karge2015(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.karge2015.build_Karge2015`\n        definition.\n        \"\"\"\n    \n>       assert build_Karge2015() is build_Karge2015()\n\ncolour_datasets\\loaders\\tests\\test_karge2015.py:75: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\karge2015.py:163: in build_Karge2015\n    _DATASET_LOADER_KARGE2015.load()\ncolour_datasets\\loaders\\karge2015.py:95: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD863F5EE0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD863CCF80>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86492...ocals>.inner at 0x000001AD86492CA0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86492980>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestReadSdsFromMatFileKuopioUniversity::test_read_sds_from_mat_file_KuopioUniversity",
      "lineno": 44,
      "outcome": "passed",
      "keywords": [
        "test_read_sds_from_mat_file_KuopioUniversity",
        "TestReadSdsFromMatFileKuopioUniversity",
        "test_kuopio.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity::test_required_attributes",
      "lineno": 107,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_KuopioUniversity",
        "test_kuopio.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity::test_required_methods",
      "lineno": 125,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_KuopioUniversity",
        "test_kuopio.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_kuopio.py::TestDatasetLoader_KuopioUniversity::test_load",
      "lineno": 143,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_KuopioUniversity",
        "test_kuopio.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_kuopio.py",
            "lineno": 3615,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\kuopio.py",
            "lineno": 186,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Munsell Colors Matt (Spectrofotometer Measured) - Hauta-Kasari (n.d.)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3269912/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3269912/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3269912/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3269912/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3269912/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3269912/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/3 [0%] in 0.4s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_kuopio.TestDatasetLoader_KuopioUniversity object at 0x000001AD84BD33E0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.kuopio.\\\n    DatasetLoader_KuopioUniversity.load` method.\n            \"\"\"\n    \n            dataset_loaders = {\n                DatasetLoader_MunsellColorsMattSpectrofotometerMeasured(): (\n                    \"munsell\",\n                    1269,\n                    \"2.5R 5/2\",\n                    np.array(\n                        [\n                            0.105600000000000,\n                            0.114100000000000,\n                            0.117000000000000,\n                            0.119000000000000,\n                            0.121900000000000,\n                            0.124600000000000,\n                            0.127100000000000,\n                            0.135200000000000,\n                            0.137100000000000,\n                            0.141900000000000,\n                            0.151300000000000,\n                            0.155800000000000,\n                            0.154900000000000,\n                            0.162200000000000,\n                            0.166000000000000,\n                            0.168700000000000,\n                            0.173300000000000,\n                            0.174400000000000,\n                            0.173900000000000,\n                            0.179700000000000,\n                            0.182200000000000,\n                            0.183900000000000,\n                            0.185500000000000,\n                            0.184600000000000,\n                            0.184800000000000,\n                            0.187700000000000,\n                            0.184600000000000,\n                            0.183700000000000,\n                            0.187600000000000,\n                            0.186500000000000,\n                            0.183200000000000,\n                            0.185800000000000,\n                            0.184400000000000,\n                            0.181300000000000,\n                            0.183800000000000,\n                            0.181800000000000,\n                            0.179500000000000,\n                            0.181900000000000,\n                            0.180200000000000,\n                            0.178600000000000,\n                            0.179600000000000,\n                            0.176300000000000,\n                            0.176300000000000,\n                            0.178100000000000,\n                            0.175100000000000,\n                            0.174000000000000,\n                            0.176300000000000,\n                            0.173400000000000,\n                            0.173800000000000,\n                            0.175500000000000,\n                            0.171100000000000,\n                            0.170600000000000,\n                            0.174300000000000,\n                            0.171800000000000,\n                            0.170600000000000,\n                            0.172800000000000,\n                            0.172300000000000,\n                            0.171200000000000,\n                            0.170900000000000,\n                            0.169300000000000,\n                            0.172000000000000,\n                            0.175300000000000,\n                            0.171500000000000,\n                            0.169500000000000,\n                            0.170800000000000,\n                            0.167100000000000,\n                            0.167700000000000,\n                            0.170100000000000,\n                            0.165600000000000,\n                            0.164800000000000,\n                            0.167500000000000,\n                            0.164600000000000,\n                            0.162500000000000,\n                            0.165500000000000,\n                            0.162500000000000,\n                            0.163400000000000,\n                            0.163600000000000,\n                            0.161500000000000,\n                            0.162400000000000,\n                            0.164500000000000,\n                            0.162200000000000,\n                            0.163900000000000,\n                            0.164900000000000,\n                            0.162200000000000,\n                            0.163600000000000,\n                            0.166100000000000,\n                            0.162900000000000,\n                            0.164700000000000,\n                            0.167400000000000,\n                            0.164800000000000,\n                            0.165200000000000,\n                            0.165400000000000,\n                            0.164400000000000,\n                            0.166300000000000,\n                            0.167600000000000,\n                            0.163800000000000,\n                            0.164400000000000,\n                            0.163600000000000,\n                            0.162100000000000,\n                            0.163800000000000,\n                            0.162900000000000,\n                            0.158600000000000,\n                            0.160300000000000,\n                            0.159100000000000,\n                            0.155300000000000,\n                            0.157200000000000,\n                            0.159000000000000,\n                            0.154100000000000,\n                            0.154500000000000,\n                            0.154600000000000,\n                            0.151100000000000,\n                            0.153700000000000,\n                            0.155000000000000,\n                            0.151200000000000,\n                            0.151100000000000,\n                            0.151300000000000,\n                            0.149300000000000,\n                            0.152000000000000,\n                            0.150700000000000,\n                            0.148400000000000,\n                            0.151300000000000,\n                            0.152600000000000,\n                            0.149000000000000,\n                            0.152200000000000,\n                            0.152700000000000,\n                            0.149700000000000,\n                            0.150800000000000,\n                            0.151100000000000,\n                            0.148300000000000,\n                            0.152100000000000,\n                            0.153100000000000,\n                            0.150900000000000,\n                            0.151100000000000,\n                            0.149300000000000,\n                            0.148500000000000,\n                            0.150900000000000,\n                            0.148300000000000,\n                            0.145300000000000,\n                            0.148100000000000,\n                            0.147000000000000,\n                            0.144900000000000,\n                            0.146600000000000,\n                            0.145300000000000,\n                            0.143100000000000,\n                            0.146300000000000,\n                            0.144400000000000,\n                            0.141000000000000,\n                            0.141200000000000,\n                            0.143700000000000,\n                            0.142000000000000,\n                            0.142900000000000,\n                            0.142400000000000,\n                            0.142700000000000,\n                            0.145400000000000,\n                            0.142900000000000,\n                            0.141300000000000,\n                            0.144500000000000,\n                            0.143700000000000,\n                            0.143400000000000,\n                            0.148600000000000,\n                            0.147500000000000,\n                            0.147000000000000,\n                            0.151300000000000,\n                            0.153100000000000,\n                            0.150800000000000,\n                            0.155800000000000,\n                            0.156400000000000,\n                            0.158100000000000,\n                            0.162700000000000,\n                            0.164600000000000,\n                            0.165200000000000,\n                            0.171900000000000,\n                            0.171900000000000,\n                            0.173600000000000,\n                            0.176300000000000,\n                            0.176800000000000,\n                            0.178200000000000,\n                            0.183400000000000,\n                            0.179800000000000,\n                            0.177500000000000,\n                            0.180400000000000,\n                            0.184800000000000,\n                            0.191700000000000,\n                            0.194900000000000,\n                            0.195100000000000,\n                            0.193100000000000,\n                            0.196400000000000,\n                            0.196700000000000,\n                            0.195900000000000,\n                            0.201000000000000,\n                            0.200100000000000,\n                            0.197400000000000,\n                            0.201200000000000,\n                            0.200500000000000,\n                            0.198200000000000,\n                            0.203900000000000,\n                            0.204700000000000,\n                            0.201900000000000,\n                            0.204000000000000,\n                            0.203800000000000,\n                            0.202000000000000,\n                            0.206200000000000,\n                            0.206600000000000,\n                            0.204200000000000,\n                            0.205500000000000,\n                            0.204700000000000,\n                            0.205100000000000,\n                            0.208300000000000,\n                            0.206300000000000,\n                            0.204100000000000,\n                            0.208100000000000,\n                            0.206600000000000,\n                            0.203300000000000,\n                            0.206400000000000,\n                            0.206400000000000,\n                            0.203900000000000,\n                            0.206100000000000,\n                            0.205400000000000,\n                            0.202700000000000,\n                            0.204600000000000,\n                            0.205300000000000,\n                            0.204700000000000,\n                            0.205800000000000,\n                            0.204600000000000,\n                            0.204000000000000,\n                            0.206900000000000,\n                            0.203500000000000,\n                            0.202900000000000,\n                            0.207000000000000,\n                            0.206200000000000,\n                            0.203400000000000,\n                            0.206500000000000,\n                            0.205500000000000,\n                            0.204300000000000,\n                            0.207100000000000,\n                            0.205100000000000,\n                            0.202300000000000,\n                            0.205000000000000,\n                            0.204100000000000,\n                            0.203900000000000,\n                            0.205800000000000,\n                            0.203500000000000,\n                            0.203800000000000,\n                            0.205800000000000,\n                            0.203200000000000,\n                            0.201200000000000,\n                            0.203700000000000,\n                            0.200600000000000,\n                            0.201400000000000,\n                            0.206300000000000,\n                            0.203100000000000,\n                            0.201000000000000,\n                            0.203600000000000,\n                            0.200500000000000,\n                            0.199300000000000,\n                            0.202700000000000,\n                            0.202300000000000,\n                            0.201700000000000,\n                            0.202900000000000,\n                            0.199900000000000,\n                            0.199200000000000,\n                            0.202500000000000,\n                            0.200400000000000,\n                            0.199500000000000,\n                            0.199800000000000,\n                            0.196400000000000,\n                            0.197200000000000,\n                            0.200500000000000,\n                            0.196800000000000,\n                            0.196700000000000,\n                            0.200100000000000,\n                            0.197800000000000,\n                            0.195700000000000,\n                            0.198500000000000,\n                            0.196500000000000,\n                            0.197100000000000,\n                            0.198400000000000,\n                            0.195900000000000,\n                            0.196400000000000,\n                            0.200200000000000,\n                            0.198300000000000,\n                            0.199400000000000,\n                            0.198500000000000,\n                            0.193700000000000,\n                            0.195300000000000,\n                            0.198400000000000,\n                            0.193300000000000,\n                            0.193800000000000,\n                            0.197200000000000,\n                            0.193900000000000,\n                            0.194700000000000,\n                            0.197300000000000,\n                            0.195000000000000,\n                            0.197700000000000,\n                            0.200700000000000,\n                            0.197100000000000,\n                            0.196300000000000,\n                            0.197700000000000,\n                            0.196800000000000,\n                            0.197300000000000,\n                            0.198000000000000,\n                            0.193900000000000,\n                            0.195300000000000,\n                            0.196100000000000,\n                            0.192900000000000,\n                            0.195100000000000,\n                            0.196100000000000,\n                            0.188600000000000,\n                            0.187100000000000,\n                            0.192700000000000,\n                            0.195800000000000,\n                            0.194800000000000,\n                            0.196100000000000,\n                            0.192200000000000,\n                            0.195100000000000,\n                            0.196500000000000,\n                            0.192600000000000,\n                            0.195000000000000,\n                            0.195500000000000,\n                            0.193100000000000,\n                            0.193200000000000,\n                            0.194200000000000,\n                            0.191800000000000,\n                            0.194500000000000,\n                            0.193600000000000,\n                            0.191100000000000,\n                            0.193100000000000,\n                            0.192800000000000,\n                            0.190600000000000,\n                            0.193600000000000,\n                            0.192400000000000,\n                            0.189900000000000,\n                            0.192900000000000,\n                            0.193900000000000,\n                            0.191700000000000,\n                            0.194700000000000,\n                            0.195900000000000,\n                            0.192400000000000,\n                            0.192900000000000,\n                            0.193100000000000,\n                            0.192200000000000,\n                            0.195700000000000,\n                            0.195500000000000,\n                            0.192200000000000,\n                            0.195100000000000,\n                            0.193600000000000,\n                            0.192300000000000,\n                            0.196200000000000,\n                            0.196100000000000,\n                            0.193800000000000,\n                            0.198400000000000,\n                            0.196900000000000,\n                            0.192900000000000,\n                            0.196300000000000,\n                            0.196800000000000,\n                            0.194800000000000,\n                            0.195600000000000,\n                            0.194600000000000,\n                            0.193700000000000,\n                            0.196900000000000,\n                            0.196100000000000,\n                            0.194800000000000,\n                            0.196700000000000,\n                            0.193900000000000,\n                            0.193400000000000,\n                            0.197000000000000,\n                            0.193000000000000,\n                            0.192200000000000,\n                            0.196000000000000,\n                            0.193800000000000,\n                            0.191800000000000,\n                            0.194000000000000,\n                            0.193500000000000,\n                            0.191000000000000,\n                            0.192300000000000,\n                            0.190700000000000,\n                            0.189500000000000,\n                            0.191700000000000,\n                            0.189900000000000,\n                            0.191200000000000,\n                            0.192400000000000,\n                            0.189600000000000,\n                            0.189500000000000,\n                            0.193200000000000,\n                            0.191200000000000,\n                            0.188600000000000,\n                            0.192800000000000,\n                            0.191700000000000,\n                            0.190800000000000,\n                            0.194300000000000,\n                            0.191600000000000,\n                            0.190400000000000,\n                            0.192700000000000,\n                            0.191000000000000,\n                            0.189300000000000,\n                            0.192200000000000,\n                            0.190200000000000,\n                            0.190100000000000,\n                            0.192900000000000,\n                            0.191300000000000,\n                            0.192900000000000,\n                            0.196700000000000,\n                            0.191600000000000,\n                            0.192400000000000,\n                            0.195900000000000,\n                            0.189600000000000,\n                            0.188700000000000,\n                            0.192400000000000,\n                            0.193200000000000,\n                            0.193000000000000,\n                            0.193400000000000,\n                            0.190200000000000,\n                            0.192200000000000,\n                            0.193100000000000,\n                            0.190000000000000,\n                            0.191000000000000,\n                            0.192500000000000,\n                            0.190200000000000,\n                            0.191300000000000,\n                            0.192700000000000,\n                            0.190000000000000,\n                        ]\n                    ),\n                ),\n                DatasetLoader_MunsellColorsMattAOTFMeasured(): (\n                    \"munsell\",\n                    1250,\n                    \"10bV50C01.NM5\",\n                    np.array(\n                        [\n                            0.363525390625000,\n                            0.486328125000000,\n                            0.262451171875000,\n                            0.270263671875000,\n                            0.278076171875000,\n                            0.293945312500000,\n                            0.272705078125000,\n                            0.253417968750000,\n                            0.272216796875000,\n                            0.255859375000000,\n                            0.260498046875000,\n                            0.253906250000000,\n                            0.256591796875000,\n                            0.248535156250000,\n                            0.245849609375000,\n                            0.243408203125000,\n                            0.247802734375000,\n                            0.240234375000000,\n                            0.247314453125000,\n                            0.243164062500000,\n                            0.237548828125000,\n                            0.238525390625000,\n                            0.230957031250000,\n                            0.227050781250000,\n                            0.231689453125000,\n                            0.232421875000000,\n                            0.228027343750000,\n                            0.223876953125000,\n                            0.224853515625000,\n                            0.219726562500000,\n                            0.220703125000000,\n                            0.218994140625000,\n                            0.216552734375000,\n                            0.217529296875000,\n                            0.217041015625000,\n                            0.213134765625000,\n                            0.212402343750000,\n                            0.204833984375000,\n                            0.210205078125000,\n                            0.205810546875000,\n                            0.201416015625000,\n                            0.202392578125000,\n                            0.200439453125000,\n                            0.198730468750000,\n                            0.197998046875000,\n                            0.193359375000000,\n                            0.192871093750000,\n                            0.193115234375000,\n                            0.192626953125000,\n                            0.188476562500000,\n                            0.189208984375000,\n                            0.185058593750000,\n                            0.185546875000000,\n                            0.186035156250000,\n                            0.183349609375000,\n                            0.183105468750000,\n                            0.181884765625000,\n                            0.178222656250000,\n                            0.175292968750000,\n                            0.169921875000000,\n                            0.175048828125000,\n                        ]\n                    ),\n                ),\n                DatasetLoader_MunsellColorsGlossySpectrofotometerMeasured(): (\n                    \"munsell\",\n                    32,\n                    \"5R 5/6\",\n                    np.array(\n                        [\n                            12.660000000000000,\n                            13.540000000000000,\n                            12.990000000000000,\n                            12.260000000000000,\n                            11.910000000000000,\n                            11.580000000000000,\n                            11.360000000000000,\n                            11.430000000000000,\n                            10.910000000000000,\n                            9.8000000000000000,\n                            9.1100000000000000,\n                            9.1400000000000000,\n                            8.5200000000000000,\n                            7.4800000000000000,\n                            8.1600000000000000,\n                            11.190000000000000,\n                            15.190000000000000,\n                            18.460000000000000,\n                            23.560000000000000,\n                            29.770000000000000,\n                            33.250000000000000,\n                            34.400000000000000,\n                            34.540000000000000,\n                            34.350000000000000,\n                            34.200000000000000,\n                            34.050000000000000,\n                            33.800000000000000,\n                            33.560000000000000,\n                            33.290000000000000,\n                            33.080000000000000,\n                            32.910000000000000,\n                        ]\n                    ),\n                ),\n                DatasetLoader_MunsellColorsGlossyAllSpectrofotometerMeasured(): (\n                    \"X\",\n                    1600,\n                    \"5\",\n                    np.array(\n                        [\n                            0.0832583349355893,\n                            0.0841964216140708,\n                            0.0854254747054747,\n                            0.0864870564212114,\n                            0.0885143682165685,\n                            0.0905455902475432,\n                            0.0915811880405238,\n                            0.0935670213290593,\n                            0.0953374607500153,\n                            0.0969212265220306,\n                            0.0988861173336562,\n                            0.1011019151764140,\n                            0.1027070137118110,\n                            0.1045144157706090,\n                            0.1066298320094840,\n                            0.1078871227364190,\n                            0.1097310323760100,\n                            0.1114069239380190,\n                            0.1121451511457540,\n                            0.1134318032825190,\n                            0.1141553695955370,\n                            0.1148042526315790,\n                            0.1151973800818870,\n                            0.1163717178232080,\n                            0.1153836989247310,\n                            0.1163973344056990,\n                            0.1164192531233960,\n                            0.1176007052049480,\n                            0.1185813542341110,\n                            0.1188167084135430,\n                            0.1188947903717930,\n                            0.1194576529747440,\n                            0.1206333985004790,\n                            0.1203924436437340,\n                            0.1212710711071110,\n                            0.1208673887423540,\n                            0.1215377256924970,\n                            0.1218716508912110,\n                            0.1213794497567520,\n                            0.1217316822846940,\n                            0.1216057200200700,\n                            0.1220691362725450,\n                            0.1223934228755990,\n                            0.1226491662040630,\n                            0.1222738901730910,\n                            0.1235775559991130,\n                            0.1240115273049840,\n                            0.1245753981184280,\n                            0.1249519072803720,\n                            0.1251793875497570,\n                            0.1253437823548850,\n                            0.1259486272019440,\n                            0.1259670591996470,\n                            0.1261504072273180,\n                            0.1270547857142860,\n                            0.1275530353200880,\n                            0.1278131387343720,\n                            0.1280998512642540,\n                            0.1287212301001870,\n                            0.1289580095830810,\n                            0.1290085828891700,\n                            0.1304132516826660,\n                            0.1309290648193960,\n                            0.1315601250826540,\n                            0.1320659696068720,\n                            0.1328932240677590,\n                            0.1336453489265910,\n                            0.1340303717553890,\n                            0.1347657294298580,\n                            0.1352923279986800,\n                            0.1360370366290280,\n                            0.1365566273001920,\n                            0.1375466104152930,\n                            0.1380393871162610,\n                            0.1391758261775510,\n                            0.1393372198783630,\n                            0.1403947401936650,\n                            0.1410517545489320,\n                            0.1420981132075470,\n                            0.1424267063197030,\n                            0.1431591745373150,\n                            0.1439438302804960,\n                            0.1449724509333040,\n                            0.1457406097108570,\n                            0.1466319866826770,\n                            0.1477144227624550,\n                            0.1491561375701750,\n                            0.1499657283479590,\n                            0.1508730084930310,\n                            0.1524472420812020,\n                            0.1538901500326160,\n                            0.1551999854276550,\n                            0.1564189116238570,\n                            0.1575284381833020,\n                            0.1588692308277620,\n                            0.1593696495517520,\n                            0.1605326245110820,\n                            0.1618569582133350,\n                            0.1624176661422450,\n                            0.1634395257586450,\n                            0.1635596262494570,\n                            0.1647163760720880,\n                            0.1653961094581390,\n                            0.1659311061379690,\n                            0.1668263889643190,\n                            0.1664016268098260,\n                            0.1663602603460430,\n                            0.1672364293227780,\n                            0.1676109344315600,\n                            0.1680388326738580,\n                            0.1677260481471460,\n                            0.1674615913396480,\n                            0.1674423665261110,\n                            0.1669457804244260,\n                            0.1667212939521800,\n                            0.1666681862479700,\n                            0.1661996093893670,\n                            0.1660631997190860,\n                            0.1650462213562810,\n                            0.1644598642563330,\n                            0.1639480785837650,\n                            0.1629394804605160,\n                            0.1618968264677260,\n                            0.1607553251918300,\n                            0.1599774502784840,\n                            0.1592006389084410,\n                            0.1577751116168180,\n                            0.1567381133546260,\n                            0.1558041359727410,\n                            0.1546063862270590,\n                            0.1532839006439740,\n                            0.1522304826541110,\n                            0.1510174361195320,\n                            0.1495370270065490,\n                            0.1482986794128800,\n                            0.1471751082251080,\n                            0.1459533303020460,\n                            0.1448406104887160,\n                            0.1432260271395360,\n                            0.1420294881655200,\n                            0.1407796123863140,\n                            0.1394713345247770,\n                            0.1383847867252320,\n                            0.1367663760554230,\n                            0.1353930054621170,\n                            0.1340665548764000,\n                            0.1326094541324100,\n                            0.1314476955556760,\n                            0.1300619568392020,\n                            0.1286112691620170,\n                            0.1270600768689440,\n                            0.1256763453237410,\n                            0.1247108740387740,\n                            0.1233902828348500,\n                            0.1219225162024490,\n                            0.1203756671729230,\n                            0.1193858886718750,\n                            0.1187244485879990,\n                            0.1172117915401300,\n                            0.1163088532870850,\n                            0.1148534423920700,\n                            0.1134792034486500,\n                            0.1125721330001090,\n                            0.1113368023192800,\n                            0.1101989148244470,\n                            0.1091195956961200,\n                            0.1083813403562120,\n                            0.1071390462089160,\n                            0.1061137185040440,\n                            0.1049129130387580,\n                            0.1043954382535030,\n                            0.1031281954323000,\n                            0.1021073306429620,\n                            0.1010716444082520,\n                            0.1004949793702500,\n                            0.0995802646626368,\n                            0.0984846824799607,\n                            0.0976298555319497,\n                            0.0964366697093181,\n                            0.0959713445121951,\n                            0.0946097380316976,\n                            0.0940169040274674,\n                            0.0931408770974068,\n                            0.0925075464007411,\n                            0.0919924512854102,\n                            0.0911384338532010,\n                            0.0904112434318108,\n                            0.0898916765781003,\n                            0.0889631941324027,\n                            0.0886735681284474,\n                            0.0881560421558456,\n                            0.0874990131233596,\n                            0.0870141730990311,\n                            0.0865602858079677,\n                            0.0866091052286152,\n                            0.0860980602739726,\n                            0.0854415269900361,\n                            0.0852274163424125,\n                            0.0846683259332347,\n                            0.0846999037966362,\n                            0.0846302515481997,\n                            0.0837975875576037,\n                            0.0838024112149533,\n                            0.0835321230735480,\n                            0.0829661160327131,\n                            0.0827144267149202,\n                            0.0827143225629190,\n                            0.0820904100032906,\n                            0.0820583758300862,\n                            0.0819189005552196,\n                            0.0810632600471517,\n                            0.0810455174001206,\n                            0.0807908284431793,\n                            0.0804156337410190,\n                            0.0805326402629417,\n                            0.0800952396585686,\n                            0.0796956921896410,\n                            0.0793305183644425,\n                            0.0789345770872087,\n                            0.0784959303128253,\n                            0.0783585716629300,\n                            0.0780296335618316,\n                            0.0776355686360401,\n                            0.0777728303000492,\n                            0.0771084880319877,\n                            0.0769203308138898,\n                            0.0765511326039387,\n                            0.0762573573616277,\n                            0.0762127566381391,\n                            0.0760990485894276,\n                            0.0759584208223972,\n                            0.0755359285636025,\n                            0.0756633663670248,\n                            0.0752572122010094,\n                            0.0758166600909639,\n                            0.0750690017513135,\n                            0.0752405613919895,\n                            0.0750479940841367,\n                            0.0752528940517383,\n                            0.0749732792022792,\n                            0.0751002570131788,\n                            0.0750104604924056,\n                            0.0749880663745893,\n                            0.0752553795596451,\n                            0.0753496369021501,\n                            0.0753240486895493,\n                            0.0749273240054870,\n                            0.0755281749629548,\n                            0.0757077530932087,\n                            0.0758634115061267,\n                            0.0756506801228609,\n                            0.0760071605101143,\n                            0.0762060860026327,\n                            0.0759151579640193,\n                            0.0760791654510557,\n                            0.0761815485996705,\n                            0.0765150256522692,\n                            0.0762693840004381,\n                            0.0764163189645717,\n                            0.0764907408057002,\n                            0.0768342669584245,\n                            0.0771621960440524,\n                            0.0770743948220065,\n                            0.0770292538916904,\n                            0.0771631784423267,\n                            0.0774133684557129,\n                            0.0772509793050447,\n                            0.0776359754048861,\n                            0.0776684550740538,\n                            0.0775999245903436,\n                            0.0775543019880607,\n                            0.0775452066523959,\n                            0.0779931107448912,\n                            0.0779379115287394,\n                            0.0777371116127967,\n                            0.0777113861657265,\n                            0.0783069040254470,\n                            0.0777791275336913,\n                            0.0778322734546252,\n                            0.0782278086575343,\n                            0.0781885667306111,\n                            0.0779885797133166,\n                            0.0778922203584937,\n                            0.0777887903693571,\n                            0.0781322884794139,\n                            0.0778500300990532,\n                            0.0783473231527094,\n                            0.0781106787355065,\n                            0.0774791683038638,\n                            0.0774638428430621,\n                            0.0776397440804944,\n                            0.0778363414820891,\n                            0.0773739737159128,\n                            0.0771565329105620,\n                            0.0774208283325135,\n                            0.0773433725061492,\n                            0.0769061458287716,\n                            0.0768768537704918,\n                            0.0767942762841530,\n                            0.0766405641193834,\n                            0.0768223210852969,\n                            0.0756511902310809,\n                            0.0760848653489134,\n                            0.0758909124746839,\n                            0.0757557372797899,\n                            0.0755393640350877,\n                            0.0755921310541311,\n                            0.0759533260309984,\n                            0.0755523312534209,\n                            0.0758025853417513,\n                            0.0754538890712176,\n                            0.0759966492343413,\n                            0.0756392191463549,\n                            0.0760002427745665,\n                            0.0759172330727733,\n                            0.0760517874821252,\n                            0.0761247379087473,\n                            0.0767259722054381,\n                            0.0763790106863501,\n                            0.0764716400109619,\n                            0.0764261489525063,\n                            0.0764849258345667,\n                            0.0770762127916552,\n                            0.0770786163439449,\n                            0.0777177075901432,\n                            0.0779242324199406,\n                            0.0779871221093106,\n                            0.0782395180299033,\n                            0.0780202550409318,\n                            0.0784945261194030,\n                            0.0789988898659046,\n                            0.0787182916666667,\n                            0.0795837732500822,\n                            0.0803447880449685,\n                            0.0798549101363562,\n                            0.0801640755957272,\n                            0.0806020982436883,\n                            0.0807538561632564,\n                            0.0815723849317322,\n                            0.0814840643355108,\n                            0.0818510493352379,\n                            0.0819726217696014,\n                            0.0822825937877291,\n                            0.0826006385614824,\n                            0.0832230251162791,\n                            0.0832401884518462,\n                            0.0837584412217095,\n                            0.0840583776960650,\n                            0.0838307027945206,\n                            0.0846559244351832,\n                            0.0854320944276695,\n                            0.0859695935852373,\n                            0.0860562020024205,\n                            0.0868489965268207,\n                            0.0869247383567663,\n                            0.0877802062760588,\n                            0.0889851523971662,\n                            0.0886742533164529,\n                            0.0894202225519288,\n                            0.0903602252401458,\n                            0.0913718090645038,\n                            0.0926356862097440,\n                            0.0927020975529644,\n                            0.0934591620557682,\n                            0.0942531088738516,\n                            0.0957034433521885,\n                            0.0966463331682351,\n                            0.0970120648886445,\n                            0.0982979563203177,\n                            0.0993772702256467,\n                            0.1001024339091560,\n                            0.1006514627853130,\n                            0.1021924514103130,\n                            0.1032385466651990,\n                            0.1042875362287090,\n                            0.1054265632733870,\n                            0.1065878370941110,\n                            0.1078802324765710,\n                            0.1085841372602890,\n                            0.1096687124910860,\n                            0.1103224411182040,\n                            0.1116595158900050,\n                            0.1135477486645740,\n                            0.1144331781621860,\n                            0.1143250851485150,\n                            0.1156502670851920,\n                            0.1175013129411760,\n                            0.1179270310695630,\n                            0.1182087558274100,\n                            0.1191784615553600,\n                            0.1209157444943570,\n                            0.1216799742574260,\n                            0.1230600100148570,\n                            0.1251525243466300,\n                            0.1264191929573590,\n                            0.1278286560939470,\n                            0.1295155392232370,\n                            0.1325001371944510,\n                            0.1325402033842440,\n                            0.1334973586771410,\n                            0.1362069264544460,\n                        ]\n                    ),\n                ),\n                DatasetLoader_ForestColors(): (\n                    \"pine\",\n                    370,\n                    \"5\",\n                    np.array(\n                        [\n                            0.010262410000000,\n                            0.009839101400000,\n                            0.012529907000000,\n                            0.011030105000000,\n                            0.010073634000000,\n                            0.011320871000000,\n                            0.011616203000000,\n                            0.013212691000000,\n                            0.012491421000000,\n                            0.011912613000000,\n                            0.013115942000000,\n                            0.013417573000000,\n                            0.013631902000000,\n                            0.013967374000000,\n                            0.014361868000000,\n                            0.014427279000000,\n                            0.014636329000000,\n                            0.014908329000000,\n                            0.014993297000000,\n                            0.015136227000000,\n                            0.015386547000000,\n                            0.015711171000000,\n                            0.015828966000000,\n                            0.016981529000000,\n                            0.018321589000000,\n                            0.019439448000000,\n                            0.021571993000000,\n                            0.023876195000000,\n                            0.025659029000000,\n                            0.026894433000000,\n                            0.028889134000000,\n                            0.030469200000000,\n                            0.030692223000000,\n                            0.031212534000000,\n                            0.030800426000000,\n                            0.029837495000000,\n                            0.029041031000000,\n                            0.027807930000000,\n                            0.027085866000000,\n                            0.026870222000000,\n                            0.026034403000000,\n                            0.025490563000000,\n                            0.025915747000000,\n                            0.025255465000000,\n                            0.024883133000000,\n                            0.024609150000000,\n                            0.023686946000000,\n                            0.023991298000000,\n                            0.023958765000000,\n                            0.023967050000000,\n                            0.023539582000000,\n                            0.022725872000000,\n                            0.022347244000000,\n                            0.022138569000000,\n                            0.021979660000000,\n                            0.020823906000000,\n                            0.021076211000000,\n                            0.021165034000000,\n                            0.022165784000000,\n                            0.025146573000000,\n                            0.029714434000000,\n                            0.039837663000000,\n                            0.052246223000000,\n                            0.067425578000000,\n                            0.083176671000000,\n                            0.097080232000000,\n                            0.111191460000000,\n                            0.122961630000000,\n                            0.134962030000000,\n                            0.143059710000000,\n                            0.149133660000000,\n                            0.155173970000000,\n                            0.155457870000000,\n                            0.159591120000000,\n                            0.164270350000000,\n                            0.165211360000000,\n                            0.167401470000000,\n                            0.167736380000000,\n                            0.169301000000000,\n                            0.170914620000000,\n                            0.171809910000000,\n                            0.172325160000000,\n                            0.174672460000000,\n                            0.176431510000000,\n                            0.174736990000000,\n                            0.177491730000000,\n                            0.176703620000000,\n                            0.177523560000000,\n                            0.182620180000000,\n                            0.182529490000000,\n                            0.183265810000000,\n                            0.183518600000000,\n                            0.186661620000000,\n                        ]\n                    ),\n                ),\n                DatasetLoader_PaperSpectra(): (\n                    \"newsprintsce\",\n                    36,\n                    \"5\",\n                    np.array(\n                        [\n                            28.430000000000000,\n                            37.390000000000000,\n                            44.860000000000000,\n                            48.860000000000000,\n                            51.120000000000000,\n                            52.330000000000000,\n                            53.140000000000000,\n                            53.930000000000000,\n                            54.620000000000000,\n                            55.090000000000000,\n                            54.890000000000000,\n                            53.670000000000000,\n                            51.830000000000000,\n                            50.610000000000000,\n                            48.660000000000000,\n                            45.180000000000000,\n                            43.640000000000000,\n                            48.450000000000000,\n                            58.400000000000000,\n                            67.180000000000000,\n                            69.940000000000000,\n                            69.630000000000000,\n                            69.300000000000000,\n                            69.340000000000000,\n                            69.370000000000000,\n                            69.190000000000000,\n                            68.880000000000000,\n                            68.610000000000000,\n                            68.290000000000000,\n                            68.250000000000000,\n                            68.230000000000000,\n                        ]\n                    ),\n                ),\n                DatasetLoader_LumberSpectra(): (\n                    \"birchWp\",\n                    12,\n                    \"5\",\n                    np.array(\n                        [\n                            0.044233333000000,\n                            0.045133333000000,\n                            0.045233333000000,\n                            0.046333333000000,\n                            0.046833333000000,\n                            0.047633333000000,\n                            0.048733333000000,\n                            0.049633333000000,\n                            0.049933333000000,\n                            0.051733333000000,\n                            0.052733333000000,\n                            0.053133333000000,\n                            0.053833333000000,\n                            0.054633333000000,\n                            0.055433333000000,\n                            0.056333333000000,\n                            0.056833333000000,\n                            0.058033333000000,\n                            0.058433333000000,\n                            0.059633333000000,\n                            0.059933333000000,\n                            0.060433333000000,\n                            0.061033333000000,\n                            0.063233333000000,\n                            0.063833333000000,\n                            0.064133333000000,\n                            0.064133333000000,\n                            0.065533333000000,\n                            0.066533333000000,\n                            0.067033333000000,\n                            0.067833333000000,\n                            0.068233333000000,\n                            0.068633333000000,\n                            0.069933333000000,\n                            0.070033333000000,\n                            0.071533333000000,\n                            0.071933333000000,\n                            0.072433333000000,\n                            0.072933333000000,\n                            0.073833333000000,\n                            0.074433333000000,\n                            0.074933333000000,\n                            0.075833333000000,\n                            0.076233333000000,\n                            0.076833333000000,\n                            0.077233333000000,\n                            0.077933333000000,\n                            0.078133333000000,\n                            0.078133333000000,\n                            0.079933333000000,\n                            0.080333333000000,\n                            0.080833333000000,\n                            0.081333333000000,\n                            0.081633333000000,\n                            0.082433333000000,\n                            0.083733333000000,\n                            0.083833333000000,\n                            0.084233333000000,\n                            0.085033333000000,\n                            0.085733333000000,\n                            0.085733333000000,\n                            0.086333333000000,\n                            0.086733333000000,\n                            0.087433333000000,\n                            0.088133333000000,\n                            0.089033333000000,\n                            0.089433333000000,\n                            0.089733333000000,\n                            0.090033333000000,\n                            0.090333333000000,\n                            0.090833333000000,\n                            0.091533333000000,\n                            0.092233333000000,\n                            0.092633333000000,\n                            0.092833333000000,\n                            0.093333333000000,\n                            0.094133333000000,\n                            0.094833333000000,\n                            0.095133333000000,\n                            0.095833333000000,\n                            0.096233333000000,\n                            0.097133333000000,\n                            0.096833333000000,\n                            0.097733333000000,\n                            0.098133333000000,\n                            0.098933333000000,\n                            0.099233333000000,\n                            0.099633333000000,\n                            0.100333330000000,\n                            0.101433330000000,\n                            0.101933330000000,\n                            0.102533330000000,\n                            0.102933330000000,\n                            0.103633330000000,\n                            0.103533330000000,\n                            0.104533330000000,\n                            0.104833330000000,\n                            0.105833330000000,\n                            0.106133330000000,\n                            0.106933330000000,\n                            0.106733330000000,\n                            0.107733330000000,\n                            0.108033330000000,\n                            0.108133330000000,\n                            0.108533330000000,\n                            0.109633330000000,\n                            0.109833330000000,\n                            0.110533330000000,\n                            0.111133330000000,\n                            0.111633330000000,\n                            0.111533330000000,\n                            0.111833330000000,\n                            0.113033330000000,\n                            0.112833330000000,\n                            0.113333330000000,\n                            0.114033330000000,\n                            0.114333330000000,\n                            0.115233330000000,\n                            0.116033330000000,\n                            0.116433330000000,\n                            0.116933330000000,\n                            0.117333330000000,\n                            0.117733330000000,\n                            0.118633330000000,\n                            0.118933330000000,\n                            0.119633330000000,\n                            0.119833330000000,\n                            0.120733330000000,\n                            0.121233330000000,\n                            0.121833330000000,\n                            0.122333330000000,\n                            0.123133330000000,\n                            0.123633330000000,\n                            0.124133330000000,\n                            0.124433330000000,\n                            0.125233330000000,\n                            0.125533330000000,\n                            0.126033330000000,\n                            0.126633330000000,\n                            0.127033330000000,\n                            0.127533330000000,\n                            0.128033330000000,\n                            0.128033330000000,\n                            0.128833330000000,\n                            0.129233330000000,\n                            0.129433330000000,\n                            0.130233330000000,\n                            0.130833330000000,\n                            0.130933330000000,\n                            0.131833330000000,\n                            0.132033330000000,\n                            0.132433330000000,\n                            0.133233330000000,\n                            0.134233330000000,\n                            0.134133330000000,\n                            0.134533330000000,\n                            0.135033330000000,\n                            0.135433330000000,\n                            0.136133330000000,\n                            0.136033330000000,\n                            0.136933330000000,\n                            0.137733330000000,\n                            0.138333330000000,\n                            0.138533330000000,\n                            0.139133330000000,\n                            0.139633330000000,\n                            0.139933330000000,\n                            0.140133330000000,\n                            0.140633330000000,\n                            0.141433330000000,\n                            0.141633330000000,\n                            0.142433330000000,\n                            0.142733330000000,\n                            0.143933330000000,\n                            0.143633330000000,\n                            0.144233330000000,\n                            0.144533330000000,\n                            0.145333330000000,\n                            0.145233330000000,\n                            0.145933330000000,\n                            0.146233330000000,\n                            0.147133330000000,\n                            0.147233330000000,\n                            0.147533330000000,\n                            0.148133330000000,\n                            0.148733330000000,\n                            0.148933330000000,\n                            0.149533330000000,\n                            0.149933330000000,\n                            0.150733330000000,\n                            0.151333330000000,\n                            0.151633330000000,\n                            0.152133330000000,\n                            0.152033330000000,\n                            0.152233330000000,\n                            0.152333330000000,\n                            0.153233330000000,\n                            0.153833330000000,\n                            0.154433330000000,\n                            0.154333330000000,\n                            0.154633330000000,\n                            0.155433330000000,\n                            0.155433330000000,\n                            0.155333330000000,\n                            0.155833330000000,\n                            0.156833330000000,\n                            0.157433330000000,\n                            0.158033330000000,\n                            0.158533330000000,\n                            0.158933330000000,\n                            0.158833330000000,\n                            0.158533330000000,\n                            0.158533330000000,\n                            0.160633330000000,\n                            0.161133330000000,\n                            0.160933330000000,\n                            0.161633330000000,\n                            0.162033330000000,\n                            0.162333330000000,\n                            0.163033330000000,\n                            0.163333330000000,\n                            0.163433330000000,\n                            0.163833330000000,\n                            0.163933330000000,\n                            0.164333330000000,\n                            0.165433330000000,\n                            0.165733330000000,\n                            0.166033330000000,\n                            0.166333330000000,\n                            0.166433330000000,\n                            0.166533330000000,\n                            0.167833330000000,\n                            0.167933330000000,\n                            0.167733330000000,\n                            0.168233330000000,\n                            0.168333330000000,\n                            0.168533330000000,\n                            0.169333330000000,\n                            0.169533330000000,\n                            0.170333330000000,\n                            0.170033330000000,\n                            0.171033330000000,\n                            0.170433330000000,\n                            0.171233330000000,\n                            0.171533330000000,\n                            0.172233330000000,\n                            0.172133330000000,\n                            0.172233330000000,\n                            0.172733330000000,\n                            0.173533330000000,\n                            0.174033330000000,\n                            0.174133330000000,\n                            0.175033330000000,\n                            0.175433330000000,\n                            0.175733330000000,\n                            0.176133330000000,\n                            0.175733330000000,\n                            0.175833330000000,\n                            0.175733330000000,\n                            0.176833330000000,\n                            0.176733330000000,\n                            0.177033330000000,\n                            0.176933330000000,\n                            0.177233330000000,\n                            0.178233330000000,\n                            0.178933330000000,\n                            0.178533330000000,\n                            0.180033330000000,\n                            0.180233330000000,\n                            0.180633330000000,\n                            0.180633330000000,\n                            0.181433330000000,\n                            0.180433330000000,\n                            0.180833330000000,\n                            0.181233330000000,\n                            0.181033330000000,\n                            0.181233330000000,\n                            0.182333330000000,\n                            0.181833330000000,\n                            0.182133330000000,\n                            0.183333330000000,\n                            0.182333330000000,\n                            0.182633330000000,\n                            0.183533330000000,\n                            0.183833330000000,\n                            0.183933330000000,\n                            0.183433330000000,\n                            0.184733330000000,\n                            0.184633330000000,\n                            0.185033330000000,\n                            0.185433330000000,\n                            0.186033330000000,\n                            0.185833330000000,\n                            0.186833330000000,\n                            0.185733330000000,\n                            0.186433330000000,\n                            0.187033330000000,\n                            0.187333330000000,\n                            0.187433330000000,\n                            0.187833330000000,\n                            0.187433330000000,\n                            0.186333330000000,\n                            0.186933330000000,\n                            0.188433330000000,\n                            0.188433330000000,\n                            0.188833330000000,\n                            0.189333330000000,\n                            0.190133330000000,\n                            0.189633330000000,\n                            0.190433330000000,\n                            0.190133330000000,\n                            0.190733330000000,\n                            0.190033330000000,\n                            0.189933330000000,\n                            0.190433330000000,\n                            0.190433330000000,\n                            0.190933330000000,\n                            0.191633330000000,\n                            0.191833330000000,\n                            0.191933330000000,\n                            0.191733330000000,\n                            0.191233330000000,\n                            0.192333330000000,\n                            0.192833330000000,\n                            0.193233330000000,\n                            0.193633330000000,\n                            0.193633330000000,\n                            0.193033330000000,\n                            0.192933330000000,\n                            0.192833330000000,\n                            0.193533330000000,\n                            0.193433330000000,\n                            0.193733330000000,\n                            0.193833330000000,\n                            0.194333330000000,\n                            0.194033330000000,\n                            0.195133330000000,\n                            0.195033330000000,\n                            0.194933330000000,\n                            0.196233330000000,\n                            0.197033330000000,\n                            0.196833330000000,\n                            0.197333330000000,\n                            0.195533330000000,\n                            0.195733330000000,\n                            0.197233330000000,\n                            0.198333330000000,\n                            0.196433330000000,\n                            0.197233330000000,\n                            0.196833330000000,\n                            0.197433330000000,\n                            0.197033330000000,\n                            0.196833330000000,\n                            0.198433330000000,\n                            0.198233330000000,\n                            0.198233330000000,\n                            0.198533330000000,\n                            0.198233330000000,\n                            0.197833330000000,\n                            0.199133330000000,\n                            0.199233330000000,\n                            0.199333330000000,\n                            0.199433330000000,\n                            0.200133330000000,\n                            0.200133330000000,\n                            0.200533330000000,\n                            0.199433330000000,\n                            0.200633330000000,\n                            0.200633330000000,\n                            0.200233330000000,\n                            0.199833330000000,\n                            0.200133330000000,\n                            0.201433330000000,\n                            0.202233330000000,\n                            0.201333330000000,\n                            0.201233330000000,\n                            0.201433330000000,\n                            0.201833330000000,\n                            0.201533330000000,\n                            0.203233330000000,\n                            0.202333330000000,\n                            0.201433330000000,\n                            0.203333330000000,\n                            0.202733330000000,\n                            0.202533330000000,\n                            0.202633330000000,\n                            0.203533330000000,\n                            0.203433330000000,\n                            0.202633330000000,\n                            0.203133330000000,\n                            0.203233330000000,\n                            0.204533330000000,\n                            0.204533330000000,\n                            0.203533330000000,\n                            0.203133330000000,\n                            0.202633330000000,\n                            0.203133330000000,\n                            0.204433330000000,\n                            0.205033330000000,\n                            0.205533330000000,\n                            0.204733330000000,\n                            0.206333330000000,\n                            0.205633330000000,\n                            0.207733330000000,\n                            0.207133330000000,\n                            0.207233330000000,\n                            0.206933330000000,\n                            0.206833330000000,\n                            0.209133330000000,\n                            0.207533330000000,\n                            0.207733330000000,\n                            0.208333330000000,\n                            0.208333330000000,\n                            0.206133330000000,\n                            0.207433330000000,\n                            0.209033330000000,\n                            0.209233330000000,\n                            0.208633330000000,\n                            0.207733330000000,\n                            0.210233330000000,\n                            0.209633330000000,\n                            0.208833330000000,\n                            0.210233330000000,\n                            0.209633330000000,\n                            0.210133330000000,\n                            0.211033330000000,\n                            0.210733330000000,\n                            0.210133330000000,\n                            0.210533330000000,\n                            0.208633330000000,\n                            0.209033330000000,\n                            0.209733330000000,\n                            0.210533330000000,\n                            0.210033330000000,\n                            0.208433330000000,\n                            0.210433330000000,\n                            0.210933330000000,\n                            0.209633330000000,\n                            0.210233330000000,\n                            0.212233330000000,\n                            0.212433330000000,\n                            0.211433330000000,\n                            0.212133330000000,\n                            0.212733330000000,\n                            0.211533330000000,\n                            0.212033330000000,\n                            0.211333330000000,\n                            0.209733330000000,\n                            0.210433330000000,\n                            0.211233330000000,\n                            0.212533330000000,\n                            0.211533330000000,\n                            0.211733330000000,\n                            0.210133330000000,\n                            0.210033330000000,\n                            0.210833330000000,\n                            0.211333330000000,\n                            0.211233330000000,\n                            0.213733330000000,\n                            0.211133330000000,\n                            0.211533330000000,\n                            0.214833330000000,\n                            0.211433330000000,\n                            0.214633330000000,\n                            0.214433330000000,\n                            0.214833330000000,\n                            0.216733330000000,\n                            0.215833330000000,\n                            0.214833330000000,\n                            0.219333330000000,\n                            0.216833330000000,\n                            0.215333330000000,\n                            0.215433330000000,\n                            0.217633330000000,\n                            0.216033330000000,\n                            0.215233330000000,\n                            0.217533330000000,\n                            0.216933330000000,\n                            0.215733330000000,\n                            0.209633330000000,\n                            0.209633330000000,\n                            0.216766670000000,\n                            0.217466670000000,\n                            0.215466670000000,\n                            0.215566670000000,\n                            0.214766670000000,\n                            0.213066670000000,\n                            0.212366670000000,\n                            0.212866670000000,\n                            0.213166670000000,\n                            0.211066670000000,\n                            0.212366670000000,\n                            0.213066670000000,\n                            0.211666670000000,\n                            0.209966670000000,\n                            0.209366670000000,\n                            0.210766670000000,\n                            0.210066670000000,\n                            0.210666670000000,\n                            0.211766670000000,\n                            0.208966670000000,\n                            0.208266670000000,\n                            0.210366670000000,\n                            0.210866670000000,\n                            0.209366670000000,\n                            0.208966670000000,\n                            0.209966670000000,\n                            0.208166670000000,\n                            0.207166670000000,\n                            0.208766670000000,\n                            0.208566670000000,\n                            0.207566670000000,\n                            0.205666670000000,\n                            0.206166670000000,\n                            0.206366670000000,\n                            0.206166670000000,\n                            0.206166670000000,\n                            0.205766670000000,\n                            0.204866670000000,\n                            0.206066670000000,\n                            0.205466670000000,\n                            0.205066670000000,\n                            0.204566670000000,\n                            0.204266670000000,\n                            0.204366670000000,\n                            0.203666670000000,\n                            0.203366670000000,\n                            0.202066670000000,\n                            0.202266670000000,\n                            0.203866670000000,\n                            0.203166670000000,\n                            0.202866670000000,\n                            0.201966670000000,\n                            0.201166670000000,\n                            0.201266670000000,\n                            0.201266670000000,\n                            0.200966670000000,\n                            0.200766670000000,\n                            0.200766670000000,\n                            0.201266670000000,\n                            0.200766670000000,\n                            0.200066670000000,\n                            0.199766670000000,\n                            0.199366670000000,\n                            0.199366670000000,\n                            0.199466670000000,\n                            0.199066670000000,\n                            0.198466670000000,\n                            0.198366670000000,\n                            0.198466670000000,\n                            0.198266670000000,\n                            0.197966670000000,\n                            0.198066670000000,\n                            0.197266670000000,\n                            0.196866670000000,\n                            0.196566670000000,\n                            0.196666670000000,\n                            0.196266670000000,\n                            0.195366670000000,\n                            0.195366670000000,\n                            0.195166670000000,\n                            0.194066670000000,\n                            0.193666670000000,\n                            0.193266670000000,\n                            0.193066670000000,\n                            0.192266670000000,\n                            0.192066670000000,\n                            0.191766670000000,\n                            0.190966670000000,\n                            0.190666670000000,\n                            0.190066670000000,\n                            0.190066670000000,\n                            0.190266670000000,\n                            0.190366670000000,\n                            0.190766670000000,\n                            0.190866670000000,\n                            0.190866670000000,\n                            0.190966670000000,\n                            0.190866670000000,\n                            0.191166670000000,\n                            0.191266670000000,\n                            0.191366670000000,\n                            0.191566670000000,\n                            0.191766670000000,\n                            0.191466670000000,\n                            0.191766670000000,\n                            0.191966670000000,\n                            0.192166670000000,\n                            0.191766670000000,\n                            0.192366670000000,\n                            0.192166670000000,\n                            0.192266670000000,\n                            0.192266670000000,\n                            0.191966670000000,\n                            0.191666670000000,\n                            0.191966670000000,\n                            0.191666670000000,\n                            0.191466670000000,\n                            0.191766670000000,\n                            0.192266670000000,\n                            0.191866670000000,\n                            0.191866670000000,\n                            0.191866670000000,\n                            0.191966670000000,\n                            0.191666670000000,\n                            0.191266670000000,\n                            0.191466670000000,\n                            0.191566670000000,\n                            0.191866670000000,\n                            0.192566670000000,\n                            0.192366670000000,\n                            0.191966670000000,\n                            0.192066670000000,\n                            0.192366670000000,\n                            0.192166670000000,\n                            0.192266670000000,\n                            0.192566670000000,\n                            0.192866670000000,\n                            0.192466670000000,\n                            0.192966670000000,\n                            0.192966670000000,\n                            0.192966670000000,\n                            0.192766670000000,\n                            0.193066670000000,\n                            0.193266670000000,\n                            0.193066670000000,\n                            0.193066670000000,\n                            0.193366670000000,\n                            0.192866670000000,\n                            0.193366670000000,\n                            0.193666670000000,\n                            0.193966670000000,\n                            0.193866670000000,\n                            0.193566670000000,\n                            0.193866670000000,\n                            0.193566670000000,\n                            0.193666670000000,\n                            0.193966670000000,\n                            0.194166670000000,\n                            0.194366670000000,\n                            0.194266670000000,\n                            0.194066670000000,\n                            0.194166670000000,\n                            0.194266670000000,\n                            0.194466670000000,\n                            0.194466670000000,\n                            0.194566670000000,\n                            0.194866670000000,\n                            0.194966670000000,\n                            0.194866670000000,\n                            0.194566670000000,\n                            0.194466670000000,\n                            0.194866670000000,\n                            0.195166670000000,\n                            0.195166670000000,\n                            0.195066670000000,\n                            0.195366670000000,\n                            0.195566670000000,\n                            0.195466670000000,\n                            0.195766670000000,\n                            0.195466670000000,\n                            0.195466670000000,\n                            0.195766670000000,\n                            0.195466670000000,\n                            0.195266670000000,\n                            0.195566670000000,\n                            0.195666670000000,\n                            0.195666670000000,\n                            0.195666670000000,\n                            0.196366670000000,\n                            0.196066670000000,\n                            0.195766670000000,\n                            0.195666670000000,\n                            0.195966670000000,\n                            0.195866670000000,\n                            0.195866670000000,\n                            0.196066670000000,\n                            0.196566670000000,\n                            0.196166670000000,\n                            0.196666670000000,\n                            0.196366670000000,\n                            0.196466670000000,\n                            0.196266670000000,\n                            0.196066670000000,\n                            0.196066670000000,\n                            0.196366670000000,\n                            0.196466670000000,\n                            0.196466670000000,\n                            0.196766670000000,\n                            0.196866670000000,\n                            0.196466670000000,\n                            0.196866670000000,\n                            0.196666670000000,\n                            0.196066670000000,\n                            0.196166670000000,\n                            0.196666670000000,\n                            0.196666670000000,\n                            0.196666670000000,\n                            0.197066670000000,\n                            0.197366670000000,\n                            0.197066670000000,\n                            0.197166670000000,\n                            0.197166670000000,\n                            0.197366670000000,\n                            0.197166670000000,\n                            0.197066670000000,\n                            0.197066670000000,\n                            0.196766670000000,\n                            0.197166670000000,\n                            0.197266670000000,\n                            0.196966670000000,\n                            0.196966670000000,\n                            0.197466670000000,\n                            0.197066670000000,\n                            0.196766670000000,\n                            0.196966670000000,\n                            0.197666670000000,\n                            0.197066670000000,\n                            0.196866670000000,\n                            0.197166670000000,\n                            0.197166670000000,\n                            0.197366670000000,\n                            0.197566670000000,\n                            0.197466670000000,\n                            0.197366670000000,\n                            0.197366670000000,\n                            0.197366670000000,\n                            0.197266670000000,\n                            0.196566670000000,\n                            0.197266670000000,\n                            0.197466670000000,\n                            0.197066670000000,\n                            0.196866670000000,\n                            0.197066670000000,\n                            0.196766670000000,\n                            0.196966670000000,\n                            0.197166670000000,\n                            0.197366670000000,\n                            0.196866670000000,\n                            0.196966670000000,\n                            0.196766670000000,\n                            0.196466670000000,\n                            0.195966670000000,\n                            0.195666670000000,\n                            0.195966670000000,\n                            0.196066670000000,\n                            0.195666670000000,\n                            0.195366670000000,\n                            0.195066670000000,\n                            0.194966670000000,\n                            0.194666670000000,\n                            0.194566670000000,\n                            0.194766670000000,\n                            0.194466670000000,\n                            0.194166670000000,\n                            0.193866670000000,\n                            0.193566670000000,\n                            0.193366670000000,\n                            0.193466670000000,\n                            0.193866670000000,\n                            0.193066670000000,\n                            0.192866670000000,\n                            0.192666670000000,\n                            0.192366670000000,\n                            0.192066670000000,\n                            0.191966670000000,\n                            0.191566670000000,\n                            0.190966670000000,\n                            0.190666670000000,\n                            0.190666670000000,\n                            0.190366670000000,\n                            0.190266670000000,\n                            0.190266670000000,\n                            0.189866670000000,\n                            0.189366670000000,\n                            0.189066670000000,\n                            0.189066670000000,\n                            0.188466670000000,\n                            0.188066670000000,\n                            0.188166670000000,\n                            0.187966670000000,\n                            0.187466670000000,\n                            0.187266670000000,\n                            0.187266670000000,\n                            0.187066670000000,\n                            0.186766670000000,\n                            0.186666670000000,\n                            0.186666670000000,\n                            0.186166670000000,\n                            0.186466670000000,\n                            0.186266670000000,\n                            0.185966670000000,\n                            0.185766670000000,\n                            0.185766670000000,\n                            0.185566670000000,\n                            0.185166670000000,\n                            0.184866670000000,\n                            0.184966670000000,\n                            0.185066670000000,\n                            0.185166670000000,\n                            0.184966670000000,\n                            0.184466670000000,\n                            0.184366670000000,\n                            0.183866670000000,\n                            0.183666670000000,\n                            0.183666670000000,\n                            0.183366670000000,\n                            0.183066670000000,\n                            0.183066670000000,\n                            0.182166670000000,\n                            0.180366670000000,\n                            0.180166670000000,\n                            0.180066670000000,\n                            0.179766670000000,\n                            0.179966670000000,\n                            0.180066670000000,\n                            0.179766670000000,\n                            0.179566670000000,\n                            0.179466670000000,\n                            0.179766670000000,\n                            0.179566670000000,\n                            0.179466670000000,\n                            0.179466670000000,\n                            0.179466670000000,\n                            0.179666670000000,\n                            0.179566670000000,\n                            0.179566670000000,\n                            0.179366670000000,\n                            0.179766670000000,\n                            0.180166670000000,\n                            0.179466670000000,\n                            0.179466670000000,\n                            0.179566670000000,\n                            0.179466670000000,\n                            0.179266670000000,\n                            0.179466670000000,\n                            0.179466670000000,\n                            0.179766670000000,\n                            0.179966670000000,\n                            0.180266670000000,\n                            0.180466670000000,\n                            0.179766670000000,\n                            0.180066670000000,\n                            0.180266670000000,\n                            0.179966670000000,\n                            0.180166670000000,\n                            0.180766670000000,\n                            0.180666670000000,\n                            0.180766670000000,\n                            0.181066670000000,\n                            0.180766670000000,\n                            0.180766670000000,\n                            0.181066670000000,\n                            0.181366670000000,\n                            0.181066670000000,\n                            0.181266670000000,\n                            0.181566670000000,\n                            0.181566670000000,\n                            0.181566670000000,\n                            0.182066670000000,\n                            0.182166670000000,\n                            0.182066670000000,\n                            0.182066670000000,\n                            0.182066670000000,\n                            0.182366670000000,\n                            0.182266670000000,\n                            0.182566670000000,\n                            0.182566670000000,\n                            0.182466670000000,\n                            0.182966670000000,\n                            0.182966670000000,\n                            0.183166670000000,\n                            0.182966670000000,\n                            0.182366670000000,\n                            0.182566670000000,\n                            0.182966670000000,\n                            0.183366670000000,\n                            0.183366670000000,\n                            0.183266670000000,\n                            0.183166670000000,\n                            0.183166670000000,\n                            0.183566670000000,\n                            0.183666670000000,\n                            0.183466670000000,\n                            0.183566670000000,\n                            0.183566670000000,\n                            0.183266670000000,\n                            0.183466670000000,\n                            0.184166670000000,\n                            0.184366670000000,\n                            0.183966670000000,\n                            0.184066670000000,\n                            0.184266670000000,\n                            0.183866670000000,\n                            0.183466670000000,\n                            0.183666670000000,\n                            0.183766670000000,\n                            0.183866670000000,\n                            0.183966670000000,\n                            0.184266670000000,\n                            0.184066670000000,\n                            0.184166670000000,\n                            0.184466670000000,\n                            0.184366670000000,\n                            0.184366670000000,\n                            0.184866670000000,\n                            0.185066670000000,\n                            0.184866670000000,\n                            0.184666670000000,\n                            0.185166670000000,\n                            0.185266670000000,\n                            0.185566670000000,\n                            0.185466670000000,\n                            0.185266670000000,\n                            0.185166670000000,\n                            0.184966670000000,\n                            0.185066670000000,\n                            0.185366670000000,\n                            0.185166670000000,\n                            0.185366670000000,\n                            0.185766670000000,\n                            0.185666670000000,\n                            0.185666670000000,\n                            0.185366670000000,\n                            0.185466670000000,\n                            0.185066670000000,\n                            0.184666670000000,\n                            0.184666670000000,\n                            0.184766670000000,\n                            0.185366670000000,\n                            0.185166670000000,\n                            0.185366670000000,\n                            0.185166670000000,\n                            0.184866670000000,\n                            0.184866670000000,\n                            0.184566670000000,\n                            0.184466670000000,\n                            0.184566670000000,\n                            0.184866670000000,\n                            0.184666670000000,\n                            0.184466670000000,\n                            0.184366670000000,\n                            0.184166670000000,\n                            0.183466670000000,\n                            0.183666670000000,\n                            0.183866670000000,\n                            0.183366670000000,\n                            0.182766670000000,\n                            0.182866670000000,\n                            0.183266670000000,\n                            0.182866670000000,\n                            0.182966670000000,\n                            0.182766670000000,\n                            0.181966670000000,\n                            0.181666670000000,\n                            0.181266670000000,\n                            0.180866670000000,\n                            0.180466670000000,\n                            0.180366670000000,\n                            0.180666670000000,\n                            0.180266670000000,\n                            0.179366670000000,\n                            0.179266670000000,\n                            0.179066670000000,\n                            0.178666670000000,\n                            0.178466670000000,\n                            0.178366670000000,\n                            0.177966670000000,\n                            0.177566670000000,\n                            0.177766670000000,\n                            0.177166670000000,\n                            0.176866670000000,\n                            0.176266670000000,\n                            0.175666670000000,\n                            0.175466670000000,\n                            0.174866670000000,\n                            0.174466670000000,\n                            0.174166670000000,\n                            0.173966670000000,\n                            0.174366670000000,\n                            0.174266670000000,\n                            0.173766670000000,\n                            0.173466670000000,\n                            0.173166670000000,\n                            0.173266670000000,\n                            0.172266670000000,\n                            0.171866670000000,\n                            0.171566670000000,\n                            0.171266670000000,\n                            0.170766670000000,\n                            0.170366670000000,\n                            0.169566670000000,\n                            0.169466670000000,\n                            0.169166670000000,\n                            0.169666670000000,\n                            0.169666670000000,\n                            0.169366670000000,\n                            0.169366670000000,\n                            0.169566670000000,\n                            0.169766670000000,\n                            0.169566670000000,\n                            0.169466670000000,\n                            0.169366670000000,\n                            0.168166670000000,\n                            0.167566670000000,\n                            0.166866670000000,\n                            0.167066670000000,\n                            0.166666670000000,\n                            0.166066670000000,\n                            0.166266670000000,\n                            0.165766670000000,\n                            0.165566670000000,\n                            0.165566670000000,\n                            0.165166670000000,\n                            0.164566670000000,\n                            0.164166670000000,\n                            0.163566670000000,\n                            0.162466670000000,\n                            0.161766670000000,\n                            0.161866670000000,\n                            0.160966670000000,\n                            0.160266670000000,\n                            0.159866670000000,\n                            0.159566670000000,\n                            0.159166670000000,\n                            0.158166670000000,\n                            0.157666670000000,\n                            0.157066670000000,\n                            0.156266670000000,\n                            0.155466670000000,\n                            0.154566670000000,\n                            0.153766670000000,\n                            0.153066670000000,\n                            0.152066670000000,\n                            0.151666670000000,\n                            0.150666670000000,\n                            0.150066670000000,\n                            0.149966670000000,\n                            0.149566670000000,\n                            0.148566670000000,\n                            0.148066670000000,\n                            0.147766670000000,\n                            0.147266670000000,\n                            0.146266670000000,\n                            0.146266670000000,\n                            0.145466670000000,\n                            0.144966670000000,\n                            0.144466670000000,\n                            0.144366670000000,\n                            0.144366670000000,\n                            0.143666670000000,\n                            0.143466670000000,\n                            0.143366670000000,\n                            0.142966670000000,\n                            0.142866670000000,\n                            0.142166670000000,\n                            0.142066670000000,\n                            0.142266670000000,\n                            0.142066670000000,\n                            0.141966670000000,\n                            0.141666670000000,\n                            0.141366670000000,\n                            0.141466670000000,\n                            0.141366670000000,\n                            0.140866670000000,\n                            0.140966670000000,\n                            0.141366670000000,\n                            0.141166670000000,\n                            0.141166670000000,\n                            0.141366670000000,\n                            0.141266670000000,\n                            0.140966670000000,\n                            0.140866670000000,\n                            0.141066670000000,\n                            0.141066670000000,\n                            0.140866670000000,\n                            0.141166670000000,\n                            0.140866670000000,\n                            0.140766670000000,\n                            0.141366670000000,\n                            0.141266670000000,\n                            0.140866670000000,\n                            0.140866670000000,\n                            0.140966670000000,\n                            0.140766670000000,\n                            0.140466670000000,\n                            0.140466670000000,\n                            0.140566670000000,\n                            0.140566670000000,\n                            0.140966670000000,\n                            0.140666670000000,\n                            0.140466670000000,\n                            0.140266670000000,\n                            0.140166670000000,\n                            0.140366670000000,\n                            0.140266670000000,\n                            0.140466670000000,\n                            0.140566670000000,\n                            0.140966670000000,\n                            0.141466670000000,\n                            0.141066670000000,\n                            0.141366670000000,\n                            0.141166670000000,\n                            0.141366670000000,\n                            0.141766670000000,\n                            0.141666670000000,\n                            0.141466670000000,\n                            0.141666670000000,\n                            0.141966670000000,\n                            0.142266670000000,\n                            0.141866670000000,\n                            0.141666670000000,\n                            0.142066670000000,\n                            0.142266670000000,\n                            0.142266670000000,\n                            0.142566670000000,\n                            0.142666670000000,\n                            0.142766670000000,\n                            0.143166670000000,\n                            0.143266670000000,\n                            0.143266670000000,\n                            0.143066670000000,\n                            0.143366670000000,\n                            0.143566670000000,\n                            0.143666670000000,\n                            0.143866670000000,\n                            0.144066670000000,\n                            0.144166670000000,\n                            0.143866670000000,\n                            0.144666670000000,\n                            0.144666670000000,\n                            0.144666670000000,\n                            0.144666670000000,\n                            0.144866670000000,\n                            0.145066670000000,\n                            0.145166670000000,\n                            0.145266670000000,\n                            0.145566670000000,\n                            0.145666670000000,\n                            0.146166670000000,\n                            0.146266670000000,\n                            0.145666670000000,\n                            0.145866670000000,\n                            0.146366670000000,\n                            0.146366670000000,\n                            0.146066670000000,\n                            0.145966670000000,\n                            0.145866670000000,\n                            0.146066670000000,\n                            0.146866670000000,\n                            0.146966670000000,\n                            0.146666670000000,\n                            0.146666670000000,\n                            0.146766670000000,\n                            0.146966670000000,\n                            0.146766670000000,\n                            0.146666670000000,\n                            0.146766670000000,\n                            0.146666670000000,\n                            0.147166670000000,\n                            0.147166670000000,\n                            0.147066670000000,\n                            0.147166670000000,\n                            0.146966670000000,\n                            0.146866670000000,\n                            0.147166670000000,\n                            0.147166670000000,\n                            0.147066670000000,\n                            0.147266670000000,\n                            0.147866670000000,\n                            0.147666670000000,\n                            0.147066670000000,\n                            0.147566670000000,\n                            0.147366670000000,\n                            0.147766670000000,\n                            0.147566670000000,\n                            0.147466670000000,\n                            0.147766670000000,\n                            0.147966670000000,\n                            0.147966670000000,\n                            0.147666670000000,\n                            0.147966670000000,\n                            0.148366670000000,\n                            0.148166670000000,\n                            0.148166670000000,\n                            0.148366670000000,\n                            0.148866670000000,\n                            0.148566670000000,\n                            0.148666670000000,\n                            0.148666670000000,\n                            0.148766670000000,\n                            0.149066670000000,\n                            0.148866670000000,\n                            0.148866670000000,\n                            0.148966670000000,\n                            0.148866670000000,\n                            0.148866670000000,\n                            0.149066670000000,\n                            0.148966670000000,\n                            0.149066670000000,\n                            0.149366670000000,\n                            0.149966670000000,\n                            0.149966670000000,\n                            0.149766670000000,\n                            0.149966670000000,\n                            0.149966670000000,\n                            0.149866670000000,\n                            0.149966670000000,\n                            0.150166670000000,\n                            0.150666670000000,\n                            0.150266670000000,\n                            0.150666670000000,\n                            0.150866670000000,\n                            0.151066670000000,\n                            0.151166670000000,\n                            0.150866670000000,\n                            0.150866670000000,\n                            0.151166670000000,\n                            0.151666670000000,\n                            0.152266670000000,\n                            0.152066670000000,\n                            0.151966670000000,\n                            0.152266670000000,\n                            0.152366670000000,\n                            0.152666670000000,\n                            0.152866670000000,\n                            0.153266670000000,\n                            0.153166670000000,\n                            0.153166670000000,\n                            0.153666670000000,\n                            0.153266670000000,\n                            0.153866670000000,\n                            0.154266670000000,\n                            0.154666670000000,\n                            0.154566670000000,\n                            0.154566670000000,\n                            0.154766670000000,\n                            0.154866670000000,\n                            0.154266670000000,\n                            0.154966670000000,\n                            0.155266670000000,\n                            0.155866670000000,\n                            0.155766670000000,\n                            0.156166670000000,\n                            0.156266670000000,\n                            0.156066670000000,\n                            0.156266670000000,\n                            0.156266670000000,\n                            0.156266670000000,\n                            0.156466670000000,\n                            0.156566670000000,\n                            0.156466670000000,\n                            0.156166670000000,\n                            0.156466670000000,\n                            0.156966670000000,\n                            0.156966670000000,\n                            0.156966670000000,\n                            0.157066670000000,\n                            0.157266670000000,\n                            0.157366670000000,\n                            0.157366670000000,\n                            0.157566670000000,\n                            0.157366670000000,\n                            0.157466670000000,\n                            0.157766670000000,\n                            0.157366670000000,\n                            0.157166670000000,\n                            0.157666670000000,\n                            0.157366670000000,\n                            0.157366670000000,\n                            0.157266670000000,\n                            0.157466670000000,\n                            0.157166670000000,\n                            0.156966670000000,\n                            0.157066670000000,\n                            0.156866670000000,\n                            0.156766670000000,\n                            0.156766670000000,\n                            0.156966670000000,\n                            0.156866670000000,\n                            0.156766670000000,\n                            0.156566670000000,\n                            0.156466670000000,\n                            0.156666670000000,\n                            0.155966670000000,\n                            0.155666670000000,\n                            0.155966670000000,\n                            0.155866670000000,\n                            0.155566670000000,\n                            0.155966670000000,\n                            0.156866670000000,\n                            0.156566670000000,\n                            0.156466670000000,\n                            0.156366670000000,\n                            0.155766670000000,\n                            0.155766670000000,\n                            0.155666670000000,\n                            0.155266670000000,\n                            0.154866670000000,\n                            0.155466670000000,\n                            0.154866670000000,\n                            0.154966670000000,\n                            0.154966670000000,\n                            0.154566670000000,\n                            0.154566670000000,\n                            0.153966670000000,\n                            0.154066670000000,\n                            0.154066670000000,\n                            0.153966670000000,\n                            0.154166670000000,\n                            0.154066670000000,\n                            0.153666670000000,\n                            0.153666670000000,\n                            0.153866670000000,\n                            0.153566670000000,\n                            0.153066670000000,\n                            0.153066670000000,\n                            0.153066670000000,\n                            0.152666670000000,\n                            0.152866670000000,\n                            0.153066670000000,\n                            0.153066670000000,\n                            0.152766670000000,\n                            0.152566670000000,\n                            0.152466670000000,\n                            0.152466670000000,\n                            0.152666670000000,\n                            0.152466670000000,\n                            0.152266670000000,\n                            0.152066670000000,\n                            0.152366670000000,\n                            0.152266670000000,\n                            0.152166670000000,\n                            0.151766670000000,\n                            0.151666670000000,\n                            0.151866670000000,\n                            0.151966670000000,\n                            0.151666670000000,\n                            0.151566670000000,\n                            0.151866670000000,\n                            0.151366670000000,\n                            0.151366670000000,\n                            0.151466670000000,\n                            0.151466670000000,\n                            0.151466670000000,\n                            0.151566670000000,\n                            0.151466670000000,\n                            0.151566670000000,\n                            0.151266670000000,\n                            0.151466670000000,\n                            0.151166670000000,\n                            0.151066670000000,\n                            0.151566670000000,\n                            0.151566670000000,\n                            0.151766670000000,\n                            0.152066670000000,\n                            0.151866670000000,\n                            0.151666670000000,\n                            0.151766670000000,\n                            0.151966670000000,\n                            0.151766670000000,\n                            0.151966670000000,\n                            0.152366670000000,\n                            0.152666670000000,\n                            0.152566670000000,\n                            0.152466670000000,\n                            0.152566670000000,\n                            0.152166670000000,\n                            0.151766670000000,\n                            0.152266670000000,\n                            0.152266670000000,\n                            0.151866670000000,\n                            0.152066670000000,\n                            0.152166670000000,\n                            0.152266670000000,\n                            0.152466670000000,\n                            0.152166670000000,\n                            0.152066670000000,\n                            0.152066670000000,\n                            0.152666670000000,\n                            0.152666670000000,\n                            0.152166670000000,\n                            0.152066670000000,\n                            0.151666670000000,\n                            0.151566670000000,\n                            0.150966670000000,\n                            0.150366670000000,\n                            0.150566670000000,\n                            0.150366670000000,\n                            0.150866670000000,\n                            0.150766670000000,\n                            0.150966670000000,\n                            0.151266670000000,\n                            0.150966670000000,\n                            0.150966670000000,\n                            0.150966670000000,\n                            0.150766670000000,\n                            0.151066670000000,\n                            0.151266670000000,\n                            0.151966670000000,\n                            0.151966670000000,\n                            0.151566670000000,\n                            0.151666670000000,\n                            0.151466670000000,\n                            0.151966670000000,\n                            0.152166670000000,\n                            0.152066670000000,\n                            0.152166670000000,\n                            0.152266670000000,\n                            0.152666670000000,\n                            0.152266670000000,\n                            0.151766670000000,\n                            0.152166670000000,\n                            0.152166670000000,\n                            0.151866670000000,\n                            0.152066670000000,\n                            0.152166670000000,\n                            0.152366670000000,\n                            0.152666670000000,\n                            0.153066670000000,\n                            0.152766670000000,\n                            0.152566670000000,\n                            0.152466670000000,\n                            0.152266670000000,\n                            0.152366670000000,\n                            0.152166670000000,\n                            0.152466670000000,\n                            0.152266670000000,\n                            0.152066670000000,\n                            0.153366670000000,\n                            0.153166670000000,\n                            0.153066670000000,\n                            0.153166670000000,\n                            0.152866670000000,\n                            0.153066670000000,\n                            0.153266670000000,\n                            0.153166670000000,\n                            0.153266670000000,\n                            0.153266670000000,\n                            0.153666670000000,\n                            0.153566670000000,\n                            0.154166670000000,\n                            0.153366670000000,\n                            0.152766670000000,\n                            0.153166670000000,\n                            0.153866670000000,\n                            0.153566670000000,\n                            0.153866670000000,\n                            0.154166670000000,\n                            0.154766670000000,\n                            0.154666670000000,\n                            0.154966670000000,\n                            0.155166670000000,\n                            0.155166670000000,\n                            0.155366670000000,\n                            0.155366670000000,\n                            0.155466670000000,\n                            0.155466670000000,\n                            0.156166670000000,\n                            0.156166670000000,\n                            0.155866670000000,\n                            0.155566670000000,\n                            0.155466670000000,\n                            0.155366670000000,\n                            0.154966670000000,\n                            0.154966670000000,\n                            0.154866670000000,\n                            0.154066670000000,\n                            0.154366670000000,\n                            0.155366670000000,\n                            0.154466670000000,\n                            0.153866670000000,\n                            0.153866670000000,\n                            0.153766670000000,\n                            0.153566670000000,\n                            0.153766670000000,\n                            0.154266670000000,\n                            0.154366670000000,\n                            0.154366670000000,\n                            0.154766670000000,\n                            0.154966670000000,\n                            0.154966670000000,\n                            0.154666670000000,\n                            0.155466670000000,\n                            0.155666670000000,\n                            0.156166670000000,\n                            0.156466670000000,\n                            0.156366670000000,\n                            0.156166670000000,\n                            0.156966670000000,\n                            0.155966670000000,\n                            0.154966670000000,\n                            0.154466670000000,\n                            0.152766670000000,\n                            0.151866670000000,\n                            0.151066670000000,\n                            0.150066670000000,\n                            0.148566670000000,\n                            0.148066670000000,\n                            0.147366670000000,\n                            0.146166670000000,\n                            0.145466670000000,\n                            0.144266670000000,\n                            0.143666670000000,\n                            0.143766670000000,\n                            0.143066670000000,\n                            0.142366670000000,\n                            0.141466670000000,\n                            0.141666670000000,\n                            0.141166670000000,\n                            0.140166670000000,\n                            0.139566670000000,\n                            0.139266670000000,\n                            0.138166670000000,\n                            0.137666670000000,\n                            0.136666670000000,\n                            0.136166670000000,\n                            0.134766670000000,\n                            0.134066670000000,\n                            0.132966670000000,\n                            0.132166670000000,\n                            0.131066670000000,\n                            0.130366670000000,\n                            0.129366670000000,\n                            0.128366670000000,\n                            0.127166670000000,\n                            0.126666670000000,\n                            0.124966670000000,\n                            0.124066670000000,\n                            0.123866670000000,\n                            0.123266670000000,\n                            0.121466670000000,\n                            0.121966670000000,\n                            0.121266670000000,\n                            0.120666670000000,\n                            0.120066670000000,\n                            0.119766670000000,\n                            0.118866670000000,\n                            0.118466670000000,\n                            0.118566670000000,\n                            0.118966670000000,\n                            0.118266670000000,\n                            0.117466670000000,\n                            0.118066670000000,\n                            0.117666670000000,\n                            0.117266670000000,\n                            0.117966670000000,\n                            0.118166670000000,\n                            0.117666670000000,\n                            0.117766670000000,\n                            0.117766670000000,\n                            0.117666670000000,\n                            0.117466670000000,\n                            0.117866670000000,\n                            0.118366670000000,\n                            0.118766670000000,\n                            0.118366670000000,\n                            0.118766670000000,\n                            0.119166670000000,\n                            0.119766670000000,\n                            0.118866670000000,\n                            0.118766670000000,\n                            0.119166670000000,\n                            0.119266670000000,\n                            0.119366670000000,\n                            0.119866670000000,\n                            0.119966670000000,\n                            0.120066670000000,\n                            0.120566670000000,\n                            0.120966670000000,\n                            0.120666670000000,\n                            0.120566670000000,\n                            0.120566670000000,\n                            0.120766670000000,\n                            0.120766670000000,\n                            0.121066670000000,\n                            0.121066670000000,\n                            0.120866670000000,\n                            0.121166670000000,\n                            0.121766670000000,\n                            0.121466670000000,\n                            0.121166670000000,\n                            0.121466670000000,\n                            0.121366670000000,\n                            0.121566670000000,\n                            0.121466670000000,\n                            0.121466670000000,\n                            0.121666670000000,\n                            0.121766670000000,\n                            0.122566670000000,\n                            0.122566670000000,\n                            0.122566670000000,\n                            0.122966670000000,\n                            0.123666670000000,\n                            0.124266670000000,\n                            0.124466670000000,\n                            0.124866670000000,\n                            0.125966670000000,\n                            0.125966670000000,\n                            0.127266670000000,\n                            0.127666670000000,\n                            0.128466670000000,\n                            0.128366670000000,\n                            0.128866670000000,\n                            0.129066670000000,\n                            0.129366670000000,\n                            0.129366670000000,\n                            0.129466670000000,\n                            0.129766670000000,\n                            0.130466670000000,\n                            0.130466670000000,\n                            0.130866670000000,\n                            0.131066670000000,\n                            0.131466670000000,\n                            0.131866670000000,\n                            0.132366670000000,\n                            0.132266670000000,\n                            0.132666670000000,\n                            0.133166670000000,\n                            0.133366670000000,\n                            0.133166670000000,\n                            0.133566670000000,\n                            0.133866670000000,\n                            0.133966670000000,\n                            0.134166670000000,\n                            0.134366670000000,\n                            0.134266670000000,\n                            0.134166670000000,\n                            0.134266670000000,\n                            0.135066670000000,\n                            0.134766670000000,\n                            0.134566670000000,\n                            0.134466670000000,\n                            0.134066670000000,\n                            0.134066670000000,\n                            0.133566670000000,\n                            0.133266670000000,\n                            0.133466670000000,\n                            0.133266670000000,\n                            0.133966670000000,\n                            0.133666670000000,\n                            0.133066670000000,\n                            0.133466670000000,\n                            0.133366670000000,\n                            0.133266670000000,\n                            0.133466670000000,\n                            0.133466670000000,\n                            0.133066670000000,\n                            0.132866670000000,\n                            0.132766670000000,\n                            0.132366670000000,\n                            0.132166670000000,\n                            0.131966670000000,\n                            0.131566670000000,\n                            0.131866670000000,\n                            0.131266670000000,\n                            0.131066670000000,\n                            0.130866670000000,\n                            0.130766670000000,\n                            0.130866670000000,\n                            0.130466670000000,\n                            0.129966670000000,\n                            0.129866670000000,\n                            0.129566670000000,\n                            0.129666670000000,\n                            0.129366670000000,\n                            0.128866670000000,\n                            0.128266670000000,\n                            0.128366670000000,\n                            0.128366670000000,\n                            0.127766670000000,\n                            0.127466670000000,\n                            0.127166670000000,\n                            0.126766670000000,\n                            0.126666670000000,\n                            0.126466670000000,\n                            0.126466670000000,\n                            0.126066670000000,\n                            0.125866670000000,\n                            0.125766670000000,\n                            0.125366670000000,\n                            0.125366670000000,\n                            0.124766670000000,\n                            0.124266670000000,\n                            0.123866670000000,\n                            0.123266670000000,\n                            0.123566670000000,\n                            0.123066670000000,\n                            0.122766670000000,\n                            0.122866670000000,\n                            0.122666670000000,\n                            0.122466670000000,\n                            0.122366670000000,\n                            0.122066670000000,\n                            0.121866670000000,\n                            0.121466670000000,\n                            0.121566670000000,\n                            0.121266670000000,\n                            0.120766670000000,\n                            0.121366670000000,\n                            0.120966670000000,\n                            0.120266670000000,\n                            0.120266670000000,\n                            0.120066670000000,\n                            0.119766670000000,\n                            0.120066670000000,\n                            0.120266670000000,\n                            0.119766670000000,\n                            0.119366670000000,\n                            0.119666670000000,\n                            0.119366670000000,\n                            0.119566670000000,\n                            0.119266670000000,\n                            0.118566670000000,\n                            0.118466670000000,\n                            0.119066670000000,\n                            0.118766670000000,\n                            0.118666670000000,\n                            0.118666670000000,\n                            0.119366670000000,\n                            0.119166670000000,\n                            0.119666670000000,\n                            0.118866670000000,\n                            0.118266670000000,\n                            0.118666670000000,\n                            0.119166670000000,\n                            0.118866670000000,\n                            0.118466670000000,\n                            0.118566670000000,\n                            0.119066670000000,\n                            0.118166670000000,\n                            0.119066670000000,\n                            0.118866670000000,\n                            0.118766670000000,\n                            0.118666670000000,\n                            0.118766670000000,\n                            0.119466670000000,\n                            0.118666670000000,\n                            0.118766670000000,\n                            0.119266670000000,\n                            0.118566670000000,\n                            0.118866670000000,\n                            0.119166670000000,\n                            0.118766670000000,\n                            0.118866670000000,\n                            0.118666670000000,\n                            0.119366670000000,\n                            0.119266670000000,\n                            0.119166670000000,\n                            0.119866670000000,\n                            0.120166670000000,\n                            0.119566670000000,\n                            0.120166670000000,\n                            0.120466670000000,\n                            0.119966670000000,\n                            0.120166670000000,\n                            0.120166670000000,\n                            0.120066670000000,\n                            0.119166670000000,\n                            0.120666670000000,\n                            0.120466670000000,\n                            0.120166670000000,\n                            0.120266670000000,\n                            0.119966670000000,\n                            0.119866670000000,\n                            0.120866670000000,\n                            0.120566670000000,\n                            0.120866670000000,\n                            0.121366670000000,\n                            0.121566670000000,\n                            0.121466670000000,\n                            0.121566670000000,\n                            0.122166670000000,\n                            0.123066670000000,\n                            0.124166670000000,\n                            0.123766670000000,\n                            0.122766670000000,\n                            0.123466670000000,\n                            0.124066670000000,\n                            0.125466670000000,\n                            0.124666670000000,\n                            0.124366670000000,\n                            0.124266670000000,\n                            0.124066670000000,\n                            0.124366670000000,\n                            0.124866670000000,\n                            0.124266670000000,\n                            0.124966670000000,\n                            0.125366670000000,\n                            0.125466670000000,\n                            0.124766670000000,\n                            0.124166670000000,\n                            0.124366670000000,\n                            0.124566670000000,\n                            0.123966670000000,\n                            0.124366670000000,\n                            0.124166670000000,\n                            0.124766670000000,\n                            0.124866670000000,\n                            0.125766670000000,\n                            0.126066670000000,\n                            0.125166670000000,\n                            0.126466670000000,\n                            0.126466670000000,\n                            0.126266670000000,\n                            0.127066670000000,\n                            0.127766670000000,\n                            0.127366670000000,\n                            0.126366670000000,\n                            0.128266670000000,\n                            0.127966670000000,\n                            0.127366670000000,\n                            0.127666670000000,\n                            0.128366670000000,\n                            0.127566670000000,\n                            0.126866670000000,\n                            0.127266670000000,\n                            0.128766670000000,\n                            0.127966670000000,\n                            0.129466670000000,\n                            0.130066670000000,\n                            0.129866670000000,\n                            0.128666670000000,\n                            0.128166670000000,\n                            0.129366670000000,\n                            0.128266670000000,\n                            0.127366670000000,\n                            0.129166670000000,\n                            0.128166670000000,\n                            0.130766670000000,\n                            0.130766670000000,\n                            0.130566670000000,\n                            0.129566670000000,\n                            0.128366670000000,\n                            0.128366670000000,\n                            0.128766670000000,\n                            0.127366670000000,\n                            0.127966670000000,\n                            0.128066670000000,\n                            0.129066670000000,\n                            0.127766670000000,\n                            0.127266670000000,\n                            0.127966670000000,\n                            0.129366670000000,\n                            0.129166670000000,\n                            0.128266670000000,\n                            0.127666670000000,\n                            0.125066670000000,\n                            0.124566670000000,\n                            0.126166670000000,\n                            0.124966670000000,\n                            0.125866670000000,\n                            0.127566670000000,\n                            0.125566670000000,\n                            0.125466670000000,\n                            0.122366670000000,\n                            0.123766670000000,\n                            0.121066670000000,\n                            0.119666670000000,\n                            0.122366670000000,\n                            0.120966670000000,\n                            0.119566670000000,\n                            0.120766670000000,\n                            0.119966670000000,\n                            0.119666670000000,\n                            0.118066670000000,\n                            0.119066670000000,\n                            0.118666670000000,\n                            0.116166670000000,\n                            0.117266670000000,\n                            0.119666670000000,\n                            0.118566670000000,\n                            0.115766670000000,\n                            0.115266670000000,\n                            0.116666670000000,\n                            0.116466670000000,\n                            0.116066670000000,\n                            0.112066670000000,\n                            0.111066670000000,\n                            0.112866670000000,\n                            0.113366670000000,\n                            0.114266670000000,\n                            0.112766670000000,\n                            0.112166670000000,\n                            0.113766670000000,\n                            0.110966670000000,\n                            0.111066670000000,\n                            0.111466670000000,\n                            0.112766670000000,\n                            0.112866670000000,\n                            0.111966670000000,\n                            0.110666670000000,\n                            0.111066670000000,\n                            0.113266670000000,\n                            0.112366670000000,\n                            0.110966670000000,\n                            0.110166670000000,\n                            0.110566670000000,\n                            0.111666670000000,\n                            0.113066670000000,\n                            0.111166670000000,\n                            0.112366670000000,\n                            0.114466670000000,\n                            0.112266670000000,\n                            0.111066670000000,\n                            0.111966670000000,\n                            0.111466670000000,\n                            0.110366670000000,\n                            0.109466670000000,\n                            0.114066670000000,\n                            0.113466670000000,\n                            0.113366670000000,\n                            0.114566670000000,\n                            0.113966670000000,\n                            0.115766670000000,\n                            0.113366670000000,\n                            0.113366670000000,\n                            0.111766670000000,\n                            0.107366670000000,\n                            0.111066670000000,\n                            0.112666670000000,\n                            0.110066670000000,\n                            0.112066670000000,\n                            0.113466670000000,\n                            0.114266670000000,\n                            0.113066670000000,\n                            0.114066670000000,\n                            0.107566670000000,\n                            0.108066670000000,\n                            0.116366670000000,\n                            0.116666670000000,\n                            0.115266670000000,\n                            0.112266670000000,\n                            0.114466670000000,\n                            0.114066670000000,\n                            0.113166670000000,\n                            0.111466670000000,\n                            0.109266670000000,\n                            0.109466670000000,\n                            0.111466670000000,\n                            0.110066670000000,\n                            0.111266670000000,\n                            0.111166670000000,\n                            0.111166670000000,\n                            0.109866670000000,\n                            0.110066670000000,\n                            0.109966670000000,\n                            0.106266670000000,\n                            0.107566670000000,\n                            0.111766670000000,\n                            0.112066670000000,\n                            0.111866670000000,\n                            0.110366670000000,\n                            0.107466670000000,\n                            0.107366670000000,\n                            0.111966670000000,\n                            0.108066670000000,\n                            0.108666670000000,\n                            0.109066670000000,\n                            0.111466670000000,\n                            0.107166670000000,\n                            0.104366670000000,\n                            0.107766670000000,\n                            0.110766670000000,\n                            0.110666670000000,\n                            0.110366670000000,\n                            0.110566670000000,\n                            0.111266670000000,\n                            0.111266670000000,\n                            0.113866670000000,\n                            0.111566670000000,\n                            0.109466670000000,\n                            0.108666670000000,\n                            0.110466670000000,\n                            0.109866670000000,\n                            0.105266670000000,\n                            0.109966670000000,\n                            0.108666670000000,\n                            0.107466670000000,\n                            0.112766670000000,\n                            0.112366670000000,\n                            0.111966670000000,\n                            0.107366670000000,\n                            0.110266670000000,\n                            0.110666670000000,\n                            0.109566670000000,\n                            0.110466670000000,\n                            0.110866670000000,\n                            0.111566670000000,\n                            0.109166670000000,\n                            0.108766670000000,\n                            0.104266670000000,\n                            0.106766670000000,\n                            0.107866670000000,\n                            0.107566670000000,\n                            0.109466670000000,\n                            0.109366670000000,\n                            0.106666670000000,\n                            0.107566670000000,\n                            0.116166670000000,\n                            0.114266670000000,\n                            0.114466670000000,\n                            0.112966670000000,\n                            0.109466670000000,\n                            0.109566670000000,\n                            0.107366670000000,\n                            0.105566670000000,\n                            0.109866670000000,\n                            0.115766670000000,\n                            0.117766670000000,\n                            0.113166670000000,\n                            0.111566670000000,\n                            0.113766670000000,\n                            0.112966670000000,\n                            0.111766670000000,\n                            0.114266670000000,\n                            0.113666670000000,\n                            0.108866670000000,\n                            0.108766670000000,\n                            0.113166670000000,\n                            0.112966670000000,\n                            0.111966670000000,\n                            0.111366670000000,\n                            0.111566670000000,\n                            0.111466670000000,\n                            0.110066670000000,\n                            0.111066670000000,\n                            0.113266670000000,\n                            0.107466670000000,\n                            0.114166670000000,\n                            0.113266670000000,\n                            0.111666670000000,\n                            0.108766670000000,\n                            0.105666670000000,\n                            0.106766670000000,\n                            0.106666670000000,\n                            0.111266670000000,\n                            0.109266670000000,\n                            0.107466670000000,\n                            0.112366670000000,\n                            0.113366670000000,\n                            0.110066670000000,\n                            0.106366670000000,\n                            0.109166670000000,\n                            0.111166670000000,\n                            0.105466670000000,\n                            0.102966670000000,\n                            0.105966670000000,\n                            0.106266670000000,\n                            0.112866670000000,\n                            0.111366670000000,\n                            0.107766670000000,\n                            0.106366670000000,\n                            0.104766670000000,\n                            0.108966670000000,\n                            0.109366670000000,\n                            0.107966670000000,\n                            0.106066670000000,\n                            0.106666670000000,\n                            0.105966670000000,\n                            0.103066670000000,\n                            0.102766670000000,\n                            0.103266670000000,\n                            0.099166667000000,\n                            0.105166670000000,\n                            0.105066670000000,\n                            0.101866670000000,\n                            0.104666670000000,\n                            0.106366670000000,\n                            0.105966670000000,\n                            0.100866670000000,\n                            0.101566670000000,\n                            0.107166670000000,\n                            0.105966670000000,\n                            0.104966670000000,\n                            0.105466670000000,\n                            0.112866670000000,\n                            0.106266670000000,\n                            0.104466670000000,\n                            0.106666670000000,\n                            0.103566670000000,\n                            0.103066670000000,\n                            0.097566667000000,\n                            0.108366670000000,\n                            0.103966670000000,\n                            0.102266670000000,\n                            0.100266670000000,\n                            0.102866670000000,\n                            0.094066667000000,\n                            0.104766670000000,\n                            0.104166670000000,\n                            0.091766667000000,\n                            0.090566667000000,\n                            0.094666667000000,\n                            0.098866667000000,\n                            0.095666667000000,\n                            0.096666667000000,\n                            0.094366667000000,\n                            0.091066667000000,\n                            0.097966667000000,\n                            0.095066667000000,\n                            0.099266667000000,\n                            0.091966667000000,\n                            0.094966667000000,\n                            0.099266667000000,\n                            0.094466667000000,\n                            0.088366667000000,\n                            0.092566667000000,\n                            0.096466667000000,\n                            0.094366667000000,\n                            0.092866667000000,\n                            0.102266670000000,\n                            0.095266667000000,\n                            0.089366667000000,\n                            0.098566667000000,\n                            0.099466667000000,\n                            0.095866667000000,\n                            0.085666667000000,\n                            0.091066667000000,\n                            0.103866670000000,\n                            0.097166667000000,\n                            0.102766670000000,\n                            0.101766670000000,\n                            0.099366667000000,\n                            0.094266667000000,\n                            0.091166667000000,\n                            0.091466667000000,\n                            0.084366667000000,\n                            0.085066667000000,\n                            0.100666670000000,\n                            0.101466670000000,\n                            0.098766667000000,\n                            0.097666667000000,\n                            0.097466667000000,\n                            0.091866667000000,\n                            0.084666667000000,\n                            0.094666667000000,\n                            0.096566667000000,\n                            0.087066667000000,\n                            0.107666670000000,\n                            0.099666667000000,\n                            0.093566667000000,\n                            0.093566667000000,\n                            0.094666667000000,\n                            0.093066667000000,\n                            0.086266667000000,\n                            0.085966667000000,\n                            0.092266667000000,\n                            0.097966667000000,\n                            0.099166667000000,\n                            0.097866667000000,\n                            0.088466667000000,\n                            0.092166667000000,\n                            0.096066667000000,\n                            0.097566667000000,\n                            0.107766670000000,\n                            0.098166667000000,\n                            0.092066667000000,\n                            0.097566667000000,\n                            0.107966670000000,\n                            0.093366667000000,\n                            0.102966670000000,\n                            0.106766670000000,\n                            0.100166670000000,\n                            0.104166670000000,\n                            0.099166667000000,\n                            0.098266667000000,\n                            0.095166667000000,\n                            0.104766670000000,\n                            0.098166667000000,\n                            0.101566670000000,\n                            0.097566667000000,\n                            0.099966667000000,\n                            0.085066667000000,\n                            0.084866667000000,\n                            0.094266667000000,\n                            0.087966667000000,\n                            0.094566667000000,\n                            0.104766670000000,\n                            0.104866670000000,\n                            0.106666670000000,\n                            0.104166670000000,\n                            0.115366670000000,\n                            0.110066670000000,\n                            0.103766670000000,\n                            0.104066670000000,\n                            0.100766670000000,\n                            0.112366670000000,\n                            0.106266670000000,\n                            0.116066670000000,\n                            0.122966670000000,\n                            0.106366670000000,\n                            0.104566670000000,\n                            0.114966670000000,\n                            0.122566670000000,\n                            0.115766670000000,\n                            0.122266670000000,\n                            0.112866670000000,\n                            0.106066670000000,\n                            0.128666670000000,\n                            0.128066670000000,\n                            0.120866670000000,\n                            0.101866670000000,\n                            0.108366670000000,\n                            0.114366670000000,\n                            0.114466670000000,\n                            0.113466670000000,\n                            0.110566670000000,\n                            0.096666667000000,\n                            0.118666670000000,\n                            0.115566670000000,\n                            0.107166670000000,\n                            0.111266670000000,\n                            0.117166670000000,\n                            0.120366670000000,\n                            0.123066670000000,\n                            0.102666670000000,\n                            0.098766667000000,\n                            0.117266670000000,\n                            0.145466670000000,\n                            0.123366670000000,\n                            0.123666670000000,\n                            0.134666670000000,\n                            0.129566670000000,\n                            0.135366670000000,\n                            0.120466670000000,\n                            0.108766670000000,\n                            0.112166670000000,\n                            0.100266670000000,\n                            0.128266670000000,\n                            0.129966670000000,\n                            0.118766670000000,\n                            0.133766670000000,\n                            0.129966670000000,\n                            0.125766670000000,\n                            0.127166670000000,\n                            0.119066670000000,\n                            0.116466670000000,\n                            0.115366670000000,\n                            0.124166670000000,\n                            0.116166670000000,\n                            0.109866670000000,\n                            0.110566670000000,\n                            0.116766670000000,\n                            0.110366670000000,\n                            0.111666670000000,\n                            0.113966670000000,\n                            0.107866670000000,\n                            0.107066670000000,\n                            0.118166670000000,\n                            0.110466670000000,\n                            0.109166670000000,\n                            0.105866670000000,\n                            0.095566667000000,\n                            0.095566667000000,\n                            0.097366667000000,\n                            0.096366667000000,\n                            0.092966667000000,\n                            0.088466667000000,\n                            0.092366667000000,\n                            0.093266667000000,\n                            0.095566667000000,\n                            0.096666667000000,\n                            0.102666670000000,\n                            0.100966670000000,\n                            0.092066667000000,\n                            0.090066667000000,\n                            0.093066667000000,\n                            0.089966667000000,\n                            0.095766667000000,\n                            0.097966667000000,\n                            0.099966667000000,\n                            0.094166667000000,\n                            0.092366667000000,\n                            0.097866667000000,\n                            0.094966667000000,\n                            0.093866667000000,\n                            0.094066667000000,\n                            0.097466667000000,\n                            0.106466670000000,\n                            0.099966667000000,\n                            0.102966670000000,\n                            0.098166667000000,\n                            0.103566670000000,\n                            0.106166670000000,\n                            0.103366670000000,\n                            0.103466670000000,\n                            0.092766667000000,\n                            0.095466667000000,\n                            0.114066670000000,\n                            0.099866667000000,\n                            0.094766667000000,\n                            0.105166670000000,\n                            0.092566667000000,\n                            0.093666667000000,\n                            0.080566667000000,\n                            0.081866667000000,\n                            0.080866667000000,\n                            0.075166667000000,\n                            0.101966670000000,\n                            0.093266667000000,\n                            0.074666667000000,\n                            0.078366667000000,\n                            0.085066667000000,\n                            0.089066667000000,\n                            0.087566667000000,\n                            0.091166667000000,\n                            0.098666667000000,\n                            0.092466667000000,\n                            0.139666670000000,\n                            0.083266667000000,\n                            0.064766667000000,\n                            0.087166667000000,\n                            0.156066670000000,\n                            0.181266670000000,\n                            0.122966670000000,\n                            0.173566670000000,\n                            0.207666670000000,\n                            0.213466670000000,\n                            0.178966670000000,\n                            0.277466670000000,\n                        ]\n                    ),\n                ),\n                DatasetLoader_AgfaIT872Set(): (\n                    \"agfa\",\n                    289,\n                    \"5\",\n                    np.array(\n                        [\n                            8.6300000000000000,\n                            12.090000000000000,\n                            14.140000000000000,\n                            14.020000000000000,\n                            14.160000000000000,\n                            14.190000000000000,\n                            14.250000000000000,\n                            14.530000000000000,\n                            14.810000000000000,\n                            14.880000000000000,\n                            14.480000000000000,\n                            13.610000000000000,\n                            12.600000000000000,\n                            11.720000000000000,\n                            11.600000000000000,\n                            12.690000000000000,\n                            14.160000000000000,\n                            16.350000000000000,\n                            18.900000000000000,\n                            20.870000000000000,\n                            21.630000000000000,\n                            21.230000000000000,\n                            20.360000000000000,\n                            19.520000000000000,\n                            18.790000000000000,\n                            18.400000000000000,\n                            18.530000000000000,\n                            19.180000000000000,\n                            20.460000000000000,\n                            22.580000000000000,\n                            25.470000000000000,\n                        ]\n                    ),\n                ),\n            }\n            for dataset_loader, values in dataset_loaders.items():\n>               assert len(dataset_loader.load()[values[0]]) == values[1]\n\ncolour_datasets\\loaders\\tests\\test_kuopio.py:3615: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\kuopio.py:186: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD866BFBA0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8641E340>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD866BC...ocals>.inner at 0x000001AD866BCCC0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD866BE980>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019::test_required_attributes",
      "lineno": 31,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Labsphere2019",
        "test_labsphere2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019::test_required_methods",
      "lineno": 39,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Labsphere2019",
        "test_labsphere2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestDatasetLoader_Labsphere2019::test_load",
      "lineno": 47,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Labsphere2019",
        "test_labsphere2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_labsphere2019.py",
            "lineno": 55,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\labsphere2019.py",
            "lineno": 90,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Labsphere SRS-99-020 - Labsphere (2019)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3245874',\n     'conceptrecid': '3245874',\n     'created': '2019-06-14T09:30...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_labsphere2019.TestDatasetLoader_Labsphere2019 object at 0x000001AD84C0C080>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.labsphere2019.\\\n    DatasetLoader_Labsphere2019.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Labsphere2019()\n>           assert sorted(dataset.load().keys()) == [\"Labsphere SRS-99-020\"]\n\ncolour_datasets\\loaders\\tests\\test_labsphere2019.py:55: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\labsphere2019.py:90: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86471BC0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD869E5780>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86653...ocals>.inner at 0x000001AD86653600>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86653BA0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_labsphere2019.py::TestBuildLabsphere2019::test_build_Labsphere2019",
      "lineno": 66,
      "outcome": "failed",
      "keywords": [
        "test_build_Labsphere2019",
        "TestBuildLabsphere2019",
        "test_labsphere2019.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_labsphere2019.py",
            "lineno": 73,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\labsphere2019.py",
            "lineno": 137,
            "message": "in build_Labsphere2019"
          },
          {
            "path": "colour_datasets\\loaders\\labsphere2019.py",
            "lineno": 90,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Labsphere SRS-99-020 - Labsphere (2019)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3245874',\n     'conceptrecid': '3245874',\n     'created': '2019-06-14T09:30...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_labsphere2019.TestBuildLabsphere2019 object at 0x000001AD84C0C440>\n\n    def test_build_Labsphere2019(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.labsphere2019.build_Labsphere2019`\n        definition.\n        \"\"\"\n    \n>       assert build_Labsphere2019() is build_Labsphere2019()\n\ncolour_datasets\\loaders\\tests\\test_labsphere2019.py:73: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\labsphere2019.py:137: in build_Labsphere2019\n    _DATASET_LOADER_LABSPHERE2019.load()\ncolour_datasets\\loaders\\labsphere2019.py:90: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD866BF4C0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86246A80>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD864A3...ocals>.inner at 0x000001AD864A0180>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD864A1D00>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997::test_required_attributes",
      "lineno": 26,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Luo1997",
        "test_luo1997.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997::test_required_methods",
      "lineno": 34,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Luo1997",
        "test_luo1997.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestDatasetLoader_Luo1997::test_load",
      "lineno": 42,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Luo1997",
        "test_luo1997.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_luo1997.py",
            "lineno": 50,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\luo1997.py",
            "lineno": 202,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"LUTCHI Colour Appearance Data - Luo and Rhodes (1997)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/100 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.4394535',\n     'conceptrecid': '4394535',\n     'created': '2020-12-27T01:49...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_luo1997.TestDatasetLoader_Luo1997 object at 0x000001AD84C0CB60>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.luo1997.DatasetLoader_Luo1997.\\\n    load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Luo1997()\n>           assert len(dataset.load().keys()) == 8\n\ncolour_datasets\\loaders\\tests\\test_luo1997.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\luo1997.py:202: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86652980>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8678DB80>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86651...ocals>.inner at 0x000001AD86651580>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86650680>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1997.py::TestBuildLuo1997::test_build_Luo1997",
      "lineno": 177,
      "outcome": "failed",
      "keywords": [
        "test_build_Luo1997",
        "TestBuildLuo1997",
        "test_luo1997.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_luo1997.py",
            "lineno": 184,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\luo1997.py",
            "lineno": 1091,
            "message": "in build_Luo1997"
          },
          {
            "path": "colour_datasets\\loaders\\luo1997.py",
            "lineno": 202,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"LUTCHI Colour Appearance Data - Luo and Rhodes (1997)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/100 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.4394535',\n     'conceptrecid': '4394535',\n     'created': '2020-12-27T01:49...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_luo1997.TestBuildLuo1997 object at 0x000001AD84C0CEF0>\n\n    def test_build_Luo1997(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.luo1997.build_Luo1997`\n        definition.\n        \"\"\"\n    \n>       assert build_Luo1997() is build_Luo1997()\n\ncolour_datasets\\loaders\\tests\\test_luo1997.py:184: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\luo1997.py:1091: in build_Luo1997\n    _DATASET_LOADER_LUO1997.load()\ncolour_datasets\\loaders\\luo1997.py:202: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD863A0720>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86814940>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86651...ocals>.inner at 0x000001AD86650180>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86470A40>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999::test_required_attributes",
      "lineno": 26,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Luo1999",
        "test_luo1999.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999::test_required_methods",
      "lineno": 34,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Luo1999",
        "test_luo1999.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestDatasetLoader_Luo1999::test_load",
      "lineno": 42,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Luo1999",
        "test_luo1999.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_luo1999.py",
            "lineno": 50,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\luo1999.py",
            "lineno": 162,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Corresponding-Colour Datasets - Luo and Rhodes (1999)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/37 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3270787',\n     'conceptrecid': '3270787',\n     'created': '2019-07-07T20:55...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_luo1999.TestDatasetLoader_Luo1999 object at 0x000001AD84C0DB50>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.luo1999.DatasetLoader_Luo1999.\\\n    load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Luo1999()\n>           assert len(dataset.load().keys()) == 37\n\ncolour_datasets\\loaders\\tests\\test_luo1999.py:50: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\luo1999.py:162: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD863A1D00>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD867DD540>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD863A0...ocals>.inner at 0x000001AD863A07C0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD863A0E00>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_luo1999.py::TestBuildLuo1999::test_build_Luo1999",
      "lineno": 160,
      "outcome": "failed",
      "keywords": [
        "test_build_Luo1999",
        "TestBuildLuo1999",
        "test_luo1999.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_luo1999.py",
            "lineno": 167,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\luo1999.py",
            "lineno": 517,
            "message": "in build_Luo1999"
          },
          {
            "path": "colour_datasets\\loaders\\luo1999.py",
            "lineno": 162,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Corresponding-Colour Datasets - Luo and Rhodes (1999)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/37 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3270787',\n     'conceptrecid': '3270787',\n     'created': '2019-07-07T20:55...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_luo1999.TestBuildLuo1999 object at 0x000001AD84C0DF10>\n\n    def test_build_Luo1999(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.luo1999.build_Luo1999`\n        definition.\n        \"\"\"\n    \n>       assert build_Luo1999() is build_Luo1999()\n\ncolour_datasets\\loaders\\tests\\test_luo1999.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\luo1999.py:517: in build_Luo1999\n    _DATASET_LOADER_LUO1999.load()\ncolour_datasets\\loaders\\luo1999.py:162: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD862DCD60>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8684F040>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86376...ocals>.inner at 0x000001AD863760C0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86374180>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023::test_required_attributes",
      "lineno": 28,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Solomotav2023",
        "test_solomotav2023.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023::test_required_methods",
      "lineno": 36,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Solomotav2023",
        "test_solomotav2023.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestDatasetLoader_Solomotav2023::test_load",
      "lineno": 44,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Solomotav2023",
        "test_solomotav2023.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_solomotav2023.py",
            "lineno": 52,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\solomotav2023.py",
            "lineno": 94,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Camera Dataset - Solomatov and Akkaynak (2023)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.0s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_solomotav2023.TestDatasetLoader_Solomotav2023 object at 0x000001AD84C0C6B0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.solomotav2023.\\\n    DatasetLoader_Solomotav2023.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Solomotav2023()\n>           assert list(dataset.load().keys()) == [\"Estimated\", \"Ground Truth\"]\n\ncolour_datasets\\loaders\\tests\\test_solomotav2023.py:52: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\solomotav2023.py:94: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86375EE0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD867029C0>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD8639B...ocals>.inner at 0x000001AD8639BF60>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD8639AD40>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_solomotav2023.py::TestBuildSolomotav2023::test_build_Solomotav2023",
      "lineno": 64,
      "outcome": "failed",
      "keywords": [
        "test_build_Solomotav2023",
        "TestBuildSolomotav2023",
        "test_solomotav2023.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_solomotav2023.py",
            "lineno": 71,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\solomotav2023.py",
            "lineno": 150,
            "message": "in build_Solomotav2023"
          },
          {
            "path": "colour_datasets\\loaders\\solomotav2023.py",
            "lineno": 94,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Camera Dataset - Solomatov and Akkaynak (2023)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/8314702/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.0s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_solomotav2023.TestBuildSolomotav2023 object at 0x000001AD84C0EA50>\n\n    def test_build_Solomotav2023(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.solomotav2023.build_Solomotav2023`\n        definition.\n        \"\"\"\n    \n>       assert build_Solomotav2023() is build_Solomotav2023()\n\ncolour_datasets\\loaders\\tests\\test_solomotav2023.py:71: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\solomotav2023.py:150: in build_Solomotav2023\n    _DATASET_LOADER_SOLOMOTAV2023.load()\ncolour_datasets\\loaders\\solomotav2023.py:94: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD8639BE20>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86716B80>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD8639A...ocals>.inner at 0x000001AD86399BC0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD8639B880>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022::test_required_attributes",
      "lineno": 33,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Winquist2022",
        "test_winquist2022.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022::test_required_methods",
      "lineno": 41,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Winquist2022",
        "test_winquist2022.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestDatasetLoader_Winquist2022::test_load",
      "lineno": 49,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Winquist2022",
        "test_winquist2022.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_winquist2022.py",
            "lineno": 58,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\winquist2022.py",
            "lineno": 90,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Physlight - Camera Spectral Sensitivity Curves - Winquist et al. (2022)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/17 [0%] in 0.3s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_winquist2022.TestDatasetLoader_Winquist2022 object at 0x000001AD84C0F680>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test\n            :func:`colour_datasets.loaders.winquist2022.DatasetLoader_Winquist2022.\\\n    load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Winquist2022()\n>           assert len(dataset.load().keys()) == 17\n\ncolour_datasets\\loaders\\tests\\test_winquist2022.py:58: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\winquist2022.py:90: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86254E00>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD864BE9C0>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86256...ocals>.inner at 0x000001AD86255300>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD862549A0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_winquist2022.py::TestBuildWinquist2022::test_build_Winquist2022",
      "lineno": 72,
      "outcome": "failed",
      "keywords": [
        "test_build_Winquist2022",
        "TestBuildWinquist2022",
        "test_winquist2022.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_winquist2022.py",
            "lineno": 79,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\winquist2022.py",
            "lineno": 135,
            "message": "in build_Winquist2022"
          },
          {
            "path": "colour_datasets\\loaders\\winquist2022.py",
            "lineno": 90,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Physlight - Camera Spectral Sensitivity Curves - Winquist et al. (2022)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/6590768/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/17 [0%] in 0.0s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_winquist2022.TestBuildWinquist2022 object at 0x000001AD84C0FA40>\n\n    def test_build_Winquist2022(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.winquist2022.build_Winquist2022`\n        definition.\n        \"\"\"\n    \n>       assert build_Winquist2022() is build_Winquist2022()\n\ncolour_datasets\\loaders\\tests\\test_winquist2022.py:79: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\winquist2022.py:135: in build_Winquist2022\n    _DATASET_LOADER_WINQUIST2022.load()\ncolour_datasets\\loaders\\winquist2022.py:90: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD8639BF60>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD865C4B80>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD862C9...ocals>.inner at 0x000001AD862CB880>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD862CAAC0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016::test_required_attributes",
      "lineno": 25,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_XRite2016",
        "test_xrite2016.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016::test_required_methods",
      "lineno": 33,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_XRite2016",
        "test_xrite2016.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestDatasetLoader_XRite2016::test_load",
      "lineno": 41,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_XRite2016",
        "test_xrite2016.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_xrite2016.py",
            "lineno": 49,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\xrite2016.py",
            "lineno": 96,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"New Color Specifications for ColorChecker SG and Classic Charts - X-Rite (2016)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3245895\\downloads\\ColorChecker24_After_Nov2014.zip\" file during attempt 1, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3245895\\downloads\\ColorChecker24_After_Nov2014.zip\" file during attempt 2, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3245895\\downloads\\ColorChecker24_After_Nov2014.zip\" file during attempt 3, retrying...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/4 [0%] in 1.1s (0.00/s) \nDownloading files |\u26a0\ufe0e                                       | (!) 0/4 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3245894',\n     'conceptrecid': '3245894',\n     'created': '2019-06-14T09:38...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n>               urls_download(urls)\n\ncolour_datasets\\records\\zenodo.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:182: in url_download\n    with urllib.request.urlopen(url) as response:  # noqa: S310\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215: in urlopen\n    return opener.open(url, data, timeout)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521: in open\n    response = meth(req, response)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630: in http_response\n    response = self.parent.error(\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559: in error\n    return self._call_chain(*args)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x000001AD84CB4BC0>\nreq = <urllib.request.Request object at 0x000001AD866A1BE0>\nfp = <http.client.HTTPResponse object at 0x000001AD866A0D30>, code = 403\nmsg = 'Forbidden', hdrs = <http.client.HTTPMessage object at 0x000001AD866A2060>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 403: Forbidden\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_xrite2016.TestDatasetLoader_XRite2016 object at 0x000001AD84C44680>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.xrite2016.\\\n    DatasetLoader_XRite2016.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_XRite2016()\n>           assert sorted(dataset.load().keys()) == [\n                \"ColorChecker24 - After November 2014\",\n                \"ColorChecker24 - Before November 2014\",\n                \"ColorCheckerSG - After November 2014\",\n                \"ColorCheckerSG - Before November 2014\",\n            ]\n\ncolour_datasets\\loaders\\tests\\test_xrite2016.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\xrite2016.py:96: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD862C9580>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8640ADC0>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD863F4...ocals>.inner at 0x000001AD863F4CC0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD863F5620>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_xrite2016.py::TestBuildXRite2016::test_build_XRite2016",
      "lineno": 68,
      "outcome": "failed",
      "keywords": [
        "test_build_XRite2016",
        "TestBuildXRite2016",
        "test_xrite2016.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_xrite2016.py",
            "lineno": 75,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\xrite2016.py",
            "lineno": 193,
            "message": "in build_XRite2016"
          },
          {
            "path": "colour_datasets\\loaders\\xrite2016.py",
            "lineno": 96,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"New Color Specifications for ColorChecker SG and Classic Charts - X-Rite (2016)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3245895/files/urls.txt/content\" url \non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3245895\\downloads\\ColorChecker24_After_Nov2014.zip\" file during attempt 1, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3245895\\downloads\\ColorChecker24_After_Nov2014.zip\" file during attempt 2, retrying...\non 0: An error occurred while downloading \"C:\\Users\\Mohay\\.colour-science\\colour-datasets\\3245895\\downloads\\ColorChecker24_After_Nov2014.zip\" file during attempt 3, retrying...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/4 [0%] in 1.0s (0.00/s) \nDownloading files |\u26a0\ufe0e                                       | (!) 0/4 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3245894',\n     'conceptrecid': '3245894',\n     'created': '2019-06-14T09:38...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n>               urls_download(urls)\n\ncolour_datasets\\records\\zenodo.py:419: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:182: in url_download\n    with urllib.request.urlopen(url) as response:  # noqa: S310\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:215: in urlopen\n    return opener.open(url, data, timeout)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:521: in open\n    response = meth(req, response)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:630: in http_response\n    response = self.parent.error(\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:559: in error\n    return self._call_chain(*args)\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:492: in _call_chain\n    result = func(*args)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <urllib.request.HTTPDefaultErrorHandler object at 0x000001AD84CB4BC0>\nreq = <urllib.request.Request object at 0x000001AD866E7770>\nfp = <http.client.HTTPResponse object at 0x000001AD866E7D60>, code = 403\nmsg = 'Forbidden', hdrs = <http.client.HTTPMessage object at 0x000001AD866E4860>\n\n    def http_error_default(self, req, fp, code, msg, hdrs):\n>       raise HTTPError(req.full_url, code, msg, hdrs, fp)\nE       urllib.error.HTTPError: HTTP Error 403: Forbidden\n\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:639: HTTPError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.loaders.tests.test_xrite2016.TestBuildXRite2016 object at 0x000001AD84C0F470>\n\n    def test_build_XRite2016(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.xrite2016.build_XRite2016`\n        definition.\n        \"\"\"\n    \n>       assert build_XRite2016() is build_XRite2016()\n\ncolour_datasets\\loaders\\tests\\test_xrite2016.py:75: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\xrite2016.py:193: in build_XRite2016\n    _DATASET_LOADER_XRITE2016.load()\ncolour_datasets\\loaders\\xrite2016.py:96: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD8663F2E0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8696EC40>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD866EB...ocals>.inner at 0x000001AD866EB9C0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD866EB6A0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009::test_required_attributes",
      "lineno": 25,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestDatasetLoader_Zhao2009",
        "test_zhao2009.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009::test_required_methods",
      "lineno": 33,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestDatasetLoader_Zhao2009",
        "test_zhao2009.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestDatasetLoader_Zhao2009::test_load",
      "lineno": 41,
      "outcome": "failed",
      "keywords": [
        "test_load",
        "TestDatasetLoader_Zhao2009",
        "test_zhao2009.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_zhao2009.py",
            "lineno": 49,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\zhao2009.py",
            "lineno": 91,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Spectral Sensitivity Database - Zhao et al. (2009)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/12 [0%] in 1.8s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_zhao2009.TestDatasetLoader_Zhao2009 object at 0x000001AD84C450A0>\n\n        def test_load(self) -> None:\n            \"\"\"\n            Test :func:`colour_datasets.loaders.zhao2009.\\\n    DatasetLoader_Zhao2009.load` method.\n            \"\"\"\n    \n            dataset = DatasetLoader_Zhao2009()\n>           assert sorted(dataset.load().keys()) == sorted(\n                [\n                    \"SONY DXC 930\",\n                    \"KODAK DCS 420\",\n                    \"NIKON D1X\",\n                    \"SONY DXC 9000\",\n                    \"CANON 10D\",\n                    \"NIKON D70\",\n                    \"KODAK DCS 460\",\n                    \"CANON 400D\",\n                    \"CANON 5D\",\n                    \"CANON 5D Mark 2\",\n                    \"Ladybug2\",\n                    \"KODAK DCS 200\",\n                ]\n            )\n\ncolour_datasets\\loaders\\tests\\test_zhao2009.py:49: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\zhao2009.py:91: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD867996C0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8681DE40>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD8679B...ocals>.inner at 0x000001AD8679BBA0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD8679B880>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/loaders/tests/test_zhao2009.py::TestBuildZhao2009::test_build_Zhao2009",
      "lineno": 73,
      "outcome": "failed",
      "keywords": [
        "test_build_Zhao2009",
        "TestBuildZhao2009",
        "test_zhao2009.py",
        "tests",
        "loaders",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\loaders\\tests\\test_zhao2009.py",
            "lineno": 80,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\zhao2009.py",
            "lineno": 154,
            "message": "in build_Zhao2009"
          },
          {
            "path": "colour_datasets\\loaders\\zhao2009.py",
            "lineno": 91,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Spectral Sensitivity Database - Zhao et al. (2009)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/4297288/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/12 [0%] in 0.3s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.loaders.tests.test_zhao2009.TestBuildZhao2009 object at 0x000001AD84C45430>\n\n    def test_build_Zhao2009(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.loaders.zhao2009.build_Zhao2009`\n        definition.\n        \"\"\"\n    \n>       assert build_Zhao2009() is build_Zhao2009()\n\ncolour_datasets\\loaders\\tests\\test_zhao2009.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\zhao2009.py:154: in build_Zhao2009\n    _DATASET_LOADER_JIANG2009.load()\ncolour_datasets\\loaders\\zhao2009.py:91: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD867ADD00>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86483180>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD8693C...ocals>.inner at 0x000001AD8693C040>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD867AFCE0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_configuration.py::TestUseSandbox::test_use_sandbox",
      "lineno": 31,
      "outcome": "passed",
      "keywords": [
        "test_use_sandbox",
        "TestUseSandbox",
        "test_configuration.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_configuration.py::TestSandbox::test_sandbox",
      "lineno": 49,
      "outcome": "passed",
      "keywords": [
        "test_sandbox",
        "TestSandbox",
        "test_configuration.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test__init__",
      "lineno": 109,
      "outcome": "passed",
      "keywords": [
        "test__init__",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test__repr__",
      "lineno": 168,
      "outcome": "passed",
      "keywords": [
        "test__repr__",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test__str__",
      "lineno": 121,
      "outcome": "passed",
      "keywords": [
        "test__str__",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_configuration",
      "lineno": 69,
      "outcome": "passed",
      "keywords": [
        "test_configuration",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_data",
      "lineno": 77,
      "outcome": "passed",
      "keywords": [
        "test_data",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_from_id",
      "lineno": 182,
      "outcome": "passed",
      "keywords": [
        "test_from_id",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_id",
      "lineno": 93,
      "outcome": "passed",
      "keywords": [
        "test_id",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_pull",
      "lineno": 201,
      "outcome": "failed",
      "keywords": [
        "test_pull",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\records\\tests\\test_zenodo.py",
            "lineno": 206,
            "message": ""
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Camera Spectral Sensitivity Database - Jiang et al. (2013)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.0s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.records.tests.test_zenodo.TestRecord testMethod=test_pull>\n\n    def test_pull(self) -> None:\n        \"\"\"Test :func:`colour_datasets.records.zenodo.Record.pull` method.\"\"\"\n    \n        self._record.remove()\n>       self._record.pull()\n\ncolour_datasets\\records\\tests\\test_zenodo.py:206: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86398E00>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD865DB240>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86398...ocals>.inner at 0x000001AD8639A200>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86398040>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_remove",
      "lineno": 208,
      "outcome": "failed",
      "keywords": [
        "test_remove",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\records\\tests\\test_zenodo.py",
            "lineno": 212,
            "message": ""
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Camera Spectral Sensitivity Database - Jiang et al. (2013)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.0s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.records.tests.test_zenodo.TestRecord testMethod=test_remove>\n\n    def test_remove(self) -> None:\n        \"\"\"Test :func:`colour_datasets.records.zenodo.Record.remove` method.\"\"\"\n    \n>       self._record.pull()\n\ncolour_datasets\\records\\tests\\test_zenodo.py:212: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86256F20>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD865ADD80>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD862DD...ocals>.inner at 0x000001AD862DE7A0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD862DE020>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_repository",
      "lineno": 82,
      "outcome": "passed",
      "keywords": [
        "test_repository",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_required_attributes",
      "lineno": 39,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_required_methods",
      "lineno": 53,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_synced",
      "lineno": 193,
      "outcome": "failed",
      "keywords": [
        "test_synced",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\records\\tests\\test_zenodo.py",
            "lineno": 197,
            "message": ""
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Camera Spectral Sensitivity Database - Jiang et al. (2013)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3245883/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.1s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.records.tests.test_zenodo.TestRecord testMethod=test_synced>\n\n    def test_synced(self) -> None:\n        \"\"\"Test :func:`colour_datasets.records.zenodo.Record.synced` method.\"\"\"\n    \n>       self._record.pull()\n\ncolour_datasets\\records\\tests\\test_zenodo.py:197: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD863A0860>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD862D1C00>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86254...ocals>.inner at 0x000001AD86255F80>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86254220>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestRecord::test_title",
      "lineno": 98,
      "outcome": "passed",
      "keywords": [
        "test_title",
        "TestRecord",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__getitem__",
      "lineno": 355,
      "outcome": "passed",
      "keywords": [
        "test__getitem__",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__init__",
      "lineno": 300,
      "outcome": "passed",
      "keywords": [
        "test__init__",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__iter__",
      "lineno": 363,
      "outcome": "passed",
      "keywords": [
        "test__iter__",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__len__",
      "lineno": 371,
      "outcome": "passed",
      "keywords": [
        "test__len__",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__repr__",
      "lineno": 341,
      "outcome": "passed",
      "keywords": [
        "test__repr__",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test__str__",
      "lineno": 312,
      "outcome": "passed",
      "keywords": [
        "test__str__",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_configuration",
      "lineno": 270,
      "outcome": "passed",
      "keywords": [
        "test_configuration",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_data",
      "lineno": 278,
      "outcome": "passed",
      "keywords": [
        "test_data",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_from_id",
      "lineno": 379,
      "outcome": "passed",
      "keywords": [
        "test_from_id",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_pull",
      "lineno": 402,
      "outcome": "failed",
      "keywords": [
        "test_pull",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\records\\tests\\test_zenodo.py",
            "lineno": 409,
            "message": ""
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 889,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Observer Function Database - Asano (2015)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/3 [0%] in 0.2s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.records.tests.test_zenodo.TestCommunity testMethod=test_pull>\n\n    def test_pull(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.records.zenodo.Community.pull` method.\n        \"\"\"\n    \n        self._community.remove()\n>       self._community.pull()\n\ncolour_datasets\\records\\tests\\test_zenodo.py:409: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:889: in pull\n    record.pull(use_urls_txt_file, retries)\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86377C40>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86816280>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD863A1...ocals>.inner at 0x000001AD863A3C40>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD863A25C0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_records",
      "lineno": 293,
      "outcome": "passed",
      "keywords": [
        "test_records",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_remove",
      "lineno": 411,
      "outcome": "failed",
      "keywords": [
        "test_remove",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\records\\tests\\test_zenodo.py",
            "lineno": 417,
            "message": ""
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 889,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Observer Function Database - Asano (2015)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/3 [0%] in 0.2s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.records.tests.test_zenodo.TestCommunity testMethod=test_remove>\n\n    def test_remove(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.records.zenodo.Community.remove` method.\n        \"\"\"\n    \n>       self._community.pull()\n\ncolour_datasets\\records\\tests\\test_zenodo.py:417: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:889: in pull\n    record.pull(use_urls_txt_file, retries)\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD86375080>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD8677AF40>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD866BC...ocals>.inner at 0x000001AD866BF380>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD866BFE20>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_repository",
      "lineno": 285,
      "outcome": "passed",
      "keywords": [
        "test_repository",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_required_attributes",
      "lineno": 238,
      "outcome": "passed",
      "keywords": [
        "test_required_attributes",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_required_methods",
      "lineno": 251,
      "outcome": "passed",
      "keywords": [
        "test_required_methods",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/records/tests/test_zenodo.py::TestCommunity::test_synced",
      "lineno": 392,
      "outcome": "failed",
      "keywords": [
        "test_synced",
        "TestCommunity",
        "test_zenodo.py",
        "tests",
        "records",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\records\\tests\\test_zenodo.py",
            "lineno": 398,
            "message": ""
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 889,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 419,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Observer Function Database - Asano (2015)\" record content...\n\u001b[?25l\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \u001b[?25h\u001b[J\rDownloading \"https://zenodo.org/api/records/3252742/files/urls.txt/content\" url \nDownloading files |\u26a0\ufe0e                                       | (!) 0/3 [0%] in 0.2s (0.00/s) \n",
        "longrepr": "self = <colour_datasets.records.tests.test_zenodo.TestCommunity testMethod=test_synced>\n\n    def test_synced(self) -> None:\n        \"\"\"\n        Test :func:`colour_datasets.records.zenodo.Community.synced` method.\n        \"\"\"\n    \n>       self._community.pull()\n\ncolour_datasets\\records\\tests\\test_zenodo.py:398: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\records\\zenodo.py:889: in pull\n    record.pull(use_urls_txt_file, retries)\ncolour_datasets\\records\\zenodo.py:419: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD864711C0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86885640>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86471...ocals>.inner at 0x000001AD86473EC0>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86470AE0>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestHashMd5::test_hash_md5",
      "lineno": 37,
      "outcome": "failed",
      "keywords": [
        "test_hash_md5",
        "TestHashMd5",
        "test_common.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\utilities\\tests\\test_common.py",
            "lineno": 42,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\labsphere2019.py",
            "lineno": 90,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Labsphere SRS-99-020 - Labsphere (2019)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3245874',\n     'conceptrecid': '3245874',\n     'created': '2019-06-14T09:30...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.utilities.tests.test_common.TestHashMd5 object at 0x000001AD84C826F0>\n\n    def test_hash_md5(self) -> None:\n        \"\"\"Test :func:`colour_datasets.utilities.common.hash_md5` definition.\"\"\"\n    \n        dataset = build_Labsphere2019()\n>       dataset.load()\n\ncolour_datasets\\utilities\\tests\\test_common.py:42: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\labsphere2019.py:90: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD866505E0>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD86A11F00>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD86650...ocals>.inner at 0x000001AD86652D40>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD86651800>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUrlDownload::test_url_download",
      "lineno": 75,
      "outcome": "failed",
      "keywords": [
        "test_url_download",
        "TestUrlDownload",
        "test_common.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
          "lineno": 121,
          "message": "UserWarning: Nested use of alive_progress is not yet supported."
        },
        "traceback": [
          {
            "path": "colour_datasets\\utilities\\tests\\test_common.py",
            "lineno": 80,
            "message": ""
          },
          {
            "path": "colour_datasets\\loaders\\labsphere2019.py",
            "lineno": 90,
            "message": "in load"
          },
          {
            "path": "colour_datasets\\loaders\\abstract.py",
            "lineno": 134,
            "message": "in sync"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 449,
            "message": "in pull"
          },
          {
            "path": "colour_datasets\\records\\zenodo.py",
            "lineno": 393,
            "message": "in urls_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 185,
            "message": "in url_download"
          },
          {
            "path": "colour_datasets\\utilities\\common.py",
            "lineno": 115,
            "message": "in __enter__"
          },
          {
            "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py",
            "lineno": 137,
            "message": "in __enter__"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\progress.py",
            "lineno": 247,
            "message": "in __alive_bar"
          },
          {
            "path": ".venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py",
            "lineno": 121,
            "message": "UserWarning"
          }
        ],
        "stdout": "Pulling \"Labsphere SRS-99-020 - Labsphere (2019)\" record content...\nDownloading files |\u26a0\ufe0e                                       | (!) 0/2 [0%] in 0.5s (0.00/s) \n",
        "longrepr": "self = Record(\n    {'conceptdoi': '10.5281/zenodo.3245874',\n     'conceptrecid': '3245874',\n     'created': '2019-06-14T09:30...      'repository': 'C:\\\\Users\\\\Mohay\\\\.colour-science\\\\colour-datasets',\n         'urls_txt_file': 'urls.txt'}\n    )\n)\nuse_urls_txt_file = True, retries = 3\n\n    def pull(self, use_urls_txt_file: bool = True, retries: int = 3) -> None:\n        \"\"\"\n        Pull the *Zenodo* record data to the local repository.\n    \n        Parameters\n        ----------\n        use_urls_txt_file\n            Whether to use the *urls.txt* file: if such a file is present in\n            the *Zenodo* record data, the urls it defines take precedence over\n            the record data files. The later will be used in the eventuality\n            where the urls are not available.\n        retries\n            Number of retries in case where a networking error occurs or the\n            *MD5* hash is not matching.\n    \n        Examples\n        --------\n        >>> from colour_datasets.utilities import suppress_stdout\n        >>> record = Record.from_id(\"3245883\")\n        >>> record.remove()\n        >>> with suppress_stdout():\n        ...     record.pull()\n        >>> record.synced()\n        True\n        \"\"\"\n    \n        print(f'Pulling \"{self.title}\" record content...')  # noqa: T201\n    \n        if not os.path.exists(self._configuration.repository):\n            os.makedirs(self._configuration.repository)\n    \n        downloads_directory = os.path.join(\n            self.repository, self._configuration.downloads_directory\n        )\n        if not os.path.exists(downloads_directory):\n            os.makedirs(downloads_directory)\n    \n        # As much as possible, the original file urls are used, those are\n        # given by the content of :attr:`URLS_TXT_FILE` attribute file.\n        urls_txt = None\n        for file_data in self.data[\"files\"]:\n            if file_data[\"key\"] == self._configuration.urls_txt_file:\n                urls_txt = file_data\n                break\n    \n        def urls_download(urls: Dict) -> None:\n            \"\"\"Download given urls.\"\"\"\n    \n            with alive_bar(len(urls), title=\"Downloading files\") as bar:\n                for url, md5 in urls.items():\n                    filename = re.sub(\"/content$\", \"\", url)\n                    filename = os.path.join(\n                        downloads_directory,\n                        urllib.parse.unquote(  # pyright: ignore\n                            filename.split(\"/\")[-1]\n                        ),\n                    )\n                    url_download(url, filename, md5.split(\":\")[-1], retries)\n                    bar()  # Update the progress bar\n    \n        try:\n            if use_urls_txt_file and urls_txt:\n                urls = {}\n                urls_txt_file = tempfile.NamedTemporaryFile(delete=False).name  # noqa: SIM115\n                url_download(\n                    urls_txt[\"links\"][\"self\"],\n                    urls_txt_file,\n                    urls_txt[\"checksum\"].split(\":\")[-1],\n                    retries,\n                )\n    \n                with open(urls_txt_file) as json_file:\n                    urls_txt_json = json.load(json_file)\n                    for url, md5 in urls_txt_json[\"urls\"].items():\n                        urls[url] = md5.split(\":\")[-1]\n    \n                shutil.copyfile(\n                    urls_txt_file,\n                    os.path.join(\n                        downloads_directory, self._configuration.urls_txt_file\n                    ),\n                )\n    \n                urls_download(urls)\n            else:\n                msg = (\n                    f'\"{self._configuration.urls_txt_file}\" file was not '\n                    f\"found in record data!\"\n                )\n>               raise ValueError(  # noqa: TRY301\n                    msg\n                )\nE               ValueError: \"urls.txt\" file was not found in record data!\n\ncolour_datasets\\records\\zenodo.py:425: ValueError\n\nDuring handling of the above exception, another exception occurred:\n\nself = <colour_datasets.utilities.tests.test_common.TestUrlDownload object at 0x000001AD84C82B40>\n\n    def test_url_download(self) -> None:\n        \"\"\"Test :func:`colour_datasets.utilities.common.url_download` definition.\"\"\"\n    \n        dataset = build_Labsphere2019()\n>       dataset.load()\n\ncolour_datasets\\utilities\\tests\\test_common.py:80: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\ncolour_datasets\\loaders\\labsphere2019.py:90: in load\n    super().sync()\ncolour_datasets\\loaders\\abstract.py:134: in sync\n    self.record.pull()\ncolour_datasets\\records\\zenodo.py:449: in pull\n    urls_download(urls)\ncolour_datasets\\records\\zenodo.py:393: in urls_download\n    url_download(url, filename, md5.split(\":\")[-1], retries)\ncolour_datasets\\utilities\\common.py:185: in url_download\n    with AliveProgressUpTo(\ncolour_datasets\\utilities\\common.py:115: in __enter__\n    self.bar.__enter__()\nC:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:137: in __enter__\n    return next(self.gen)\n.venv\\Lib\\site-packages\\alive_progress\\core\\progress.py:247: in __alive_bar\n    hook_manager = buffered_hook_manager(header if config.enrich_print else '',\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nheader_template = 'on {:d}: '\nget_pos = <function __alive_bar.<locals>.<lambda> at 0x000001AD864A0680>\noffset = 0\ncond_refresh = <Condition(<unlocked _thread.RLock object owner=0 count=0 at 0x000001AD868E2540>, 0)>\nterm = namespace(interactive=True, cursor_up_1=<function new.<locals>._ansi_escape_sequence.<locals>.inner at 0x000001AD864A0...ocals>.inner at 0x000001AD864A0720>, factory_cursor_up=<function new.<locals>.factory_cursor_up at 0x000001AD864A0860>)\n\n    def buffered_hook_manager(header_template, get_pos, offset, cond_refresh, term):\n        \"\"\"Create and maintain a buffered hook manager, used for instrumenting print\n        statements and logging.\n    \n        Args:\n            header_template (): the template for enriching output\n            get_pos (Callable[..., Any]): the container to retrieve the current position\n            offset (int): the offset to add to the current position\n            cond_refresh: Condition object to force a refresh when printing\n            term: the current terminal\n    \n        Returns:\n            a closure with several functions\n    \n        \"\"\"\n    \n        def flush_buffers():\n            for stream, buffer in buffers.items():\n                flush(stream)\n    \n        def flush(stream):\n            if buffers[stream]:\n                write(stream, '\\n')  # when the current index is about to change, send a newline.\n                stream.flush()\n    \n        def write(stream, part):\n            if isinstance(part, bytes):\n                part = part.decode(ENCODING)\n    \n            buffer = buffers[stream]\n            if part != '\\n':\n                osc = part.find('\\x1b]')  # https://en.wikipedia.org/wiki/ANSI_escape_code\n                if osc >= 0:\n                    end, s = part.find('\\x07', osc + 2), 1  # 1 -> len('\\x07')\n                    if end < 0:\n                        end, s = part.find('\\x1b\\\\', osc + 2), 2  # 2 -> len('\\x1b\\\\')\n                        if end < 0:\n                            end, s = len(part), 0\n                    stream.write(part[osc:end + s])\n                    stream.flush()\n                    part = part[:osc] + part[end + s:]\n                    if not part:\n                        return\n                with cond_refresh:\n                    # this will generate a sequence of lines interspersed with None, which will later\n                    # be rendered as the indent filler to align additional lines under the same header.\n                    gen = chain.from_iterable(zip(repeat(None), part.split('\\n')))\n                    buffer.extend(islice(gen, 1, None))\n            else:\n                with cond_refresh:\n                    if stream in base:  # pragma: no cover\n                        term.clear_line()\n                        term.clear_end_screen()\n                    if buffer:\n                        header = get_header()\n                        spacer = '\\n' + ' ' * len(header)\n                        nested = ''.join(spacer if line is None else line for line in buffer)\n                        buffer[:] = []\n                        stream.write(f'{header}{nested.rstrip()}')\n                    stream.write('\\n')\n                    stream.flush()\n                    cond_refresh.notify()\n    \n        # better hook impl, which works even when nested, since __hash__ will be forwarded.\n        class Hook(BaseHook):\n            def write(self, part):\n                return write(self._stream, part)\n    \n            def flush(self):\n                return flush(self._stream)\n    \n        def get_hook_for(handler):\n            if handler.stream:  # supports FileHandlers with delay=true.\n                handler.stream.flush()\n            return Hook(handler.stream)\n    \n        def install():\n            def get_all_loggers():\n                yield logging.root\n                yield from (logging.getLogger(name) for name in logging.root.manager.loggerDict)\n    \n            def set_hook(h):\n                try:\n                    return h.setStream(get_hook_for(h))\n                except Exception:  # captures AttributeError, AssertionError, and anything else,\n                    pass  # then returns None, effectively leaving that handler alone, unchanged.\n    \n            # account for reused handlers within loggers.\n            handlers = set(h for logger in get_all_loggers()\n                           for h in logger.handlers if isinstance(h, StreamHandler))\n            # modify all stream handlers, including their subclasses.\n            before_handlers.update({h: set_hook(h) for h in handlers})  # there can be Nones now.\n            sys.stdout, sys.stderr = (get_hook_for(SimpleNamespace(stream=x)) for x in base)\n    \n        def uninstall():\n            flush_buffers()\n            buffers.clear()\n            sys.stdout, sys.stderr = base\n    \n            [handler.setStream(original) for handler, original in before_handlers.items() if original]\n            before_handlers.clear()\n    \n            # did the number of logging handlers change??\n            # if yes, it probably means logging was initialized within alive_bar context,\n            # and thus there can be an instrumented stdout or stderr within handlers,\n            # which causes a TypeError: unhashable type: 'types.SimpleNamespace'...\n            # or simply a logger **reuses** a handler...\n    \n        if issubclass(sys.stdout.__class__, BaseHook):\n>           raise UserWarning('Nested use of alive_progress is not yet supported.')\nE           UserWarning: Nested use of alive_progress is not yet supported.\n\n.venv\\Lib\\site-packages\\alive_progress\\core\\hook_manager.py:121: UserWarning"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestJsonOpen::test_json_open",
      "lineno": 120,
      "outcome": "passed",
      "keywords": [
        "test_json_open",
        "TestJsonOpen",
        "test_common.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed",
        "stdout": "An error occurred while opening \"https://nemo.io\" url during attempt 1, retrying...\nAn error occurred while opening \"https://nemo.io\" url during attempt 2, retrying...\nAn error occurred while opening \"https://nemo.io\" url during attempt 3, retrying...\n"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_common.py::TestUnpackGzipfile::test_unpack_gzipfile",
      "lineno": 146,
      "outcome": "passed",
      "keywords": [
        "test_unpack_gzipfile",
        "TestUnpackGzipfile",
        "test_common.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestRowToIndex::test_row_to_index",
      "lineno": 40,
      "outcome": "passed",
      "keywords": [
        "test_row_to_index",
        "TestRowToIndex",
        "test_spreadsheet.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToRow::test_index_to_row",
      "lineno": 61,
      "outcome": "passed",
      "keywords": [
        "test_index_to_row",
        "TestIndexToRow",
        "test_spreadsheet.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestColumnToIndex::test_column_to_index",
      "lineno": 80,
      "outcome": "passed",
      "keywords": [
        "test_column_to_index",
        "TestColumnToIndex",
        "test_spreadsheet.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestIndexToColumn::test_index_to_column",
      "lineno": 101,
      "outcome": "passed",
      "keywords": [
        "test_index_to_column",
        "TestIndexToColumn",
        "test_spreadsheet.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "colour_datasets/utilities/tests/test_spreadsheet.py::TestCellRangeValues::test_cell_range_values",
      "lineno": 120,
      "outcome": "passed",
      "keywords": [
        "test_cell_range_values",
        "TestCellRangeValues",
        "test_spreadsheet.py",
        "tests",
        "utilities",
        "colour_datasets",
        "colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    }
  ],
  "warnings": [
    {
      "message": "defusedxml.cElementTree is deprecated, import from defusedxml.ElementTree instead.",
      "category": "DeprecationWarning",
      "when": "collect",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\xlrd\\xlsx.py",
      "lineno": 39
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: HTTP Error 404: Not Found\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: HTTP Error 404: Not Found\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: HTTP Error 404: Not Found\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: HTTP Error 404: Not Found\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: HTTP Error 403: Forbidden\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: HTTP Error 403: Forbidden\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    },
    {
      "message": "An error occurred using urls from \"urls.txt\" file: \"urls.txt\" file was not found in record data!\nSwitching to record urls...",
      "category": "ColourWarning",
      "when": "runtest",
      "filename": "D:\\repos\\colour-science@colour-datasets__aa4ae7be__tqdm__alive-progress\\.venv\\Lib\\site-packages\\colour\\utilities\\verbose.py",
      "lineno": 322
    }
  ]
}