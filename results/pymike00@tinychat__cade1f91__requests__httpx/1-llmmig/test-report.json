{
  "exitcode": 1,
  "summary": {
    "failed": 3,
    "passed": 18,
    "total": 21,
    "collected": 21
  },
  "collectors": [
    {
      "nodeid": "",
      "outcome": "passed",
      "result": [
        {
          "nodeid": ".",
          "type": "Dir"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 50
        },
        {
          "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 10
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming::test_stream_response_success",
          "type": "TestCaseFunction",
          "lineno": 9
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_anthropic_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 26
        },
        {
          "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 9
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming::test_stream_response_success",
          "type": "TestCaseFunction",
          "lineno": 7
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_cohere_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 53
        },
        {
          "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 10
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 8
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_google_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_invalid_key",
          "type": "TestCaseFunction",
          "lineno": 15
        },
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_valid_key",
          "type": "TestCaseFunction",
          "lineno": 9
        },
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_default_headers",
          "type": "TestCaseFunction",
          "lineno": 23
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_llms_base.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 49
        },
        {
          "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 10
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 8
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_mistral_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 53
        },
        {
          "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 11
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 8
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_openai_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_failure",
          "type": "TestCaseFunction",
          "lineno": 53
        },
        {
          "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_success",
          "type": "TestCaseFunction",
          "lineno": 11
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_client.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming::test_stream_response",
          "type": "TestCaseFunction",
          "lineno": 8
        }
      ]
    },
    {
      "nodeid": "tests/llms/test_together_handler.py",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming",
          "type": "UnitTestCase"
        }
      ]
    },
    {
      "nodeid": "tests/llms",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms/test_anthropic_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_anthropic_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_cohere_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_cohere_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_google_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_google_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_llms_base.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_mistral_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_mistral_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_openai_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_openai_handler.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_together_client.py",
          "type": "Module"
        },
        {
          "nodeid": "tests/llms/test_together_handler.py",
          "type": "Module"
        }
      ]
    },
    {
      "nodeid": "tests",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests/llms",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": "tinychat/backend",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat/llms",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat/ui",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat/utils",
      "outcome": "passed",
      "result": []
    },
    {
      "nodeid": "tinychat",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tinychat/backend",
          "type": "Package"
        },
        {
          "nodeid": "tinychat/llms",
          "type": "Package"
        },
        {
          "nodeid": "tinychat/ui",
          "type": "Package"
        },
        {
          "nodeid": "tinychat/utils",
          "type": "Package"
        }
      ]
    },
    {
      "nodeid": ".",
      "outcome": "passed",
      "result": [
        {
          "nodeid": "tests",
          "type": "Package"
        },
        {
          "nodeid": "tinychat",
          "type": "Package"
        }
      ]
    }
  ],
  "tests": [
    {
      "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_failure",
      "lineno": 50,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_failure",
        "__wrapped__",
        "patchings",
        "TestAnthropicAIClientStreaming",
        "test_anthropic_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "C:\\Users\\Mohay\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\unittest\\case.py",
          "lineno": 715,
          "message": "AssertionError: 'Server responded with an error. Status Code: 400' not found in 'Server responded with an error. Status Code: 401'"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_anthropic_client.py",
            "lineno": 65,
            "message": "AssertionError"
          }
        ],
        "longrepr": "self = <tests.llms.test_anthropic_client.TestAnthropicAIClientStreaming testMethod=test_perform_stream_request_failure>\nmock_api_key = <MagicMock name='api_key' id='1657989424064'>\nmock_post = <MagicMock name='post' id='1657989647824'>\n\n    @patch(\"tinychat.llms.anthropic.httpx.post\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    def test_perform_stream_request_failure(self, mock_api_key, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Mocking the response with an error status code\n        mock_response = Response(status_code=400, content=b\"\")\n        mock_post.return_value = mock_response\n    \n        client = AnthropicAIClient(model_name=\"test_model\", temperature=0.0)\n        messages = [{\"role\": \"user\", \"content\": \"hello\"}]\n    \n        with self.assertRaises(ValueError) as context:\n            next(client.perform_stream_request(messages))\n>       self.assertIn(\n            \"Server responded with an error. Status Code: 400\", str(context.exception)\n        )\nE       AssertionError: 'Server responded with an error. Status Code: 400' not found in 'Server responded with an error. Status Code: 401'\n\ntests\\llms\\test_anthropic_client.py:65: AssertionError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_anthropic_client.py::TestAnthropicAIClientStreaming::test_perform_stream_request_success",
      "lineno": 10,
      "outcome": "failed",
      "keywords": [
        "test_perform_stream_request_success",
        "__wrapped__",
        "patchings",
        "TestAnthropicAIClientStreaming",
        "test_anthropic_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\pymike00@tinychat__cade1f91__requests__httpx\\tinychat\\llms\\anthropic.py",
          "lineno": 51,
          "message": "ValueError: Server responded with an error. Status Code: 401"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_anthropic_client.py",
            "lineno": 40,
            "message": ""
          },
          {
            "path": "tinychat\\llms\\anthropic.py",
            "lineno": 51,
            "message": "ValueError"
          }
        ],
        "longrepr": "self = <tests.llms.test_anthropic_client.TestAnthropicAIClientStreaming testMethod=test_perform_stream_request_success>\nmock_api_key = <MagicMock name='api_key' id='1657990458368'>\nmock_post = <MagicMock name='post' id='1657990661184'>\n\n    @patch(\"tinychat.llms.anthropic.httpx.post\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    def test_perform_stream_request_success(self, mock_api_key, mock_post):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Mocking the response\n        mock_response = Mock(spec=Response)\n        mock_response.status_code = 200\n        mock_post.return_value = mock_response\n    \n        # Creating mock events\n        mock_event1 = MagicMock()\n        mock_event1.data = json.dumps(\n            {\"type\": \"content_block_delta\", \"delta\": {\"text\": \"part1\"}}\n        )\n        mock_event2 = MagicMock()\n        mock_event2.data = json.dumps(\n            {\"type\": \"content_block_delta\", \"delta\": {\"text\": \"part2\"}}\n        )\n        mock_event_done = MagicMock()\n        mock_event_done.data = json.dumps({\"type\": \"done\"})\n    \n        # Mocking SSEClient to return test events\n        with patch(\"tinychat.llms.anthropic.SSEClient\") as mock_sse_client:\n            test_stream = iter([mock_event1, mock_event2, mock_event_done])\n            mock_sse_client.return_value.events = MagicMock(return_value=test_stream)\n    \n            client = AnthropicAIClient(model_name=\"test_model\", temperature=0.0)\n            messages = [{\"role\": \"user\", \"content\": \"hello\"}]\n>           stream = client.perform_stream_request(messages)\n\ntests\\llms\\test_anthropic_client.py:40: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tinychat.llms.anthropic.AnthropicAIClient object at 0x0000018207A79730>\nmessages = [{'content': 'hello', 'role': 'user'}]\n\n    def perform_stream_request(self, messages: list[dict]) -> SSEClient:\n        # info: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events\n        data = {\n            \"model\": self.model_name,\n            \"messages\": messages,\n            \"temperature\": self.temperature,\n            \"stream\": True,\n            \"max_tokens\": 2048,\n        }\n        with httpx.stream(\n            \"POST\",\n            self.ANTHROPIC_MESSAGES_API_URL,\n            headers=self.anthropic_headers(),  # type: ignore\n            json=data,\n        ) as response:\n            if response.status_code != 200:\n>               raise ValueError(\n                    f\"Server responded with an error. Status Code: {response.status_code}\"\n                )\nE               ValueError: Server responded with an error. Status Code: 401\n\ntinychat\\llms\\anthropic.py:51: ValueError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_anthropic_handler.py::TestAnthropicAIHandlerStreaming::test_stream_response_success",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_stream_response_success",
        "__wrapped__",
        "patchings",
        "TestAnthropicAIHandlerStreaming",
        "test_anthropic_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_failure",
      "lineno": 26,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "__wrapped__",
        "patchings",
        "TestCohereClientStreaming",
        "test_cohere_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_cohere_client.py::TestCohereClientStreaming::test_perform_stream_request_success",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "__wrapped__",
        "patchings",
        "TestCohereClientStreaming",
        "test_cohere_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_cohere_handler.py::TestCohereHandlerStreaming::test_stream_response_success",
      "lineno": 7,
      "outcome": "failed",
      "keywords": [
        "test_stream_response_success",
        "__wrapped__",
        "patchings",
        "TestCohereHandlerStreaming",
        "test_cohere_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "failed",
        "crash": {
          "path": "D:\\repos\\pymike00@tinychat__cade1f91__requests__httpx\\tinychat\\llms\\cohere.py",
          "lineno": 84,
          "message": "AttributeError: 'list' object has no attribute 'iter_bytes'"
        },
        "traceback": [
          {
            "path": "tests\\llms\\test_cohere_handler.py",
            "lineno": 23,
            "message": ""
          },
          {
            "path": "tinychat\\llms\\cohere.py",
            "lineno": 84,
            "message": "AttributeError"
          }
        ],
        "longrepr": "self = <tests.llms.test_cohere_handler.TestCohereHandlerStreaming testMethod=test_stream_response_success>\nmock_api_key = <MagicMock name='api_key' id='1657994423440'>\nmock_perform_stream_request = <MagicMock name='perform_stream_request' id='1657994414272'>\n\n    @patch.object(CohereClient, \"perform_stream_request\")\n    @patch(\"tinychat.llms.base.BaseLLMClient.api_key\", new_callable=MagicMock)\n    def test_stream_response_success(self, mock_api_key, mock_perform_stream_request):\n        # Setting a dummy value for mock_api_key is not strictly needed here\n    \n        # Mocking the stream of responses\n        mock_stream = [b'{\"event_type\": \"text-generation\", \"text\": \"Hi!\"}',\n                       b'{\"event_type\": \"text-generation\", \"text\": \"How can I help?\"}']\n        mock_perform_stream_request.return_value = mock_stream\n    \n        handler = CohereHandler()\n        user_input = \"hello\"\n        generator = handler.stream_response(user_input)\n    \n        # Collecting responses from the generator\n>       responses = [resp for resp in generator]\n\ntests\\llms\\test_cohere_handler.py:23: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n\nself = <tinychat.llms.cohere.CohereHandler object at 0x00000182082B3890>\nuser_input = 'hello'\n\n    def stream_response(self, user_input: str) -> Generator[str, None, None]:\n        \"\"\"\n        Yield stream responses from the client as they are received.\n    \n        This method sends the user input to the client and then yields each piece\n        of the language model's response as it is received in real-time. After the\n        streaming is complete, it updates the message list with the user input and\n        the full language model response.\n    \n        :param user_input: The input string from the user to be sent to the model.\n        :return: A generator yielding the model's response in streamed parts.\n        \"\"\"\n        self._chat_history.append({\"role\": \"User\", \"message\": user_input})\n        stream = self._client.perform_stream_request(user_input, self._chat_history)\n        lm_response = \"\"\n>       for response_piece in stream.iter_bytes():  # Changed to httpx's iter_bytes\nE       AttributeError: 'list' object has no attribute 'iter_bytes'\n\ntinychat\\llms\\cohere.py:84: AttributeError"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_failure",
      "lineno": 53,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "__wrapped__",
        "patchings",
        "TestGoogleAIClientStreaming",
        "test_google_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_google_client.py::TestGoogleAIClientStreaming::test_perform_stream_request_success",
      "lineno": 10,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "__wrapped__",
        "patchings",
        "TestGoogleAIClientStreaming",
        "test_google_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_google_handler.py::TestGoogleGeminiHandlerStreaming::test_stream_response",
      "lineno": 8,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "__wrapped__",
        "patchings",
        "TestGoogleGeminiHandlerStreaming",
        "test_google_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_invalid_key",
      "lineno": 15,
      "outcome": "passed",
      "keywords": [
        "test_api_key_setter_invalid_key",
        "__wrapped__",
        "patchings",
        "TestBaseLLMClient",
        "test_llms_base.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_api_key_setter_valid_key",
      "lineno": 9,
      "outcome": "passed",
      "keywords": [
        "test_api_key_setter_valid_key",
        "__wrapped__",
        "patchings",
        "TestBaseLLMClient",
        "test_llms_base.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_llms_base.py::TestBaseLLMClient::test_default_headers",
      "lineno": 23,
      "outcome": "passed",
      "keywords": [
        "test_default_headers",
        "__wrapped__",
        "patchings",
        "TestBaseLLMClient",
        "test_llms_base.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_failure",
      "lineno": 49,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "__wrapped__",
        "patchings",
        "TestMistralClientStreaming",
        "test_mistral_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_mistral_client.py::TestMistralClientStreaming::test_perform_stream_request_success",
      "lineno": 10,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "__wrapped__",
        "patchings",
        "TestMistralClientStreaming",
        "test_mistral_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_mistral_handler.py::TestMistralHandlerStreaming::test_stream_response",
      "lineno": 8,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "__wrapped__",
        "patchings",
        "TestMistralHandlerStreaming",
        "test_mistral_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_failure",
      "lineno": 53,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "__wrapped__",
        "patchings",
        "TestOpenAIClientStreaming",
        "test_openai_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_openai_client.py::TestOpenAIClientStreaming::test_perform_stream_request_success",
      "lineno": 11,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "__wrapped__",
        "patchings",
        "TestOpenAIClientStreaming",
        "test_openai_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_openai_handler.py::TestOpenAIHandlerStreaming::test_stream_response",
      "lineno": 8,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "__wrapped__",
        "patchings",
        "TestOpenAIHandlerStreaming",
        "test_openai_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_failure",
      "lineno": 53,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_failure",
        "__wrapped__",
        "patchings",
        "TestTogetherClientStreaming",
        "test_together_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_together_client.py::TestTogetherClientStreaming::test_perform_stream_request_success",
      "lineno": 11,
      "outcome": "passed",
      "keywords": [
        "test_perform_stream_request_success",
        "__wrapped__",
        "patchings",
        "TestTogetherClientStreaming",
        "test_together_client.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    },
    {
      "nodeid": "tests/llms/test_together_handler.py::TestTogetherHandlerStreaming::test_stream_response",
      "lineno": 8,
      "outcome": "passed",
      "keywords": [
        "test_stream_response",
        "__wrapped__",
        "patchings",
        "TestTogetherHandlerStreaming",
        "test_together_handler.py",
        "llms",
        "tests",
        "pymike00@tinychat__cade1f91__requests__httpx",
        ""
      ],
      "setup": {
        "outcome": "passed"
      },
      "call": {
        "outcome": "passed"
      },
      "teardown": {
        "outcome": "passed"
      }
    }
  ]
}